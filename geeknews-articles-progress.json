[
  {
    "title": "Z80-μLM, 40KB 안에 담긴 ‘대화형 AI’",
    "content": "# Z80-μLM: 레트로컴퓨팅 마이크로 언어 모델\n[](#z80-μlm-a-레트로컴퓨팅-마이크로 언어 모델)\nZ80-μLM은 64kb RAM이 있는 Z80 프로세서에서 실행되는 양자화 인식 훈련(QAT)을 통해 짧은 문자별 시퀀스를 생성하는 '대화형 AI'입니다.\n이 프로젝트의 근본 원인은 다음과 같은 질문이었습니다. 개성을 유지하면서 얼마나 작아질 수 있는지, 쉽게 훈련하거나 미세 조정할 수 있는지? 간편한 자체 호스팅 배포가 가능합니까?\n대답은 '예'입니다! 그리고 1976년부터 4MHz 프로세서에서 실행되는 40kb .com 바이너리(추론, 가중치 및 채팅 스타일 UI 포함)입니다.\nTuring 테스트를 통과하지는 못하지만 녹색 화면에서 미소를 지을 수 있습니다.\n자신의 모델을 가장 잘 훈련시키는 방법에 대한 자세한 내용은 [TRAINING.md](/HarryR/z80ai/blob/main/TRAINING.md)를 참조하세요.\n## 예\n[](#예제)\n사전 구축된 두 가지 예가 포함되어 있습니다.\n### [tinychat](/HarryR/z80ai/blob/main/examples/tinychat)\n[](#tinychat)\n일상적인 Q&A 쌍으로 훈련된 대화형 챗봇입니다. 인사, 자신에 대한 질문, 일반적인 농담에 대해 간결한 성격 중심의 답변으로 응답합니다.\n````\n> 안녕하세요\n안녕하세요\n> 당신은 로봇입니까?\n예\n> 꿈을 꾸나요?\n어쩌면\n````\n### [추측](/HarryR/z80ai/blob/main/examples/guess)\n[](#추측)\n모델이 비밀 주제를 알고 질문에 대해 예/아니요/아마도 대답하는 20개 질문 게임입니다. 올바르게 추측하면 승리할 수 있습니다.\n````\n> 살아있나요?\n예\n> 큰가요?\n예\n> 트렁크가 있나요?\n예\n> 회색인가요?\n어쩌면\n> 코끼리\n승리\n````\nLLM(Ollama 또는 Claude API)을 사용하여 교육 데이터를 생성하고 클래스 분포의 균형을 맞추는 도구가 포함되어 있습니다.\n## 기능\n[](#기능)\n- **트라이그램 해시 인코딩**: 입력 텍스트는 128개의 버킷으로 해시됩니다. - 오타 허용, 단어 순서 불변\n- **2비트 가중치 양자화**: 각 가중치는 {-2, -1, 0, +1}이며 바이트당 4개씩 압축됩니다.\n- **16비트 정수 추론**: 모든 수학은 Z80 기본 16비트 부호 있는 산술을 사용합니다.\n- **~40KB .COM 파일**: CP/M의 TPA(임시 프로그램 영역)에 적합\n- **자동 회귀 생성**: 텍스트를 문자 단위로 출력합니다.\n- **부동 소수점 없음**: 모든 것이 고정 소수점 스케일링을 사용하는 정수 수학입니다.\n- **대화형 채팅 모드**: 인수 없이 `CHAT`을 실행하세요.\n## 상호작용 스타일\n[](#interaction 스타일)\n모델은 당신을 이해하지 못합니다. 하지만 어떻게든 그것은 당신을 *얻는다*.\n귀하의 입력은 추상적인 \"태그 클라우드\" 표현인 트라이그램 인코딩을 통해 128개의 버킷으로 해시됩니다. 모델은 정확한 단어가 아닌 입력의 *모양*에 반응합니다.\n````\n\"안녕하세요\" → [버킷 23:64, 버킷 87:32, ...]\n\"안녕하세요\" → [버킷 23:64, 버킷 87:32, ...] (동일!)\n\"helo ther\" → [버킷 23: 32, 버킷 87: 32, ...] (유사 - 오타 허용)\n````\n이는 짧은 입력의 경우 의미상 강력하지만 한계가 있습니다. 개념이 동일한 버킷을 놓고 경쟁함에 따라 길거나 순서에 따른 문장이 흐려집니다. \"문을 열고 불을 켜라\"는 \"문을 켜고 불을 켜라\"와 구별하기에는 너무 가까워질 가능성이 높습니다.\n### 작은 응답, 큰 의미\n[](#작은-응답-큰 의미)\n1~2단어 응답으로 놀라운 뉘앙스를 전달할 수 있습니다.\n- `OK' - 인정, 중립\n- '왜?' - 전제에 대한 질문\n- `R U?` - 실존적 의심 던지기\n- 'MAYBE' - 진짜 불확실성\n- `AM I?` - 다시 질문 반영\n이는 반드시 제한 사항은 아니며 상호 작용의 다른 모드입니다. 간결한 응답은 문맥에서 의미를 추론하거나 이해 여부를 확인하기 위해 직접 예/아니요 질문을 하도록 강요합니다(예: '당신은 봇입니까', '당신은 인간입니까', '나는 인간입니까'는 논리적으로 일관되게 기억된 답변을 표시합니다).\n### 잘하는 것\n[](#뭐가 좋은지)\n- 일관되게 분류된 출력을 갖춘 짧고 다양한 입력\n- 퍼지 매칭(오타, 바꿔쓰기, 단어 순서)\n- 어휘 선택을 통한 성격\n- 제한된 8비트 하드웨어에서 실행\n### 그게 아닌 것\n[](#무엇이 아닌지)\n- 새로운 문장을 생성하는 챗봇\n- 다중 턴 컨텍스트를 깊이 추적하는 것\n- 문법을 이해하는 파서\n- 일반 정보에 접근하는 모든 것\n작지만 기능적입니다. 때로는 그것이 바로 당신에게 필요한 것입니다.\n## 아키텍처\n[](#아키텍처)\n- **입력**: 쿼리 트라이그램 버킷 128개 + 컨텍스트 버킷 128개\n- **숨겨진 레이어**: 구성 가능한 깊이/너비(예: 256 → 192 → 128)\n- **출력**: 문자 세트의 문자당 하나의 뉴런\n- **활성화**: 히든 레이어 간 ReLU\n### 양자화 제약\n[](#양자화-제약조건)\nZ80은 8비트 CPU이지만 활성화 및 누산기에 16비트 레지스터 쌍(HL, DE, BC)을 사용합니다. 가중치는 바이트당 4비트(각각 2비트)로 압축되고 곱셈 누적을 위해 8비트 부호 있는 값으로 압축 해제됩니다.",
    "source": "github.com",
    "sourceUrl": "https://github.com/HarryR/z80ai",
    "category": "AI"
  },
  {
    "title": "CEO는 너무 비싸다. 자동화할 수는 없을까?",
    "content": "- \n[비즈니스\n](https://www.newstatesman.com/business)\n**\n- \n[기업\n](https://www.newstatesman.com/business/companies)\n**\n# CEO는 돈이 많이 든다. 왜 자동화하지 않습니까?\n단일 역할의 비용이 수천 명의 작업자만큼 비싸다면 확실히 로봇으로 인한 중복성의 주요 후보입니다.\n작성자:\n[윌 던](https://www.newstatesman.com/author/will-dunn) \n*\n(사진제공: 정성준/Getty Images)\n- \n[\n](mailto:type%20email%20address%20here?subject=I%20wanted%20to%20share%20this%20post%20with%20you%20from%20New%20Statesman&body=CEO%20%20대단히 %20비싸다.%20Why%20not%20automate%20them?%20-%20https://www.newstatesman.com/business/companies/2023/05/ceos-salaries-expensive-automate-robots)\n- \n[\n](http://www.linkedin.com/shareArticle?mini=true&url=https://www.newstatesman.com/business/companies/2023/05/ceos-salaries-expensive-automate-robots)\n- \n[\n](https://twitter.com/intent/tweet?url=https://www.newstatesman.com/business/companies/2023/05/ceos-salaries-expensive-automate-robots)\n- \n[\n](https://www.facebook.com/sharer/sharer.php?u=https://www.newstatesman.com/business/companies/2023/05/ceos-salaries-expensive-automate-robots)\n5월 31일 수요일, Channel 4의 CEO인 Alex Mahon이 [기록적인 연간 급여 140만 파운드](https://www.theguardian.com/uk-news/2023/may/31/channel-4-boss-alex-mahon-could-get-stations-biggest-ever-payday-of-14m)를 받을 수 있다고 보고되었습니다. 이 기사는 원래 2021년 4월 26일에 게시되었으며 임원 급여가 계속 인상됨에 따라 회사에 CEO가 전혀 필요합니까?*를 묻습니다.\n앞으로 2주 동안 [BAE Systems](https://news.sky.com/story/bae-systems-on-defensive-over-golden-handcuffs-deal-for-sought-after-ceo-12280257) 이사회는 [AstraZeneca](https://news.sky.com/story/looming-astrazeneca-pay-row-provides-latest-headache-for-ceo-soriot-12284677), [Glencore](https://www.reuters.com/article/glencore-ceo-pay-idUSL1N2M90QZ), [Flutter 엔터테인먼트](https://www.thetimes.co.uk/article/flutter-entertainment-shareholder-revolt-chief-executive-pay-rise-hostelworld-v6j3khkx2) 및 [런던 증권 거래소](https://news.sky.com/story/london-stock-exchange-faces-investor-backlash-over-chiefs-25-pay-rise-12262725) 모두 다가오는 연례 주주총회(AGM)에서 임원 보수를 두고 주주들이 반발할 가능성에 직면해 있습니다. AGM 시즌이 시작되면서 특히 급여에 대한 관심이 집중되고 있습니다.\n임원 급여는 종종 AGM에서 가장 논쟁의 여지가 있는 항목이지만 올해는 분명히 예외적입니다. [Covid-19](https://www.newstatesman.com/tag/covid-19)로 인해 심각한 영향을 받은 기업을 운영하는 사람들은 팬데믹으로 인한 수익 손실에 대해 비난받을 수 없지만, 그들을 버틸 수 있게 해준 정부 부양책에 대한 공로를 인정할 수도 없습니다. 예를 들어, 지난 주 부동산 중개업체 Foxtons의 주주 중 거의 40%가 [반대 투표](https://propertyindustryeye.com/last-weeks-foxtons-agm-must-serve-as-a-wake-up-call-for-the-board/)하여 CEO인 Nicholas Budden이 £1m 미만의 보너스를 받았습니다. Foxtons는 직접적인 정부 지원으로 약 700만 파운드를 받았으며 정부의 [지속적인 주택 시장 인플레이션](https://www.newstatesman.com/business/sectors/2021/04/who-benefits-when-government-pumps-housing-market)의 혜택을 받고 있습니다. Foxtons의 지속적인 행운을 보장하기 위해 가장 많은 일을 한 사람은 Nicholas Budden이 아니라 [Rishi Sunak](https://www.newstatesman.com/tag/rishi-sunak)입니다. \n기업 및 규제 개혁법에 따라 임원 급여는 최소 3년마다 투표로 결정되며, 이 과정에서 주주와 대중은 최고위층이 얼마나 많은 돈을 가져가는지 대결하게 됩니다. FTSE 100에서 가장 높은 연봉을 받는 CEO인 Tim Steiner는 2019년 Ocado 운영 대가로 5,870만 파운드를 받았습니다. 이는 해당 연도 [직원 중간 소득의 2,605배](https://www.cipd.co.uk/Images/ftse-100-executive-pay-report_tcm18-82375.pdf)에 해당하는 반면, 평균 FTSE100 CEO는 더 많은 연봉을 받았습니다. 하루 £15,000 이상. \n[*](자바스크립트(void);)\n이번 크리스마스에 자신이나 친구에게 £2의 New Statesman 구독권을 선물하세요. \n[구독](https://secure.newstatesman.com/W5KXPOPN)\nHigh Pay Center의 CEO 급여에 대한 연간 평가에서 지적했듯이, 최고 임금 청구서가 CEO를 넘어서까지 확장되며 올해 어떤 회사에서도 지속 가능하지 않을 수 있습니다. 보고서는 “CEO 외에 고소득자를 고려할 때 기업이 고임금 직원에게 희생을 요구함으로써 일자리와 소득을 보호할 수 있는 가능성이 실제로 상당히 크다”고 말합니다.\n장기적으로 보면,",
    "source": "newstatesman.com",
    "sourceUrl": "https://www.newstatesman.com/business/companies/2023/05/ceos-salaries-expensive-automate-robots",
    "category": "AI"
  },
  {
    "title": "작업을 공개하면 행운이 따른다",
    "content": "[\n](/읽어보기)\n# \n작품을 출판하면 행운이 늘어납니다\n으스스한 댓글 하나하나에 대해 당신의 작품을 존경하는 사람들이 10배나 더 많습니다.\n*\n작품: [아리엘 데이비스](https://arielrdavis.com/)\n![Aaron Francis의 사진](//images.ctfassets.net/s5uo95nf6njh/6o81SACP0ugjHy1SYtPCSt/4340ed9255f5e7bc8ff2e8dc5ea1d4a5/DSC_4446__1_.jpg?w=240&fm=jpg)\n![튜플 로고](//images.ctfassets.net/s5uo95nf6njh/7gheNu5VYCPxhHlk9lFUXP/916b37d5b5a5af0c0b2ac238ab10725d/Tuple_logo.jpeg?w=72&fm=jpg)\n**Aaron Francis** // 마케팅 엔지니어, Tuple \n**ReadME 프로젝트**는 오픈 소스 커뮤니티, 즉 매일 세상을 발전시키는 데 기여하는 관리자, 개발자 및 팀의 목소리를 증폭시킵니다.\n- \n[\n](https://twitter.com/intent/tweet?url=https%3A%2F%2Fgithub.com%2Freadme%2Fguides%2Fpublishing-your-work&text=)\n- \n[\n](https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fgithub.com%2Freadme%2Fguides%2Fpublishing-your-work&quote=)\n- \n[\n](https://www.linkedin.com/sharing/share-offsite/?url=https%3A%2F%2Fgithub.com%2Freadme%2Fguides%2Fpublishing-your-work)\n[\nReadME 프로젝트](/readme)\n** \n아무리 열심히 일하더라도 뭔가를 성공시키려면 여전히 약간의 행운이 필요합니다. 행운은 우리가 통제할 수 없는 힘처럼 느껴지기 때문에 그것은 실망스러울 수 있습니다. 하지만 좋은 소식은 행운을 만날 확률이 높아질 수 있다는 것입니다. 그것은 마술처럼 들릴지 모르지만 초자연적인 것은 아닙니다. 비결은 행운이 우리를 찾을 수 있는 기회의 수를 늘리는 것입니다. 당신의 작품을 출판하는 단순한 행위는 당신의 삶에 조금 더 많은 행운을 불러오는 가장 좋은 방법 중 하나입니다.\n\"어떻게\"에 대해 알아보기 전에 \"무엇\"에 대해 동일한 내용을 이해하는 것이 중요합니다. \"행운\"이라고 하면 무엇을 말하는 걸까요? 적용할 수 있는 정의가 많이 있지만 간단한 정의만 고수하겠습니다. 행운은 예상치 못한 좋은 일이 당신에게 일어날 때입니다. 예상치 못한 좋은. 예상치 못한 좋은 일이 일어날 확률을 높이고 싶지 않은 사람이 어디 있겠습니까?\n우리 세상에서 행운에는 다음이 포함될 수 있습니다.\n- OSS 라이브러리 출시\n- 컨퍼런스에서 연설하도록 초대받는 경우\n- 새로운 직업을 구함\n- 새로운 컨설팅 고객 확보\n- 팟캐스트에 초대받기\n- 지역 사회에서 새로운 친구 사귀기\n이러한 것 중 어느 것도 전적으로 귀하가 통제할 수 없으므로 때때로 좌절감을 느낄 수 있습니다. \n행운을 찾을 확률을 어떻게 높일 수 있습니까? 공개적으로 일하는 사람이 됨으로써. 일을 하고 그에 대해 공개함으로써 자신에 대한 평판을 쌓을 수 있습니다. 당신은 실적을 구축합니다. 당신은 그 어떤 이력서보다 당신을 대신하여 더 잘 말할 수 있는 공공 기관을 구축할 수 있습니다.\n목표는 유명해지는 것이 아니라 행운이 우리를 찾을 가능성을 높이는 것입니다. 나에게 있어 이에 대해 생각하는 가장 유용한 방법 중 하나는 [Jason Roberts의 이전 게시물](https://www.codusoperandi.com/posts/increasing-your-luck-surface-area)에 설명된 \"행운 표면적\"이라는 개념이었습니다. 그는 다음과 같이 썼습니다(그리고 강조점은 제가 쓴 것입니다). \n\"당신의 삶에서 일어날 우연의 양, 즉 행운 표면적은 당신이 열정을 갖고 있는 **무언가를 하는** 정도와 이것이 ****효과적으로 전달되는 총 사람들의 수****에 정비례합니다.\"*\n더 나아가 그는 이를 다음과 같은 공식으로 코드화합니다.\n1\n````\n행운 = [일을 하는 것] * [사람들에게 말하는 것]\n````\n당신이 하는 일이 많아질수록, 더 많은 사람에게 알리게 될수록 당신의 행운 표면적은 더 커집니다. 행운의 표면적이 클수록 흘러가는 행운을 잡을 확률이 높아집니다.\n*\n### 출처:[제이슨 로버츠](https://www.codusoperandi.com/posts/increasing-your-luck-surface-area)\n---\n## 일을 하는 중\n작업을 출판하기 전에 실제로 작업을 수행*해야 합니다. 좋은 소식은 ReadME 프로젝트에 대한 이 가이드를 읽는 것만으로도 이미 \"일을 하는\" 것이 어느 정도 자연스럽게 이루어지는 사람들의 그룹으로 스스로 선택되었을 것이라는 것입니다. 당신은 개발자, 디자이너, 창작자, 작가 또는 완전히 다른 사람입니다.  자신에게 어떤 별명을 붙이든 당신은 일을 *할* 수 있도록 만들어졌으며 그것이 중요한 부분입니다. \n이것이 사실이 아닌 경우 다음 두 그룹 중 하나에 속할 수 있습니다.\n- 당신은 실제로 어떤 일을 *하고* 있고, 자신이 하는 모든 일이 공유할 가치가 없다고 생각하도록 스스로 훈련했을 뿐입니다.\n- 당신은 어떤 일을 *하고 싶지만* 시작할 마음이 없습니다.\n첫 번째 그룹에 속해 있다면 한 걸음 물러나 이미 하고 있는 작업을 재구성해야 할 수도 있습니다. 이것은 높은 수준의 실행을 하는 사람들이 흔히 발견하는 사각지대입니다! 그들은",
    "source": "github.com",
    "sourceUrl": "https://github.com/readme/guides/publishing-your-work",
    "category": "AI"
  },
  {
    "title": "Google Ads는 죽었다. 이제 어디로 가야 할까?",
    "content": "# 구글은 죽었다. 이제 우리는 어디로 가는 걸까요?\n일화인 건 알지만 제 주요 [엔터테인먼트 사업](https://bigtop.co.za) 수익이 지난 3개월 동안 50% 감소했습니다. 우리의 주요 유료 리드 소스는 지난 10여년 동안 우리에게 많은 도움을 준 Google Ads였습니다. 이제 제가 애드워즈에서 무엇을 하고 있는지 알 것 같습니다. \n한 달에 한 번씩 분석을 확인하고 키워드를 업데이트하며 광고 캠페인을 조정합니다. 지난 1년 동안 우리는 예산을 늘렸고, 일주일에 한 번씩 다양한 설정으로 동시 캠페인을 실행하면서 뭔가를 얻기 위해 예산을 살펴보기 시작했습니다. \n지난 달 Google은 우리에게 보너스, 즉 공짜 돈을 주었습니다! 이는 12월 연휴 동안 가장 필요할 때 지출하기 위해 월간 광고 지출의 5배였습니다. 또 다른 새 캠페인을 추가하고 기존 캠페인의 예산을 업데이트했습니다. 여전히 변화가 없습니다. 지난 주에는 사용하지 않은 광고 지출로 인해 남은 돈을 태울 수 있었습니다. 예산을 10배로 늘렸습니다. 제로 리턴. \n돈이 다 떨어졌습니다. 더 이상 넣지 않겠습니다. 여기서 어디로 가야 할까요? \n## 다음은 무엇입니까\n연구에 따르면 많은 젊은이들이 TikTok 및 Instagram과 같은 짧은 비디오 플랫폼에서 정보를 얻고 있습니다. 우리는 거기에 광고를 시도하고 있습니다. \n우리 고객 기반은 50%의 재방문 고객으로 구성되어 있습니다(그 통계가 자랑스럽습니다!). 우리는 이메일 뉴스레터를 가지고 있으며 지난 2개월 동안 정기적으로 보내기 시작했습니다. 우리를 기억하시나요? \n우리는 또한 실제 물리적 광고도 할 계획입니다. 다음 주말에 시장에 가서 무료 쇼를 한두 번 하고 카드를 나눠줄 예정입니다. \n또한, 우리는 사업을 확장하고 있습니다. [Magic Poi 프로젝트](http://www.patreon.com/c/CircusScientist)와 관련하여 만들고 싶은 프로젝트가 몇 가지 있는데, 판매를 희망하고 있습니다. 우리는 지난주에 물품을 주문했습니다. \n하지만 지금은 – 나는 파산했습니다. [웹사이트 또는 IOT 프로젝트 구축](https://devsoft.co.za)이 필요한 분 계시나요? 나는 AI의 도움을 받아 매우 빠릅니다!",
    "source": "circusscientist.com",
    "sourceUrl": "https://www.circusscientist.com/2025/12/29/google-is-dead-where-do-we-go-now/",
    "category": "AI"
  },
  {
    "title": "GOG가 원 공동 창업자에게 인수됨",
    "content": "안녕하세요 여러분, GOG 팀이 왔습니다.**\n현재 CD PROJEKT의 공동 창립자 중 한 명이자 GOG의 공동 창립자인 Michał Kiciński가 CD PROJEKT로부터 GOG를 인수했습니다.\n# GOG와 마이클 키친스키가 뭉친 이유\n우리는 우리를 형성한 게임이 살아남을 자격이 있다고 믿습니다. 쉽게 찾고, 구매하고, 다운로드하고, 영원히 플레이할 수 있습니다. 하지만 시간은 그것들을 지우는 데 짜증스러울 정도로 좋습니다. 권리가 엉키고, 호환성이 깨지고, 빌드가 사라지고, 향수에 젖는 저녁이 문제 해결 세션으로 바뀌는 경우가 많습니다. 이것이 \"오늘 플레이 중입니다\"(게임은 계속 진행됨)와 \"언젠가 플레이하겠습니다\"(게임이 종료됨)의 차이입니다.\nMichał이 말했듯이 \"GOG는 자유, 독립, 진정한 통제를 상징합니다.\"\nGOG는 항상 강력한 가치와 명확한 원칙을 바탕으로 구축되었습니다. Marcin Iwiński와 Michał Kiciński가 2007년에 처음으로 GOG에 대한 아이디어를 내놓았을 때의 비전은 간단했습니다. 클래식 게임을 플레이어에게 다시 제공하고, 일단 게임을 구매하면 그 게임이 영원히 당신의 것이 되도록 하는 것입니다. 필수 고객과 폐쇄적인 생태계로 점점 더 정의되는 시장에서 이러한 철학은 그 어느 때보다 더 적절하다고 느껴집니다.\n이 새로운 장은 그 비전을 두 배로 확대하는 것에 관한 것입니다. 우리는 과거의 고전 게임을 보존하고, 오늘날의 뛰어난 게임을 기념하며, 진정한 복고풍 정신이 담긴 새로운 게임을 포함하여 미래의 고전 게임을 형성하는 데 도움을 주기 위해 더 많은 일을 하고 싶습니다.\n# 당신에게 그것은 무엇을 의미합니까?\n우선, DRM 프리는 그 어느 때보다 GOG의 핵심입니다. 동일한 액세스, 동일한 오프라인 설치 프로그램, 동일한 소유권을 누릴 수 있는 라이브러리입니다. 귀하의 데이터는 GOG에 보관되며 GOG GALAXY는 선택 사항으로 유지됩니다.\n우리는 CD PROJEKT와의 관계를 계속 이어갈 것입니다. CD PROJEKT RED 게임은 계속해서 [GOG](http://gog.com)에서 이용할 수 있으며, 스튜디오에서 출시할 예정인 타이틀도 이 플랫폼에서 출시될 예정입니다. \nGOG 후원자이거나 보존 프로그램을 지원하기 위해 기부하는 경우 해당 자금은 GOG 내에 유지됩니다. 올해 여러분의 지원은 엄청났습니다. 여러분의 도움으로 우리는 2026년과 2027년에 훨씬 더 야심찬 구조 임무를 수행할 수 있다고 생각합니다. 이에 대해서는 2026년에 더 많은 말씀을 드릴 수 있을 것입니다.\nGOG는 독립적인 운영을 유지합니다. 우리는 인디 개발자가 전 세계에 진출할 수 있도록 돕는 동시에 윤리적이고 약탈적이지 않으며 지속 가능한 플랫폼을 계속 구축할 것입니다. 또한 우리는 2026년에 계획된 새로운 계획을 통해 커뮤니티에 더 강력한 목소리를 제공하기 위해 최선을 다하고 있습니다.\n이 모든 것이 중요한 이유가 되어 주셔서 감사합니다.\n많은 회사에서 게임을 판매합니다. 사람들의 삶을 형성한 게임이 비호환성으로 조용히 썩어가는 일이 없도록 하는 화려하지 않은 작업을 수행하는 사람은 거의 없습니다.\n우리와 함께 이 임무에 관심을 가져주셔서 감사합니다. 배송되는 대로 계속해서 알려드리겠습니다. 그동안 전체 FAQ를 통해 자세한 답변을 확인하실 수 있습니다.\n## FAQ\n### 무슨 일이 일어나고 있나요?**\nGOG의 최초 공동 창립자이자 CD PROJEKT의 공동 창립자인 Michał Kiciński가 CD PROJEKT에서 GOG를 인수했습니다. GOG는 게임을 영원히 살아있게 한다는 동일한 사명을 가지고 별도의 회사인 GOG로 계속 운영될 것입니다.\n### **이에 대한 GOG의 입장은 무엇인가요?**\nGOG에서는 이것이 GOG의 고유한 기능을 가속화하는 가장 좋은 방법이라고 생각합니다. Michał Kiciński는 고전 게임을 다시 가져와 한 번 구매한 게임을 영원히 제어할 수 있다는 간단한 아이디어를 바탕으로 GOG를 만든 사람들 중 한 명입니다. 그가 GOG를 인수함에 따라 우리는 자유, 독립성, 통제, 시간이 지나도 게임을 계속 플레이할 수 있도록 하는 우리의 가치에 부합하는 장기적인 지원을 계속하고 있습니다.\n### **Michał Kiciński가 이런 일을 하는 이유는 무엇입니까?**\n왜냐하면 그는 GOG의 원래 철학을 보존하고 성장시키고 싶기 때문입니다. 필수 클라이언트와 폐쇄된 생태계를 향해 계속 나아가고 있는 PC 시장에서 그는 GOG의 접근 방식이 그 어느 때보다 적절하다고 믿습니다. 즉, 종속성, 강제 플랫폼 없음, 소유권이 없다는 것입니다. 그의 목표는 게이머와 개발자 모두를 계속 지원하고 GOG의 사명을 강화하는 것입니다. 즉, 과거의 고전 게임을 보존하고, 오늘날의 뛰어난 게임을 기념하며, 미래의 고전 게임을 만드는 데 도움을 주는 것입니다.\n### **CD PROJEKT는 왜 이런 일을 하고 있나요?**\nGOG 판매는 CD PROJEKT의 장기 전략에 부합합니다. CD PROJEKT는 최고 품질의 RPG를 제작하고 팬들에게 브랜드를 기반으로 한 다른 형태의 엔터테인먼트를 제공하는 데 모든 관심을 집중하고 싶습니다. 이번 계약을 통해 CD PROJEKT는 그 초점을 유지하고 GOG는 자체 사명을 추구할 수 있는 강력한 지원을 받게 됩니다.\n### **GOG의 사명이 바뀌나요?**\n아니요. 우리의 사명은 게임을 영원히 살아있게 만드는 것입니다.\n### **DRM 프리가 여전히 GOG의 핵심인가요?**\n그렇습니다. DRM 프리는 그 어느 때보다 GOG의 핵심입니다.\n### **내 GOG 계정은 어떻게 되나요?**\n아무것도 변하지 않습니다. 귀하의 계정",
    "source": "gog.com",
    "sourceUrl": "https://www.gog.com/blog/gog-is-getting-acquired-by-its-original-co-founder-what-it-means-for-you/",
    "category": "AI"
  },
  {
    "title": "FastLanes – 차세대 빅데이터 파일 포맷",
    "content": "[*](/cwida/FastLanes/blob/dev/assets/logo.svg)\n[![라이센스: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](/cwida/FastLanes/blob/dev/LICENSE)\n**Parquet와 비슷하지만 압축률이 40% 향상되고 디코딩 속도가 40배 빨라졌습니다.**\nFastLanes 기능:\n- \n**명시적인 SIMD 지침이 없어 완전히 SIMD 친화적입니다**\n- \n**의존성 없음**:\n외부 라이브러리가 필요하지 않습니다\n---\n## 문서\n[](#문서)\n- [타이핑 시스템](/cwida/FastLanes/blob/dev/docs/typing_system.md)\n- [파일 형식 사양(PDF)](/cwida/FastLanes/blob/dev/docs/specation.pdf)\n---\n## 시작하기\n[](#시작하기)\n### 파이썬\n[](#파이썬)\n````\npyfastlanes 가져오기\n# FastLanes에 연결\nconn = pyfastlanes.connect()\n# CSV 디렉토리를 FastLanes 형식으로 변환\nconn.inline_footer().read_csv(\"path/to/csv_dir\").to_fls(\"data.fls\")\n# 다시 읽고 CSV에 쓰기\n리더 = conn.read_fls(\"data.fls\")\nreader.to_csv(\"decoded.csv\")\n````\n### C++\n[](#c)\nCMake를 통해 FastLanes를 종속성으로 추가합니다.\n````\n포함(FetchContent)\nFetchContent_Declare(\n고속 차선\nGIT_REPOSITORY https://github.com/cwida/FastLanes.git\nGIT_TAG 개발자\n)\nFetchContent_MakeAvailable(fastlanes)\nadd_executable(예제 example.cpp)\ntarget_link_libraries(예: PRIVATE FastLanes)\n````\n사용 예:\n````\n#include \"fastlanes.hpp\"\n정수 메인() {\nfastlanes::연결 연결;\nconn.read_csv(\"data/csv_dir\").to_fls(\"data.fls\");\n자동 판독기 = fastlanes::Connection().read_fls(\"data.fls\");\nreader->to_csv(\"decoded.csv\");\nEXIT_SUCCESS를 반환합니다.\n}\n````\n### 러스트\n[](#녹)\nFastLanes Rust 바인딩을 `Cargo.toml`에 추가하세요.\n````\n[종속성]\nfls-rs = { 경로 = \"./rust\" }\n````\n````\n어쨌든 사용::Result;\nfls_rs::connect를 사용하세요.\nfn main() -> 결과<()> {\nlet mut conn = connect();\nconn.inline_footer()\n.read_csv(\"데이터/csv_dir\")\n.to_fls(\"data.fls\");\nconn.read_fls(\"data.fls\")\n.to_csv(\"decoded.csv\");\n알았어(())\n}\n````\n### 출시 예정\n[](#출시 예정)\n- FastLanes CUDA 리더에 대한 **CUDA** 지원\n---\n## 출판물\n[](#출판물)\n- \n**Azim Afroozeh & Peter Boncz**, \"FastLanes 압축 레이아웃: 디코딩 > 초당 1000억 정수\n스칼라 코드,” PVLDB*, 16(9): 2132–2144, 2023년 5월\n[논문 읽기](https://www.vldb.org/pvldb/vol16/p2132-afroozeh.pdf)\n- [소스 코드](/cwida/FastLanes/blob/dev/publications/data_parallelized_encodings)\n- \n**Azim Afroozeh, Lotte Felius & Peter Boncz**, \"FastLanes 압축을 사용하여 GPU 데이터 처리 가속화\", *DaMoN\n’24*, 새로운 하드웨어의 데이터 관리에 관한 제20차 국제 워크숍 간행물, 칠레 산티아고, 2024년 6월\n[논문 읽기](https://doi.org/10.1145/3662010.3663450)\n- [소스코드](https://github.com/cwida/FastLanesGPU)\n- \n**Azim Afroozeh, Leonardo Kuffó 및 Peter Boncz**, “ALP: 적응형 무손실 부동 소수점 압축,” *SIGMOD ’24*,\nACM SIGMOD, 2024년 6월\n[논문 읽기](https://doi.org/10.1145/3626717)\n- [소스코드](https://github.com/cwida/ALP)\n- \n**Sven Hielke Hepkema, Azim Afroozeh, Charlotte Felius, Peter Boncz & Stefan Manegold**, “G-ALP: 재고\nGPU용 경량 인코딩,” *DaMoN ’25*, 2025년 7월\n[논문 읽기](https://dl.acm.org/doi/pdf/10.1145/3736227.3736242)\n- [소스코드](https://github.com/cwida/FastLanesGpu-Damon2025)\n---\n## 인용 방법\n[](#인용 방법)\n연구나 프로젝트에서 FastLanes를 사용하는 경우 다음을 인용해 주세요.\n````\n@article{afroozeh2023fastlanes,\n작성자 = {Afroozeh, Azim 및 Boncz, Peter},\ntitle = {FastLanes 압축 레이아웃: 디코딩 > 스칼라 코드를 사용하여 초당 1000억 정수},\n저널 = {VLDB 기부금 절차},\n볼륨 = {16},\n번호 = {9},\n페이지 = {2132--2144},\n월 = 5월,\n연도 = {2023},\n게시자 = {VLDB 기부금}\n}\n@inproceedings{afroozeh2024gpu,\n작성자 = {Afroozeh, Azim 및 Felius, Lotte 및 Boncz, Peter},\ntitle = {FastLanes 압축을 사용하여 GPU 데이터 처리 가속화},\n책제목 = {DaMoN ’24: 제20회 새로운 하드웨어 데이터 관리 국제 워크숍 진행},\n페이지 = {1--11},\n월 = 6월,\n연도 = {2024},\n조직 = {ACM},\n도이 = {10.1145/3662010.3663450}\n}\n@inproceedings{afroozeh2024alp,\n저자 = {Afroozeh, Azim 및 Kuffó, Leonardo 및 Boncz, Peter},\ntitle = {ALP: 적응형 무손실 부동 소수점 압축},\n책제목 = {SIGMOD ’24: 데이터 관리에 관한 2024 ACM SIGMOD 국제 컨퍼런스 진행},\n페이지 = {1--13},\n월 = 6월,\n연도 = {2024},\n조직 = {ACM},\n도이 = {10.1145/3626717}\n}\n@inproceedings{hepke2025galp,\n저자 = {Hepkema, Sven Hielke 및 Afroozeh, Azim 및 Felius, Charlotte 및 Boncz, Peter 및 Manegold, Stefan},\ntitle = {G‑ALP: 리를 다시 생각하다",
    "source": "github.com",
    "sourceUrl": "https://github.com/cwida/FastLanes",
    "category": "AI"
  },
  {
    "title": "창업자가 집중해야 할 '회사를 만드는 초석'들",
    "content": "**[Dharmesh Shah](https://www.linkedin.com/in/dharmesh/?ref=review.firstround.com)**가 아내와의 약속을 지켰다면 **HubSpot**은 결코 결실을 맺지 못했을 수도 있습니다. “저는 몇 개의 스타트업을 매각하고 다음 행보를 알아보기 위해 MIT Sloan 대학원 프로그램에 참여했습니다.”라고 그는 말합니다. 10년에 걸친 오랜 시간과 스타트업의 희생 끝에 그는 아내에게 창업 여정이 끝났다고 확신했습니다. 그러다가 MIT에 입학한 지 불과 몇 달 만에 [Brian Halligan](https://www.linkedin.com/in/brianhalligan/?ref=review.firstround.com)을 만났습니다.\n특정 회사 아이디어에 대한 명확한 경로는 없었지만 Shah와 Halligan은 스타트업, 기술 및 중소기업에 대한 열정에서 많은 공통점을 찾았습니다. Shah는 “우리는 아이디어를 만들기 전에 공동 창업자로 함께 모였고, 스타트업이 한 번 더 남았다고 아내를 설득했습니다.”라고 말했습니다.\n그 마지막 타석은 선수들이 꿈꾸는 그랜드슬램으로 바뀌었다. 15년이 지난 후, 회사는 [연간 매출 10억 달러, 유료 고객 100,000명](https://www.hubspot.com/company-news/hubspot-surpasses-100000-customers-and-1-billion-in-annual-recurring-revenue?ref=review.firstround.com)을 돌파했습니다. 두 사람은 Shah가 CTO 의장을 맡고 Halligan이 CEO를 맡는 등 로켓 성장을 통해 함께 뭉쳤습니다(그가 2021년에 최근 [사임](https://www.hubspot.com/company-news/yamini-rangan-ceo-brian-halligan-executive-chairman?ref=review.firstround.com)하기 전까지).\n\"새로운 것을 시작하는\" 일에 대한 열의가 있는 반복 창업자에게는 Shah가 말했듯이 15년이 지난 지금 HubSpot에서 5,000명의 직원과 함께 더 나은 시간을 보내고 있다고는 기대하지 않을 수도 있습니다. \"초창기 시절은 재미있을 수 있습니다. 당신은 매우 민첩하고 신속하게 실행할 수 있습니다. 하지만 규모를 확장하고 어른들의 식탁에 있다는 것에 대해 할 말이 있습니다. 당신은 아이디어에 맞설 수 있는 돈, 사람, 재능을 가지고 있습니다. 10명의 허술한 스타트업에서는 할 수 없는 방식입니다.\"라고 Shah는 말합니다.\n이 독점 인터뷰에서 Shah는 HubSpot을 구축한 15년의 여정을 추적하고 공동 창립자 선택, 역할 설계 및 초기 팀 참여부터 회사 성장에 따른 피드백 받기 및 확장 가능한 문화 조성에 이르기까지 창립자가 직면하는 5가지 회사 구축 초석을 강조하고 자신의 조언을 공유합니다. 뛰어 들어 봅시다.\n## **초석 #1: 공동 창업자 선택 — 전략적으로 시작하여 성공을 거두도록 하세요.**\n[공동 창립자 선택](https://review.firstround.com/Looking-for-Love-in-All-The-Wrong-Places-How-to-Find-a-Co-Founder/)과 관련하여 Shah는 명백한 실수처럼 보이지만 창립 팀이 계속해서 실수하는 것을 목격합니다. \"사람들은 아이디어를 평가하고 함께 맥주를 마시러 갈 수도 있지만, 이 사람과 함께 시간을 보내는 것이 즐거운지 여부를 실제로 질문해야 합니다.\"라고 그는 말합니다.\nMIT에 있는 동안 미래의 HubSpot 공동 창립자는 공동 창립자의 적합성을 평가하는 데 매우 체계적이었습니다. \"만난 후 Brian과 저는 언젠가 함께 회사를 시작하고 싶다는 것을 알았습니다. 그래서 프로젝트가 있는 대학원 프로그램의 모든 수업에서 우리는 의도적으로 같은 팀에 속하게 되었습니다.\"라고 Shah는 말합니다. \"한 단계 더 나아가서 우리는 모든 프로젝트가 HubSpot이라고 불리는 이 스타트업과 연결될 수 있도록 했습니다. 그것은 한 번에 회사가 아니었습니다. 단지 끊임없이 변화하는 아이디어였습니다. 목표는 한 번에 8시간 동안 이 사람과 함께 일하는 것이 어떨지 시뮬레이션하는 것이었습니다.\"\n**개인적인 관계에서는 평생의 약속을 하기 전에 오랜 시간 동안 데이트를 하는 경우가 많습니다. 그러나 공동 창업자의 경우 사람들은 잠재적인 파트너를 알아가는 데 그다지 신중하지 않습니다. 학업 환경은 잠재적인 공동 창업자를 알아가는 데 유용한 도구이지만 Shah는 몇 가지 다른 방법을 설명합니다. \"온라인 수업을 듣거나 함께 작업할 단기 프로젝트를 찾으세요. 서로를 움직이는 요소를 이해하는 데 도움이 되는 작은 일입니다.\"라고 그는 말합니다.\n### 두 개의 겹치는 원이 아닌 벤다이어그램을 찾으세요.**\n또 다른 일반적인 트립 와이어? 공동 창업자 클론을 찾고 있습니다. \"우리는 우리와 가장 비슷한 사람들에게 매력을 느끼지만 서로 다른 기술을 갖고 있다는 것이 중요합니다. Brian의 배경은 영업 및 마케팅 분야였고 저는 제품 및 엔지니어링 조직에서 자랐습니다.\"라고 Shah는 말합니다. 즉, 공통 가치와 작업 패턴이 핵심입니다.\n- **배움에 대한 열정: **“오늘까지 우리는 새벽 1시나 2시에 서로에게 새 책 추천 이메일을 보낼 것입니다. (그리고 우리 둘 다 올빼미족입니다. 그렇지 않았다면 관계가 발전했을지 모르겠습니다)",
    "source": "review.firstround.com",
    "sourceUrl": "https://review.firstround.com/the-company-building-cornerstones-every-founder-needs-to-focus-on-advice-from-hubspots-dharmesh-shah",
    "category": "AI"
  },
  {
    "title": "Unity의 Mono 문제: 왜 당신의 C# 코드는 기대보다 느리게 실행되는가",
    "content": "# Unity의 모노 문제: C# 코드가 예상보다 느리게 실행되는 이유\n게시일: 2025년 12월 27일\r[\r*\r](/blog/mono-vs-dot-net-in-unity/img/MonoVsDotNet-thn.551.jpg)\r작성자:\r마렉 파이저 *\r*10분* 읽기\rUnity의 Mono 런타임에서 C# 코드 실행은 오늘날의 표준에 비해 느립니다. 예상보다 훨씬 느립니다! 우리 게임은 Unity의 Mono에 비해 최신 .NET에서 2~3배 더 빠르게 실행되며, 몇 가지 소규모 벤치마크에서 최대 15배의 속도 향상을 측정했습니다. 저는 무슨 일이 일어나고 있는지 조사하는 데 시간을 보냈으며 이 기사에서는 제가 발견한 내용과 왜 모두가 Unity의 .NET 현대화가 가능한 한 빨리 프로덕션 준비가 되기를 원하는지 설명하겠습니다.\n## 우리는 어떻게 여기까지 왔는가\nUnity는 Mono 프레임워크를 사용하여 C# 프로그램을 실행하며 2006년에는 .NET의 유일하게 실행 가능한 다중 플랫폼 구현 중 하나였습니다.\rMono는 또한 오픈 소스이므로 Unity가 게임 개발에 더 적합하도록 몇 가지 조정을 수행할 수 있습니다.\r흥미로운 반전은 약 10년 후에 일어났습니다.\r2014년에 Microsoft는 .NET(특히 그해 후반에 .NET Core) 오픈 소스를 시작했으며 2016년 6월에 .NET Core 1.0이 공식 크로스 플랫폼 지원과 함께 출시되었습니다.\r그 이후로 .NET 생태계는 추진력을 얻었으며 Roslyn 컴파일러 플랫폼, 새로운 JIT(Just-In-Time 컴파일러), 성능 개선, 더 많은 기능 등을 포함하여 많은 개선이 이루어졌습니다.\r2018년에 Unity 엔지니어들은 .NET 프로그램을 실행하는 구성 요소인 CLR(공용 언어 런타임)의 다중 플랫폼 버전인 .NET CoreCLR로 엔진을 포팅하는 작업을 진행 중이라고 논의했습니다.\r이 프로젝트의 주요 동기는 성능과 융합이었습니다.\r그들의 게시물에서 그들은 이렇게 말했습니다.\r**...CoreCLR은 Unity 게임 개발자에게 매우 유용할 수 있습니다. 이는 일부 워크로드에서 Mono 런타임에 비해 때로는 최대 10배까지 2배~5배 정도 성능이 크게 향상되기 때문입니다!\r안타깝게도 지금은 2025년 말인데 여전히 CoreCLR에서 게임을 실행할 수 없습니다.\r## 성능 격차\nMono와 .NET 사이의 성능 차이에 대해서는 많이 듣지 못합니다. 아마도 최신 .NET에서는 Unity용으로 작성된 게임을 실행할 수 없기 때문일 것입니다.\r하지만 Unity에 직접적으로 의존하지 않는 코드와 직접 비교할 수는 있습니다.\r우리 게임은 독특한 아키텍처를 가지고 있습니다. 게임 시뮬레이션 코드(비즈니스 로직)를 렌더링과 엄격하게 분리합니다.\r시뮬레이션 코드는 Unity 라이브러리에 의존하지 않으며 모든 .NET 버전에서 컴파일하고 실행할 수 있습니다.\r어느 날 지도 생성 문제를 디버깅하고 있었는데 게임을 시작하는 데 2분 이상이 걸리기 때문에 시간이 많이 걸렸습니다.\r디버깅 속도를 높이기 위해 Unity에서 게임을 시작하기 전에 새 DLL을 크런치하고 도메인을 다시 로드하는 데 15초 이상이 걸리고 내가 신경 쓰지 않았던 렌더링 항목도 초기화하므로 처리 시간을 줄이기 위해 단위 테스트를 작성했습니다.\r테스트를 실행해보니 40초만에 끝났습니다.\r3배 이상 빨라진 것에 상당히 놀랐고, 그래서 더 깊이 파고들기 시작했습니다.\r간단히 말해서, 그림 1은 Mono에서 실행되는 Unity에서 게임을 실행하는 것과 .NET에서 실행하는 단위 테스트 간의 차이점을 보여주는 프로파일러의 추적을 보여줍니다.\r*표시된 모든 벤치마크는 Unity 6.0 또는 .NET 10을 사용하고 있습니다.*\r- *디버그 모드에서 컴파일된 Unity 편집기: 100초.\n- 디버그 모드에서 컴파일된 .NET 단위 테스트: 38초.\n그림 1: Unity 및 .NET, 디버그 모드에서 게임 시작 추적.\n따라서 벤치마크에서는 저장 파일 로드, 맵 생성 및 시뮬레이션 초기화에 Unity/Mono에서는 100초가 걸리지만 .NET에서는 38초만 걸리는 것으로 나타났습니다.\r이 결과만으로도 이미 눈살을 찌푸릴 수 있으며 디버깅 및 테스트에 접근하는 방법에 대한 실질적인 결과를 가져올 수 있습니다.\r또한 저는 Unity를 사용한 경험을 통해 (Unity 편집기 없이) 독립 실행형 실행 파일로 실행되는 릴리스 모드가 훨씬 빠르다는 것을 알고 있으므로 다음에 이를 테스트하기로 결정했습니다.\r## .NET과 독립 실행형 릴리스 모드의 Mono 비교\n디버그 모드 속도 저하가 크지는 않지만 최적화되지 않은 C++ 코드도 느릴 수 있습니다.\rMono와 .NET 간의 실제 성능 차이를 비교하기 위해 위와 동일한 벤치마크를 실행하지만 릴리스 모드에서 독립 실행형 실행 파일을 실행해 보겠습니다.\r첫 번째: 유니티. 최적화된 실행 파일을 얻고 직접 실행하기 위해 배포 스크립트를 실행했습니다.\r당연히 최적화된 독립 실행형 실행 파일이 Unity 편집기보다 3배 이상 빠른 속도로 큰 차이를 보이고 있습니다.\r다음으로, 릴리스 모드에서 .NET에서 동일한 코드를 실행합니다.\r그림 2는 결과를 보여줍니다.\r- 릴리스 모드에서 컴파일된 독립 실행형 실행 파일인 Mono: 30초.\n- 릴리스 모드에서 컴파일된 .NET 단위 테스트: 12초.\n그림 2: g의 흔적",
    "source": "marekfiser.com",
    "sourceUrl": "https://marekfiser.com/blog/mono-vs-dot-net-in-unity/",
    "category": "AI"
  },
  {
    "title": "자바스크립트를 HTML만으로 대체하기",
    "content": "# JS를 HTML로만 대체\n작성자: [Aaron T. Grogg](https://aarontgrogg.com), 2025년 12월 27일 게시\n수년 동안 JavaScript는 웹의 주력 제품이었습니다. HTML과 CSS만으로는 할 수 없는 작업을 수행하고 싶다면 일반적으로 JS를 사용하여 수행할 수 있는 방법을 찾을 수 있습니다.**아주 훌륭합니다! JS는 사용자 경험을 발전시키는 데 도움을 주었고 HTML과 CSS를 발전시키는 데 정직하게 도움을 주었습니다!\n그러나 시간이 흐르고 HTML 및 CSS 메서드가 [견인력을 얻으면서](https://webstatus.dev/?q=%28group%3Ahtml+OR+css%29&sort=name_asc), 우리는 편안함을 느끼는 기존 JS 메서드를 JS가 덜 필요한 새로운 메서드로 교체하기 시작해야 합니다.\n*JS에 반대되는 것은 없습니다***. 하지만 아코디언이나 오프스크린 탐색 메뉴를 설정하고 관리하는 것보다 더 나은 일이 있습니다... 또한 JS는 다운로드, 압축 해제, 평가, 처리해야 하며 기능을 모니터링하고 유지하기 위해 종종 메모리를 소비합니다. JS 기능을 기본 HTML 또는 CSS로 *인계*할 수 있다면 사용자는 더 적은 양의 항목을 다운로드할 수 있으며 나머지 JS는 HTML 및 CSS가 (아직) 처리할 수 없는 더 중요한 작업에 주의를 기울일 수 있습니다.\n다음은 몇 가지 예입니다. 추가하고 싶은 것이 있나요?\n## 목차:\n- [아코디언 / 콘텐츠 패널 확장](#accordions-expanding-content-panels)\n- [자동 필터 제안 드롭다운을 사용한 입력](#input-with-autofilter-suggestions-dropdown)\n- [모달 / 팝오버](#modals-popovers)\n- [오프스크린 탐색/콘텐츠](#offscreen-nav-content)\n## 아코디언 / 콘텐츠 패널 확장\n### 설명:\n'세부정보' 및 '요약' HTML 요소는 일반적인 JS 아코디언에 대한 HTML 전용 대체 기능을 제공합니다.***\nCopePen: [아코디언 / 콘텐츠 확장](https://codepen.io/aarontgrogg/pen/GgoOqVX)\n### 사용 사례:\n- 콘텐츠 숨기기/보이기\n- 콘텐츠 섹션 확장\n### 기본 구현:\n``html\n<상세>\n<summary>처음에는 닫혀 있지만 열려면 클릭하세요</summary>\n내용은 처음에는 숨겨져 있지만 요약을 클릭하면 표시될 수 있습니다.\n</세부사항>\n````\n기본 모양을 \"open\"으로 설정하려면 `open` 속성을 추가하세요.\n``html\n<세부사항 공개>\n<summary>처음에는 열리지만 클릭하면 닫힙니다.</summary>\n처음에는 콘텐츠가 표시되지만 요약을 클릭하면 숨길 수 있습니다.\n</세부사항>\n````\n한 번에 하나의 열린 패널만 제한하려면 관련된 모든 '세부정보'(예: 라디오 버튼)에 동일한 '이름' 속성을 사용하세요.\n``html\n<상세 이름=\"foo\" 열기>\n<summary>처음에는 열려 있으며 다른 항목을 클릭하면 닫힙니다.</summary>\n콘텐츠는 처음에 표시되지만 요약을 클릭하면 숨길 수 있습니다. 한 번에 하나의 패널만 열 수 있습니다.\n</세부사항>\n<상세 이름=\"foo\">\n<summary>처음에는 닫혔습니다. 클릭하면 이 항목이 열리고 다른 항목도 닫힙니다.</summary>\n콘텐츠는 처음에는 숨겨져 있지만 요약을 클릭하면 표시될 수 있습니다. 한 번에 하나의 패널만 열 수 있습니다.\n</세부사항>\n<상세 이름=\"foo\">\n<summary>처음에는 닫혔습니다. 클릭하면 이 항목이 열리고 다른 항목도 닫힙니다.</summary>\n콘텐츠는 처음에는 숨겨져 있지만 요약을 클릭하면 표시될 수 있습니다. 한 번에 하나의 패널만 열 수 있습니다.\n</세부사항>\n````\nCSS로 모양을 맞춤설정하고 JS를 통해 열기/닫기를 실행할 수도 있습니다.\n이전에 게시된 \"[<세부 사항>을 사랑합니다](https://www.htmhell.dev/adventcalendar/2025/23)\"에서 `세부 사항` 요소에 대해 자세히 알아보세요.\n### 리소스:\n- [MDN `세부정보` 페이지](https://developer.mozilla.org/en-US/docs/Web/HTML/Element/details)\n- [<세부정보> 요소](https://www.codewithshripal.com/playground/html/details-element)\n### 브라우저 호환성:\n- [MDN `세부정보` 브라우저 호환성](https://developer.mozilla.org/en-US/docs/Web/HTML/Element/details#browser_compatibility)\n## 자동 필터 제안 드롭다운을 사용한 입력\n### 설명:\nHTML `input` 요소와 `datalist` 요소를 결합하면 입력 시 자동 필터링되는 옵션 드롭다운을 만들 수 있습니다.\n![HTML 및 자동 필터 드롭다운 제공 예시](input-with-datalist.gif)\nCodePen: [자동 필터 제안 드롭다운을 통한 입력](https://codepen.io/aarontgrogg/pen/yyePPor)\n### 사용 사례:\n- 사이트 검색\n- 상품 검색 또는 필터링\n- 데이터 목록 필터링\n### 기본 구현:\n``html\n<label for=\"browser\">브라우저</label>\n<입력 유형=\"텍스트\"\n목록=\"브라우저\"\nid=\"브라우저\" 이름=\"브라우저\"\n크기=\"50\"\n자동완성=\"꺼짐\" />\n<데이터 목록 id=\"브라우저\">\n<옵션 값=\"Arc\"></option>\n<옵션 값=\"용감한\"></option>\n<옵션 값=\"크롬\"></option>\n<옵션 값=\"DuckDuckGo\"></option>\n<옵션 값=\"Firefox\"></option>\n<옵션 값=\"Microsoft Edge\"></option>\n<옵션 값=\"오페라\"></option>\n<옵션 값=\"사파리\"></option>\n<옵션 값=\"토르\"></option>\n<옵션 값=\"비발디\"></option></op",
    "source": "htmhell.dev",
    "sourceUrl": "https://www.htmhell.dev/adventcalendar/2025/27/",
    "category": "AI"
  },
  {
    "title": "AI를 비용 낭비 없이 운영하기 위한 실전 통합 모범 사례",
    "content": "# 부트스트래퍼를 위한 AI 모범 사례(실제로 비용 절감)\n[2025년 11월 28일 2025년 11월 27일](https://thebootstrappedfounder.com/ai-best-practices-for-bootstrappers-that-actually-save-you-money/) ~ [Arvid Kahl](https://thebootstrappedfounder.com/author/arvid53d1a2b65a/) \n읽기 시간: 19분\n저는 최근에 사용자를 위해 많은 백그라운드 데이터 추출 및 분석을 수행하는 팟캐스트 데이터베이스 시스템인 Podscan을 구축하면서 뭔가를 깨달았습니다. 나는 많은 사람들이 완전히 알지 못하는 몇 가지 AI 통합 모범 사례를 우연히 발견했습니다. 그래서 오늘 저는 유용할 뿐만 아니라 LLM 및 AI 플랫폼을 사용하여 미션 크리티컬 데이터 처리를 유지 관리하고 운영하는 데 필수적인 개념에 대해 자세히 알아보고 싶습니다.\n*\n스폰서인 [Paddle.com](http://paddle.com/)이 전하는 짧은 한마디입니다. 나는 모든 소프트웨어 프로젝트에 대해 기록상의 판매자로 Paddle을 사용합니다. 그들은 모든 세금, 통화, 거부된 거래 추적 및 업데이트된 신용 카드를 처리하므로 저는 경쟁업체(은행 및 금융 규제 기관이 아닌)와의 거래에 집중할 수 있습니다. 제품을 직접 제작하고 싶다면 결제 서비스 제공업체인 [Paddle.com](http://paddle.com/)을 확인하세요.*\n나는 Greg Eisenberg의 트윗을 통해 AI 관행을 떠올렸습니다. 그는 모든 새로운 AI 도구와 모델을 100% 따라잡는 것은 불가능하며 오늘 작동하는 것이 내일 실패할 수도 있다고 말했습니다.\n그 관찰은 나의 가장 큰 배움이었고, 나는 그것을 단순한 프로세스가 아닌 구현 스타일로 전환했습니다. 내가 만든 것을 공유하겠습니다.\n## 마이그레이션 패턴\nAI 호출을 사용할 때마다(로컬 모델이든 OpenAI, Anthropic, Google Gemini의 클라우드 모델이든) 항상 코드에 마이그레이션 패턴이 구현되어 있습니다.\n모든 API 호출을 서비스로 추출합니다. 이러한 서비스는 각 API 호출에 대해 원하는 특정 프롬프트 외에도 모든 연결, 모든 프롬프트 마사지 및 프롬프트 구성을 내부적으로 처리합니다. 그리고 이러한 서비스는 항상 제가 영구 마이그레이션 가능한 상태라고 부르는 상태에서 작동합니다. 즉, 그들은 항상 최신 버전과 최신 모델을 사용할 수 있으며, 최소한 제가 이전에 사용했던 프롬프트 버전과 모델을 사용할 수 있습니다.\n오랫동안 GPT 4.1을 사용한 후 몇 달 전 GPT-5 구현을 시작했을 때 이것이 필요하다는 것을 깨달았습니다. 첫 번째 실험은 끔찍했습니다. 많은 API 변경이 발생했으며 프롬프트의 미묘한 부분이 이전만큼 잘 작동하지 않았습니다. 4.1용으로 완벽하게 제작된 프롬프트(최소 반년 동안 실행됨)는 GPT-5에서 재사용할 수 없었습니다.\n자세한 내용은 다음과 같습니다. GPT 4.1에 대한 내 프롬프트에는 JSON 형식 기대치가 있었습니다. 이는 OpenAI API의 일부로 \"이것이 JSON으로 다시 돌아오길 원합니다\"라고 말하면 JSON을 얻을 수 있습니다. 프롬프트의 모든 내용은 해당 JSON을 가장 효과적으로 생성하는 것을 목표로 했습니다.\n해당 호출을 GPT-5로 마이그레이션하면 여전히 JSON 데이터가 생성되지만 특정 키는 삭제됩니다. 해당 프롬프트의 4.1 버전만큼 안정적이지 않았습니다. 그 이유를 알아내려고 노력한 결과, GPT-5는 구조화된 JSON 스키마를 사용하는 데 더 중점을 두고 있다는 것이 밝혀졌습니다. 단순히 \"이것은 JSON이 될 것입니다\"라고 말하는 대신 \"이것이 출력할 정확한 JSON입니다\"라고 말하고 키와 잠재적인 값을 정의합니다. 그런 다음 프롬프트에서 이러한 항목이 어떻게 채워지는지 설명합니다. 근본적으로 이전과 유사하지만 기술적으로는 다릅니다.\n나는 새 모델을 사용하여 새 실험을 배포하고 동일한 데이터가 생성되기를 바라는 것이 아니었기 때문에 다음과 같은 마이그레이션 전략을 생각해 냈습니다. 특정 기간 또는 테스트 및 준비 환경에 대해 \"이전 모델에는 이전 프롬프트를 사용한 다음 새 모델에는 새 프롬프트를 사용하세요.\"라고 말할 수 있습니다. 완전히 다른 데이터 구조와 완전히 다른 API 호출일 수도 있습니다. OpenAI는 사람들이 채팅 스타일 API에서 응답 스타일 API로 이동하기를 원하기 때문입니다.\n저는 두 결과를 모두 기록하여 큰 차이점이 있는지 확인하고, 차이가 있는 경우 시스템에서 차이점을 알려주고 디버깅을 위해 액세스할 수 있도록 했습니다. 그런 다음 호출된 함수나 프로시저에 대해 새 데이터로 응답합니다.\n이 이중 접근 방식을 실행하는 서버의 경우 비용이 두 배 증가했습니다. 하지만 이전 모델의 기능과 새 모델의 기능, 그리고 프롬프트 간의 차이가 데이터의 품질, 기대성 및 신뢰성에 어떤 영향을 미치는지 확인할 수 있었습니다.\n나",
    "source": "thebootstrappedfounder.com",
    "sourceUrl": "https://thebootstrappedfounder.com/ai-best-practices-for-bootstrappers-that-actually-save-you-money/",
    "category": "AI"
  },
  {
    "title": "ScratchPixel - 컴퓨터 그래픽스를 기초부터 무료로 배우기",
    "content": "컴퓨터 그래픽을 처음부터 무료로 배우세요.\n평소 사랑받는 레슨. 블로그, 일부 개인 강좌, 그리고 다가오는 도서 프로젝트!\n### 블로그\n## 화난 괴상한 사람들을 위해\n우리는 3D 프로그래밍과 관련된 주제는 물론 Scratchapixel에서 수행하는 작업과 연결되는 AI 및 교육과 같은 더 광범위한 주제에 대해 이야기할 수 있는 공간을 놓쳤습니다.\n### 강좌\n## Vulkan 배우기\n이것은 우리가 시작한 새로운 프로젝트입니다. 현재 우리는 특히 Vulkan API 학습을 목표로 하는 과정을 제공하는 데 중점을 두고 있습니다. 관심 있는? 더 읽어보세요…\n### 예약\n## 스크래치픽셀을 해변으로 가져가세요\n우리는 컴퓨터 그래픽에 대한 물리적 참조를 유지할 수 있도록 책을 집필 중입니다. 인터넷이 연결되지 않는 무인도에 갇혀 있는 경우 매우 유용합니다. 더 읽어보세요...\n3D 렌더링의 기초\n이 강의는 초보자에게 친숙한 순서로 3D 렌더링 개념을 소개하도록 구성되어 있습니다. 대부분의 리소스와는 달리 이론을 살펴보기 전에 실습 결과부터 시작합니다.\n3D 컴퓨터 그래픽 입문서: 광선 추적을 예로 들어\n시작하려면 무엇이 필요합니까?\n당신의 출발점!\n3D 장면의 이미지 렌더링\n3D 포인트의 픽셀 좌표 계산\n핀홀 카메라 모델\n래스터화\n원근 및 직교 투영 행렬\n광선 추적 렌더링 기술 개요\n광선 추적을 사용하여 카메라 광선 생성\n최소 광선 추적기\n광선 추적: 삼각형 렌더링\n다각형 메쉬 소개\n다각형 메시의 광선 추적\n행렬을 사용하여 객체 변환\n셰이딩 소개\n셰이더 및 BRDF 소개\nBRDF, 선형성 및 노출에 대한 창의적인 탐구\n조명개론\n텍스처링 소개\n가속 구조 소개\n볼륨 렌더링\n컴퓨터 그래픽 수학\n이 섹션에서는 컴퓨터로 이미지와 시뮬레이션을 생성하는 데 사용되는 수학적 이론과 도구를 설명합니다. 이는 출발점으로 사용하기 위한 것이 아니라 다른 섹션의 강의에서 이러한 주제가 언급될 때 참고할 수 있는 참고 자료로 사용됩니다.\n기하학\n역행렬: Gauss-Jordan 방법\n보간\n카메라 배치: LookAt 기능\n음영의 수학\n몬테카를로 방법의 수학적 기초\n실제 몬테카를로 방법\n푸리에 변환 소개\n컴퓨터 그래픽 보석\n광범위한 카테고리에 꼭 들어맞을 필요는 없지만 그럼에도 불구하고 흥미롭고 멋진 특정 주제에 대한 강의 모음입니다.\n흑체\n기하학\n컴퓨터 그래픽에서 모양을 정의하는 방법.\n베지어 곡선 및 표면\n디지털 이미징\n디스크에서 이미지 저장 및 읽기, 이미지 파일 형식, 색상 공간, 색상 관리 및 기본 이미지 처리.\n빛, 색상 및 색 공간 소개\n디지털 이미지: 파일에서 화면으로\n간단한 이미지 조작\n가상 세계의 절차적 생성\n자연 현상의 절차적 시뮬레이션.\n가치 노이즈와 절차적 패턴\n펄린 노이즈\n하늘의 색상 시뮬레이션\n툴링\n일반적으로 3D 도구를 개발하고 3D 콘텐츠와 상호 작용하는 데 유용한 다양한 기술입니다.\n윈도잉\nOBJ 파일 형식\n카메라 내비게이션 컨트롤",
    "source": "scratchapixel.com",
    "sourceUrl": "https://www.scratchapixel.com",
    "category": "AI"
  },
  {
    "title": "Show GN: aipack: BGE-M3 기반의 중립적 시맨틱 청킹된 파킷 생성기 + MCP 서버",
    "content": "# AI 팩 - BGE-M3를 사용한 의미적 청킹\n[](#ai-pack---bge-m3을 사용한 의미적 청킹)\n[![라이선스](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)\n[![Python](https://img.shields.io/badge/Python-3.11%2B-blue.svg)](https://www.python.org/)\n[![MCP](https://img.shields.io/badge/MCP-Compatible-green.svg)](https://modelcontextprotocol.io/)\n[![GitHub 후원자](https://img.shields.io/github/sponsors/rkttu)](https://github.com/sponsors/rkttu)\nBGE-M3 임베딩 모델을 사용하는 의미론적 청킹 도구.**\n다양한 형식의 문서를 Markdown으로 변환하고 의미론적 의미에 따라 분할하며 제목 계층 구조를 유지합니다.\n## 프로젝트 컨셉\n[](#프로젝트-개념)\n> \n다양한 RAG 확장을 위한 Basecamp + 간단한 미리보기\naipack은 벡터 RAG의 기반을 제공하는 동시에 그래프 RAG 및 하이브리드 RAG와 같은 확장의 시작점 역할을 합니다.\n- Basecamp 역할**: Parquet 파일은 Milvus, Qdrant, Memgraph와 같은 다양한 백엔드로 쉽게 마이그레이션할 수 있는 \"확장 허브\" 역할을 합니다.\n- **미리보기 역할**: MCP 서버는 전체 RAG 애플리케이션을 구축하기 전에 테스트/프로토타입을 지원합니다.\n- **데이터베이스 중립성**: 특정 벡터 DB에 얽매이지 않으며, Parquet 기반의 유연한 확장\n- **증분 업데이트**: 내장 모델 또는 소스 콘텐츠의 변경에 유연하게 대응\n## 아키텍처\n[](#아키텍처)\n````\n흐름도 TD\n하위 그래프 \"입력\"\nA[input_docs/<br/>다양한 형식의 문서]\n끝\n하위 그래프 \"전처리\"\nB[02_prepare_content.py<br/>메타데이터 추출<br/>마크다운 변환]\n끝\n하위 그래프 \"청킹\"\nC[03_semantic_chunking.py<br/>의미적 청킹<br/>임베딩 생성]\n끝\n하위 그래프 \"스토리지\"\nD[chunked_data/<br/>마루 파일]\n끝\n하위 그래프 \"벡터 DB\"\nE[04_build_Vector_db.py<br/>sqlite-vec 빌드]\n끝\n하위 그래프 \"서빙\"\nF[05_mcp_server.py<br/>MCP 서버<br/>벡터 검색 + 순위 재지정]\n끝\nA --> B\n비 --> 씨\nC --> D\nD --> E\n이자 --> 에프\n스타일 A 채우기:#e1f5fe\n스타일 B 채우기:#f3e5f5\n스타일 C 채우기:#e8f5e8\n스타일 D 채우기:#fff3e0\n스타일 E 채우기:#fce4ec\n스타일 F 채우기:#e0f2f1\n````\n로드 중\n각 단계의 중간 결과는 파켓 파일로 저장되어 다양한 실험과 외부 시스템 마이그레이션이 용이합니다.\n## 기능\n[](#기능)\n- **다양한 문서 형식 지원**: Microsoft markitdown 사용\nOffice 문서: Word(.docx), Excel(.xlsx), PowerPoint(.pptx)\n- PDF, HTML, XML, JSON, CSV\n- 이미지(EXIF/OCR), 오디오(음성인식), 비디오(자막 추출)\n- 코드 파일, Jupyter Notebook, ZIP 아카이브\n- **Microsoft Foundry 서비스 통합**(선택 사항)\nDocument Intelligence: 스캔한 PDF 및 이미지에 대한 향상된 OCR\n- Azure OpenAI(GPT-4o): 이미지 콘텐츠 이해\n- 구성된 서비스만 자동으로 활성화됩니다.\n- **의미적 청킹**: 의미적 유사성을 기반으로 한 청크 분할\n- **마크다운 구조 보존**: 제목 수준 및 섹션 경로와 같은 계층적 정보를 유지합니다.\n- **다국어 지원**: BGE-M3는 100개 이상의 언어를 지원합니다.\n- **증분 업데이트**: 콘텐츠 해시를 기반으로 변경 감지\n- **zstd 압축**: 효율적인 쪽모이 세공 마루 보관\n- **BGE Reranker**: 향상된 검색 결과 정확성을 위한 재순위 지원\n- **CPU 친화적**: GPU 없이 작동(가능한 경우 자동으로 GPU 사용)\n## 지원되는 파일 형식\n[](#지원되는 파일 형식)\n카테고리\n확장\n사무실 문서\n`.docx`, `.doc`, `.xlsx`, `.xls`, `.pptx`, `.ppt`\nPDF/웹\n`.pdf`, `.html`, `.htm`, `.xml`, `.json`, `.csv`\n마크다운/텍스트\n`.md`, `.markdown`, `.txt`, `.rst`\n이미지(EXIF/OCR)\n`.jpg`, `.jpeg`, `.png`, `.gif`, `.bmp`, `.webp`, `.tiff`\n오디오(음성 인식)\n`.mp3`, `.wav`, `.m4a`, `.ogg`, `.flac`\n영상(자막 추출)\n`.mp4`, `.mkv`, `.avi`, `.mov`, `.webm`\n코드/기타\n`.py`, `.js`, `.ts`, `.java`, `.c`, `.cpp`, `.ipynb`, `.zip`\n## 모듈 구조\n[](#모듈 구조)\n모듈\n설명\n`01_download_model.py`\nBGE-M3 임베딩 모델 및 리랭커 모델 다운로드\n`02_prepare_content.py`\n메타데이터 추출 및 YAML 머리말 생성\n`03_semantic_chunking.py`\n의미론적 청킹 및 쪽모이 세공 마루 저장\n`04_빌드_벡터_db.py`\nsqlite-vec 벡터 DB 구축 및 검색\n`05_mcp_server.py`\nMCP 서버(stdio/SSE 모드 지원)\n## 설치\n[](#설치)\n### UV 설치\n[](#installing-uv)\nuv는 빠른 Python 패키지 관리자입니다. 공식 저장소에서 설치하세요:\n**윈도우(파워셸):**\n````\npowershell -c \"irm https://astral.sh/uv/install.ps1 | iex\"\n````\n**리눅스/맥OS:**\n````\n컬 -LsSf https://astral.sh/uv/install.sh | 쉬\n````\n또는 pip를 통해 설치하십시오.\n````\n핍 설치 UV\n````\n더 설치하려면",
    "source": "github.com",
    "sourceUrl": "https://github.com/rkttu/aipack",
    "category": "AI"
  },
  {
    "title": "Perfetto - 시스템 프로파일링, 앱 트레이싱 및 트레이스 분석 도구",
    "content": "# Perfetto - 시스템 프로파일링, 앱 추적 및 추적 분석\n[](#perfetto---시스템 프로파일링-앱 추적 및 추적 분석)\nPerfetto는 SDK, 데몬 및 도구의 오픈 소스 제품군입니다.\n**추적**을 통해 개발자가 복잡한 시스템의 동작을 이해하고\n클라이언트 및 임베디드 시스템의 기능 및 성능 문제의 근본 원인.\n이는 프로덕션 수준의 도구로서 기본 추적 시스템입니다.\n**Android 운영체제** 및 **Chromium 브라우저**.\n[![](/google/perfetto/raw/main/docs/images/perfetto-stack.svg)](/google/perfetto/blob/main/docs/images/perfetto-stack.svg)\n## 핵심 구성 요소\n[](#핵심 구성 요소)\nPerfetto는 단일 도구가 아니라 작동하는 구성 요소 모음입니다.\n함께:\n- **고성능 추적 데몬:**\n단일 시스템의 많은 프로세스를 통합된 추적 파일로 만듭니다.\n- **낮은 오버헤드 추적 SDK:** 직접 추적용 C++17 라이브러리\n사용자 공간 간 타이밍 및 상태 변경 추적\n신청.\n- **광범위한 OS 수준 프로브:** Android에서 시스템 전체 컨텍스트를 캡처합니다.\n및 Linux(예: 스케줄링 상태, CPU 주파수, 메모리 프로파일링,\n콜스택 샘플링).\n- **브라우저 기반 UI:** 시각화 및 탐색을 위한 강력하고 완전한 로컬 UI\n타임라인의 대규모 다중 GB 추적. 모든 주요 브라우저에서 작동하며 다음이 필요합니다.\n설치가 필요 없으며 다른 도구에서 추적을 열 수 있습니다.\n- **SQL 기반 분석 라이브러리:** 다음을 수행할 수 있는 강력한 엔진입니다.\n분석 및 추출을 자동화하기 위해 SQL을 사용하여 프로그래밍 방식으로 추적 쿼리\n사용자 정의 측정항목.\n## 왜 Perfetto를 사용해야 하나요?\n[](#perfetto를 사용하는 이유)\nPerfetto는 다양한 분야에 대한 다재다능하고 강력한 추적 시스템으로 설계되었습니다.\n다양한 사용 사례.\n- **Android 앱 및 플랫폼 개발자의 경우:** 디버그 및 근본 원인 기능 및\n느린 시작, 프레임 손실(버벅거림), 애니메이션과 같은 성능 문제\n결함, 메모리 부족, ANR 등이 있습니다. Java/Kotlin 및 네이티브 C++ 모두 프로파일링\n힙 덤프 및 프로필의 메모리 사용량.\n- **C/C++ 개발자(Linux, macOS, Windows)의 경우:**\n[Tracing SDK](/google/perfetto/blob/main/docs/instrumentation/tracing-sdk.md)를 사용하여\n실행 흐름을 이해하기 위한 사용자 정의 추적 지점이 있는 애플리케이션\n성능 병목 현상을 해결하고 복잡한 동작을 디버깅합니다. Linux에서는 다음을 수행할 수도 있습니다.\n자세한 CPU 및 기본 힙 프로파일링을 수행합니다.\n- **Linux 커널 및 시스템 개발자의 경우:** 커널에 대한 깊은 통찰력을 얻으세요.\n행동. Perfetto는 'ftrace'에 대한 효율적인 사용자 공간 데몬 역할을 합니다.\n일정, 시스템 호출, 인터럽트 및 사용자 정의 커널을 시각화할 수 있습니다.\n타임라인의 추적점.\n- **Chromium 개발자의 경우:** Perfetto는 다음을 위한 추적 백엔드입니다.\n'chrome://tracing'. 이를 사용하여 브라우저 V8에서 문제를 디버깅하고 근본 원인을 찾으십시오.\n그리고 깜박임.\n- **성능 엔지니어 및 SRE의 경우:** 다양한 범위의 분석 및 시각화\nPerfetto의 형식뿐만 아니라 프로파일링 및 추적 형식도 가능합니다. 강력한 SQL을 사용하세요\n**Linux 성능**과 같은 도구의 추적을 프로그래밍 방식으로 분석하는 인터페이스\n**macOS Instruments**, **Chrome JSON 추적** 등.\n## 시작하기\n[](#시작하기)\n우리는 귀하에게 올바른 정보를 안내하기 위해 문서를 설계했습니다.\n성과 분석을 처음 접하는 사람이든,\n숙련된 개발자.\n- \n**추적을 처음 사용하시나요?** 추적 및 추적과 같은 개념에 익숙하지 않은 경우\n프로파일링, 여기에서 시작하세요:\n[**Tracing이란 무엇입니까?**](https://perfetto.dev/docs/tracing-101) -\n성과 분석의 세계를 소개합니다.\n- \n**시작할 준비가 되셨나요?** \"시작하기\" 가이드가 주요 진입점입니다.\n모든 사용자에게. 올바른 튜토리얼과 문서를 찾는 데 도움이 될 것입니다.\n귀하의 특정 요구 사항에 맞게:\n[**Perfetto 사용을 시작하려면 어떻게 해야 하나요?**](https://perfetto.dev/docs/getting-started/start-using-perfetto) -\n자신의 역할과 목표(예: Android 앱 개발자,\nC/C++ 개발자 등).\n- \n**전체 개요를 원하시나요?** Perfetto가 무엇인지 포괄적으로 살펴보려면,\n이것이 유용한 이유와 이를 사용하는 사람은 기본 문서 페이지를 참조하세요.\n[**Perfetto 문서 홈**](https://perfetto.dev/docs/)\n## 데비안 배포판\n[](#debian-배포)\nPerfetto의 데비안 배포판에 관심이 있는 사용자를 위한 공식 소스\n진실과 포장 노력이 유지됩니다.\n[Debian Perfetto Salsa 저장소](https://salsa.debian.org/debian/perfetto)\n## 커뮤니티 및 지원\n[](#커뮤니티--지원)\n질문이 있으신가요? 도움이 필요하신가요?\n- **[GitHub 토론](https://github.com/google/perfetto/discussions/categories/q-a):**\nQ&A 및 일반 토론용입니다.\n- **[GitH",
    "source": "github.com",
    "sourceUrl": "https://github.com/google/perfetto",
    "category": "AI"
  },
  {
    "title": "왜 AI 에이전트는 계속 실패하는가 — 문제는 모델이 아니라 ‘세계(World) 설계’다",
    "content": "[\n*\n](https://media2.dev.to/dynamic/image/width=1000,height=420,fit=cover,gravity=auto,format=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2F11n0oz7tusx8gws4y5d9.png)\n[![정 성우](https://media2.dev.to/dynamic/image/width=50,height=50,fit=cover,gravity=auto,format=auto/https%3A%2F%2Fdev-to -uploads.s3.amazonaws.com%2Fuploads%2Fuser%2Fprofile_image%2F2026591%2F149d88af-cf27-46ba-b3b9-ed79d4079a6c.jpg)](/eggp)\n[정성우](/egp)\n게시일: 12월 30일\n# \n세계 중심 에이전트 아키텍처: AI 에이전트가 계속 실패하는 이유(모델의 잘못은 아님)\n[#에이전트](/t/에이전트)\n[#ai](/t/ai)\n[#llm](/t/llm)\n[#아키텍처](/t/architecture)\n# \n[\n](#worldcentric-agent-아키텍처)\n세계 중심 에이전트 아키텍처\n## \n[\n](#결정론적 런타임 및 계층적 지능 조정)\n결정론적 런타임 및 계층적 인텔리전스 오케스트레이션\n---\n## \n[\n](#tldr)\nTL;DR\nAI 에이전트의 실패는 모델이 충분히 똑똑하지 않기 때문이 아닙니다. 그 이유는 **세상은 결코 설계되지 않았기 때문**입니다.\n이 게시물에서는 다음과 같은 패러다임인 **세계 중심 아키텍처**를 소개합니다.\n- 세계는 명시적이고 불변하며 검증 가능합니다.\n- 인텔리전스는 변경을 제안하지만 직접 실행하지는 않습니다.\n- 시스템 안정성은 모델 크기와 무관합니다.\n- 모든 값은 \"왜?\"라고 답할 수 있습니다.\n**\n다른 에이전트 프레임워크 튜토리얼을 기대하신다면 이는 그렇지 않습니다.\n이 게시물은 강력한 모델이 있어도 에이전트 시스템이 구조적으로 실패하는 이유에 대해 설명합니다.\n---\n## \n[\n](#the-problem-nobodys-talking-about)\n아무도 이야기하지 않는 문제\nLLM 기반 에이전트는 놀라운 발전을 이루었습니다. 그러나 그들은 예측 가능한 방식으로 계속 실패하고 있습니다.\n실패 모드\n무슨 일이 일어나는가\n불가능한 작업 루프**\n상담사가 작동하지 않는 작업을 반복적으로 시도합니다.\n**상태 불투명도**\n상태가 언제, 왜 바뀌었는지 아무도 모릅니다.\n**재현불가능성**\n같은 입력, 다른 결과\n**복구할 수 없는 오류**\n롤백할 수 없으며 대안을 시도할 수 없습니다.\n**설명 불가능**\n\"왜 그랬어요?\" → 🤷\n익숙한 것 같나요?\n---\n## \n[\n](#the-오진)\n오진\n업계의 반응은 일관적이었습니다.\n**\n\"모델이 충분히 똑똑하지 않습니다. 더 큰 모델을 사용합시다.\"\n````\n문제 → \"모델이 너무 멍청하다\"\n→ 더 큰 모델 / 더 긴 추론 / 복잡한 계획\n→ 비용 증가 / 복잡성 증가 / 문제 지속\n````\n전체 화면 모드로 전환\n전체 화면 모드 종료\n우리는 질병이 아닌 증상을 치료해 왔습니다.\n---\n## \n[\n](#진짜 문제)\n진짜 문제\n불편한 진실은 다음과 같습니다.\n> \n이러한 실패는 지능 실패가 아닙니다. 그것은 세계 모델링 실패입니다.**\n대부분의 에이전트 아키텍처에서 \"세계\"는 모델의 머리 내부에만 존재합니다.**\n````\n┌─────────────────────────────────────────────────────────┐\n│ 모델의 머리 │\n│ │\n│ ┌───────────────┐ ┌──────────────┐ ┌──────────────┐ │\n│ │ 세계 │ │ 액션 │ │ 상태 │ │\n│ │ 이해 │ │ 선택 │ │ 전환 │ │\n│ └───────────────┘ └──────────────┘ └──────────────┘ │\n│ │\n│ 암시적인 모든 것. 확인할 수 있는 것이 없습니다. │\n└─────────────────────────────────────────────────────────┘\n````\n전체 화면 모드로 전환\n전체 화면 모드 종료\n모델은 다음을 수행해야 합니다.\n- 세상을 이해하다(맥락을 통해)\n- 무엇이 가능한지 알아보세요(추론을 통해)\n- 올바른 행동을 선택하세요(환각 중에)\n- 상태 변화 추적(주의 가중치에서)\n- 실패에 대해 설명하세요(행운을 빕니다)\n비결정적 텍스트 예측자에게는 너무 많은 책임이 있습니다.\n---\n## \n[\n](#the-inversion-worldcentric-design)\n반전: 세계 중심 디자인\n대본을 뒤집으면 어떨까요?\n````\n┌──────────────────────────────────────────────────────────┐\n│ 세계 │\n│ (일등 시민) │\n│ │\n│ ┌─────────────┐ ┌─────────────┐ ┌──────────────┐ │\n│ │ 규칙 │ │ 상태 │ │ 조치 │ │\n│ │ (스키마) │ │ (스냅샷) │ │(가용성)│ │\n│ └─────────────┘ └─────────────┘ └──────────────┘ │\n│ │ │\n│ ▼ │\n│ ┌─────────────────┐ │\n│ │ 지능 │ │\n│ │ (제안자) │ │\n│ └─────────────────┘ │\n│ │\n│ 지능은 외부에 있습니다. 세상은 명백하다. │\n└───────────────────────────────────────────────────────────┘\n````\n전체 화면 모드로 전환\n전체 화면 모드 종료\n주요 변화:**\n- 세계는 모델 **외부**에 존재합니다.\n- 상태는 **명시적이고 불변**입니다.\n- 작업에는 **검증 가능한 가용성**이 있습니다.\n- 지능이 **제안**하지만 실행하지 않음\n- 모든 것은 **그 자체로 설명**될 수 있습니다\n---\n## \n[\n](#the-헌법)\n헌법\n세계 중심 아키텍처는 다음 6가지 원칙을 따릅니다.**\n````\n┌─────────────────────────────────────────────────────────┐\n│ 헌법 │\n├─────────────────────────────────────────────────────────┤\n│ │\n│ 1. COMPILER 정의",
    "source": "dev.to",
    "sourceUrl": "https://dev.to/eggp/world-centric-agent-architecture-why-your-ai-agent-keeps-failing-and-its-not-the-models-fault-2e5n",
    "category": "AI"
  },
  {
    "title": "[2025/12/22 ~ 28] 이번 주에 살펴볼 만한 AI/ML 논문 모음",
    "content": "[파이토치 한국 사용자 모임](/)\n# \n[[2025/12/22 ~ 28] 이번 주에 살펴볼 만한 AI/ML 논문 모음](/t/2025-12-22-28-ai-ml/8537)\n[\n읽을거리&정보공유\n](/c/news/14)\nself-supervised, \npaper, \nsurvey-paper, \nai-ml-papers-of-the-week, \nmodel-first-reasoning-llm-agents, \nquco-rag, \nmodel-first-reasoning, \nstabilizing-reinforcement-learning, \ndynamic-rag, \nreasoning-agent, \nperceptual-4d-distillation, \nmulti-token-generation, \nqttt, \n4d-rgpt, \nllm-harms, \nworldplay, \njacobi-forcing, \ncausal-parallel-decoding, \nh-neurons, \nnepa\n9bow\n(박정환)\n12월 28, 2025, 9:30오후\n1\n# [](#p-16844-h-20251222-28-aiml-1)[2025/12/22 ~ 28] 이번 주에 살펴볼 만한 AI/ML 논문 모음\n### [](#p-16844-pytorchkr-2)PyTorchKR​![:fire:](https://discuss.pytorch.kr/images/emoji/fluentui/fire.png?v=15)![:south_korea:](https://discuss.pytorch.kr/images/emoji/fluentui/south_korea.png?v=15) ![:thinking:](https://discuss.pytorch.kr/images/emoji/fluentui/thinking.png?v=15)![:thought_balloon:](https://discuss.pytorch.kr/images/emoji/fluentui/thought_balloon.png?v=15)\n![:one:](https://discuss.pytorch.kr/images/emoji/fluentui/one.png?v=15) **심층적인 환각 탐지와 완화 전략 (Deep Hallucination Detection & Mitigation)**: 이번 주 선정된 논문들을 살펴보면, 단순히 모델의 크기를 키우는 것을 넘어, LLM의 고질적인 문제인 **환각(Hallucination)** 을 근본적으로 해결하려는 시도가 두드러집니다. **QuCo-RAG**는 모델 내부의 주관적 신뢰도 대신 사전 학습 데이터의 통계라는 객관적 지표를 활용해 검색 시점을 결정하며, **H-Neurons**는 환각을 유발하는 특정 뉴런을 식별하고 그 기원을 추적하는 미시적 접근을 취합니다. 또한, **Model-First Reasoning**은 문제 해결 전 명시적인 모델링 단계를 거치게 함으로써 구조적인 오류를 줄입니다. 이는 AI 연구가 단순히 '그럴듯한 답변'을 내놓는 것에서 '검증 가능하고 신뢰할 수 있는 메커니즘'을 갖추는 방향으로 진화하고 있음을 보여줍니다.\n![:two:](https://discuss.pytorch.kr/images/emoji/fluentui/two.png?v=15) **추론 효율성 및 실시간 처리 기술의 진화 (Evolution of Inference Efficiency & Real-Time Processing)**: 또한, 모델이 거대해짐에 따라 **추론 속도와 메모리 효율성**을 극대화하려는 연구가 활발합니다. **WorldPlay**는 속도와 메모리 간의 트레이드오프를 해결하여 실시간 비디오 생성을 가능하게 했고, **Jacobi Forcing**은 순차적인 생성 방식(AR)의 한계를 넘어 병렬 디코딩을 통해 추론 속도를 획기적으로 높였습니다. 또한 **qTTT**는 긴 문맥 처리 시 발생하는 성능 저하(점수 희석)를 막기 위해 추론 단계에서 경량화된 학습을 수행하는 새로운 접근법을 제시했습니다. 이는 고성능 모델을 실제 서비스 레벨(Real-time application)에서 활용하기 위한 필수적인 최적화 과정으로 해석됩니다.\n![:three:](https://discuss.pytorch.kr/images/emoji/fluentui/three.png?v=15) **동적 세계 이해와 구조적 추론 능력 강화 (Enhanced Dynamic World Understanding & Structured Reasoning)**: 정적인 이미지나 텍스트 분석을 넘어, **시간의 흐름(4D)과 물리적/논리적 구조**를 이해하려는 흐름이 강합니다. **4D-RGPT**는 비디오의 시간적 동역학을 이해하기 위해 3D 공간에 시간 축을 더한 4D 인식을 시도하며, **WorldPlay**는 기하학적 일관성을 유지하며 세계 모델링을 수행합니다. **NEPA** 역시 픽셀 복원 대신 임베딩 예측을 통해 시각적 이해를 높이려 합니다. 이는 AI가 단순한 패턴 매칭을 넘어, 인간처럼 물리 법칙과 논리적 인과관계를 포함한 **'세계의 작동 원리'** 를 내재화하는 단계로 나아가고 있음을 시사합니다.\n---\n## [](#p-16844-worldplay-towards-long-term-geometric-consistency-for-real-time-interactive-world-modeling-3)월드플레이: 실시간 상호작용 세계 모델링을 위한 장기 기하학적 일관성 향상 / WorldPlay: Towards Long-Term Geometric Consistency for Real-Time Interactive World Modeling\n[![월드플레이: 실시간 상호작용 세계 모델링을 위한 장기 기하학적 일관성 향상 / WorldPlay: Towards Long-Term Geometric Consistency for Real-Time Interactive World Modeling #1](https://discuss.pytorch.kr/uploads/default/original/2X/a/a91913e5108675f1a61a41032b74895f534717dc.jpeg)월드플레이: 실시간 상호작용 세계 모델링을 위한 장기 기하학적 일관성 향상 / WorldPlay: Towards Long-Term Geometric Consistency for Real-Time Interactive World Modeling #1997×395 109 KB\n](https://discuss.pytorch.kr/uploads/default/a91913e5108675f1a61a41032b74895f534717dc)**\n[![월드플레이: 실시간 상호작용 세계 모델링을 위한 장기 기하학적 일관성 향상 / WorldPlay: Towards Long-Term Geometric Consistency for Real-Time Interactive World Modeling #2](https://discuss.pytorch.kr/uploads/default/optimized/2X/4/48c605c028d6005269ecb7d065f11dd6288b4f2d_2_1028x604.jpeg)월드플레이: 실시간 상호작용 세계 모델링을 위한 장기 기하학적 일관성 향상 / WorldPlay: Towards Long-Term Geometric Consistency for Real-Time Interactive World Modeling #21142×671 389 KB\n](https://discuss.pytorch.kr/uploads/default/48c605c028d6005269ecb7d065f11dd6288b4f2d)\n### [](#p-16844-h-4)논문 소개\nWorldPlay**는 실시간 상호작용 세계 모델링을 위한 혁신적인 스트리밍 비디오 디퓨전 모델로, 장기 기하학적 일관성을 유지하면서도 속도와 메모리 간의 트레이드오프를 해결하는 데 중점을 두고 개발되었습니다. 이 모델은 세 가지 주요 혁신을 통해 성능을 극대화합니다. 첫째, **Dual Action Representation**을 통해 사용자의 입력에 대한 강력한 동작 제어를 가능하게 하여, 다양한 스케일의 장면에서 물리적으로 그럴듯한 움직임을 구현합니다. 둘째, **Reconstituted Context Memory**는 과거 프레임의 정보를 동적으로 재구성하여 장기 일관성을 유지하는 데 기여합니다. 이를 통해 기하학적으로 중요한 오래된 프레임을 접근 가능하게 하여 메모리 효율성을 높입니다. 셋째, **Context Forcing**이라는 새로운 증류 방법을 도입하여 메모리 인식 모델의 성능을 향상시킵니다. 이 방법은 교사와 학생 모델 간의 메모리 컨텍스트를 정렬하여 학생 모델이 장기 정보를 효과적으로 활용할 수 있도록 지원합니다.\nWorldPlay는 24 프레임 초당 720p 비디오를 생성하며, 기존 기술들과 비교할 때 우수한 일관성을 보여줍니다. 이 모델은 실시간 비디오 생성에서의 속도와 장기 기하학적 일관성을 동시에 달성하는 데 성공하였으며, 다양한 장면에서 강한 일반화를 나타냅니다. 또한, 고품질의 3D 재구성을 가능하게 하여 동적인 세계 이벤트를 트리거할 수 있는 프롬프트 기반 상호작용",
    "source": "discuss.pytorch.kr",
    "sourceUrl": "https://discuss.pytorch.kr/t/2025-12-22-28-ai-ml/8537",
    "category": "AI"
  },
  {
    "title": "소프트웨어 엔지니어는 약간은 냉소적일 필요가 있다",
    "content": "# 소프트웨어 엔지니어는 약간 냉소적이어야 한다\n많은 독자들이 \"당신은 [당신의 관리자를 행복하게 만드는](/how-to-ship) 일을 해야 합니다\" 또는 \"대형 기술 회사\"와 같은 말을 할 때 [전화](https://lobste.rs/c/ch8tn0) [나](https://news.ycombinator.com/item?id=46085088) [냉소적](https://news.ycombinator.com/item?id=46082989)이라고 말합니다. 어떤 프로젝트를 진행하고 있는지 [결정](/bad-code-at-big-companies)하세요.” Alex Wennerberg는 자신의 게시물 [*소프트웨어 엔지니어는 정치인이 아닙니다*](https://alexwennerberg.com/blog/2025-11-28-engineering.html)에서 \"Sean Goedecke는 냉소적입니다\"라는 사례를 잘 설명했습니다. 다음은 일부 발췌 내용입니다.\n**\n나는 [Sean의] 조언이 크고 성숙한 소프트웨어 제품을 생산하는 데 전념하는 조직의 상위 수준을 탐색하는 데 매우 효과적이라는 데 의심의 여지가 없습니다. 그러나 잃어버린 것은 가치에 대한 어떤 종류의 개념이다. 엔지니어가 \"정치 게임의 도구\" 그 이상이며, 의미 있는 문제를 해결하기 위해 자신의 전문 지식을 적용하는 역할을 하는 전문 전문가라고 말하는 것은 너무 순진한 것입니까?\n> \n아이러니한 점은 이런 생각이 실제로 돈을 버는 회사의 능력을 파괴한다는 것입니다. 엔지니어가 관리자가 지시한 대로 수행한다는 자기 개념부터 시작해야 한다는 생각은 제게는 매우 암울합니다. 관료적인 조직 내에서 원활하게 운영되는 좋은 방법일 수도 있고, 물론 타협하고 방향을 잡아야 하는 경우도 많지만, 좋은 일을 하기에는 나쁜 방법이다.\n사람들이 왜 이렇게 생각하는지 알 것 같아요. 하지만 저는 거대 기술 기업에서 일하는 것을 *좋아*합니다! 나는 나 자신을 의미 있는 문제를 해결하는 전문가라고 생각합니다. 그리고 저는 실제 기능이나 개선 사항을 사용자에게 제공하기 위해 조직을 탐색하는 것이 훌륭한 작업을 수행하는 훌륭한 방법, 어쩌면 가장 좋은 방법이라고 생각합니다.\n그렇다면 나는 왜 이렇게 냉소적인 글을 쓰는 걸까? 글쎄, 조직이 어떻게 작동하는지 명확하게 생각하고, 지나치게 냉소적인 함정에 빠지지 않으려면 약간의 냉소주의가 필요하다고 생각합니다. 일반적으로 좋은 엔지니어는 약간 냉소적이어야 한다고 생각합니다**.\n### 이상주의자의 견해는 이상주의자가 생각하는 것보다 더 냉소적입니다.\n소프트웨어 엔지니어링에 대한 한 교조적인 \"이상주의적\" 관점은 다음과 같습니다. 나는 분명히 그것을 가장 끔찍한 형태로 표현하고 있지만 많은 사람들이 이것을 문자 그대로 믿는 것 같습니다:[1](#fn-1)\n**\n우리는 권력을 바라는 것 외에는 심각한 신념이 없는 강도 지망생들이 대기업을 운영하는 후기 자본주의 지옥에 살고 있습니다. 회사가 원하는 것은 순종적인 엔지니어링 드론이 잘못된 코드를 빠르게 생성하여 (대부분 허구의) 주가를 거둘 수 있는 것입니다. 한편, 최종 사용자는 더 나쁜 소프트웨어에 더 많은 비용을 지불하고, 광고로 인해 번거롭고, 수정하기에 수익성이 없는 버그를 처리하는 등의 책임을 맡게 됩니다. 윤리적인 소프트웨어 엔지니어가 할 수 있는 유일한 일은 상사를 무시하고 실제적이고 훌륭한 엔지니어링 작업을 수행할 수 있는 일시적인 틈새 시장을 찾거나 취미 농장으로 은퇴하여 여가 시간에 우아한 오픈 소스 소프트웨어를 작성하는 것입니다.\n이 내용을 모두 적어 보면 이것이 *믿을 수 없을 정도로* 냉소적이라는 것이 분명해집니다. 적어도 그것은 대체로 당신과 같은 동료와 상사를 보는 냉소적인 방법입니다. 일을 하고, 좋은 일을 하고 싶은 욕구와 자신의 상사를 기쁘게 해야 하는 필요성의 균형을 맞추는 것입니다. 회사의 C-직원을 냉소적으로 보는 방식입니다. 나는 그것이 또한 정확하지 않다고 생각합니다. 나의 제한된 경험으로 볼 때 대규모 기술 회사를 운영하는 사람들은 실제로 사용자에게 좋은 소프트웨어를 제공하고 싶어합니다.\n이는 개별 소프트웨어 엔지니어의 타협 필요성을 허용하지 않는다는 점에서만 이상주의적입니다. 이 견해에 따르면 *당신*은 나쁜 소프트웨어를 작성할 필요가 전혀 없습니다. 회사가 아무리 타협하고 뭔가를 얻으라고 해도 도덕적으로 발을 단단히 디디고 지옥에나 가라고 말해야합니다. 사실, 그렇게 함으로써 당신은 현대 소프트웨어 세계의 전반적인 퇴보에 맞서는 입장을 취하게 됩니다. 당신은 배트맨처럼 이름도 알려지지 않은 채 당신의 존재를 결코 알지 못하는 최종 사용자의 요구를 보호하고 있습니다.\n나는 확실히 이 견해의 매력을 알 수 있다! 하지만 나는 그것이 *이상주의적인* 매력이라고 생각하지 않습니다. 그것은 세상이 근본적으로 부패하고 이기적이라고 보고, 진정한 긍정적인 변화는 불가능하다고 믿는 데서 비롯됩니다. 즉, *냉소적인* 호소라고 생각합니다.**\n### 냉소적인 견해는 이상주의자들이 생각하는 것보다 더 이상주의적입니다.\n나는 \"정치 게임의 도구\"인 엔지니어와 의미 있는 문제를 해결하는 전문가 사이에 뚜렷한 구분이 없다고 생각합니다. 사실 저는 얇아요",
    "source": "seangoedecke.com",
    "sourceUrl": "https://www.seangoedecke.com/a-little-bit-cynical/",
    "category": "AI"
  },
  {
    "title": "Witr - 리눅스 시스템에서 프로세스가 실행 중인 이유를 설명하는 도구",
    "content": "# witr(이것이 실행되는 이유)\n[](#witr-이것이 실행되는 이유)\n[*](https://private-user-images.githubusercontent.com/4262592/530468710-e51cace3-0070-4200-9d1f-c 4c9fbc81b8d.png?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3L mdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NjcwNzM0OTEsIm5iZiI6MTc2NzA3MzE5MSwicG F0aCI6Ii80MjYyNTkyLzUzMDQ2ODcxMC1lNTFjYWNlMy0wMDcwLTQyMDAtOWQxZi1jNGM5ZmJjODFiOGQucG5nP1gtQW16LUFs Z29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUs0WkElMkYyMDI1MTIzM CUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNTEyMzBUMDUzOTUxWiZYLUFtei1FeHBpcmV zPTMwMCZYLUFtei1TaWduYXR1cmU9Zjc1YThjMGJmZTQ0NTViZTI3NzZlZTllY2UyMGNjY2FhZDhkODZmN2QzYTMxZWMxODFmN 2UyZDhhNzA4NGU1MCZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QifQ.6Mktlq0QmV1wx01rDwo-vuHB-SGrA-2rScub2eVvlYw)\n---\n## 목차\n[](#목차)\n- [1. 목적](#1-목적)\n- [2. 목표](#2-골)\n- [3. 핵심 개념](#3-핵심 개념)\n- [4. 지원 대상](#4-지원 대상)\n[4.1 이름(프로세스 또는 서비스)](#41-name-process-or-service)\n- [4.2 PID](#42-pid)\n- [4.3 포트](#43-포트)\n- [5. 출력 동작](#5-출력 동작)\n[5.1 출력 원리](#51-출력 원리)\n- [5.2 표준 출력 섹션](#52-standard-output-sections)\n- [6. 플래그 및 옵션](#6-플래그--옵션)\n- [7. 예제 출력](#7-예제-출력)\n[7.1 이름 기반 쿼리](#71-이름 기반 쿼리)\n- [7.2 쇼트 출력](#72-쇼트-출력)\n- [7.3 트리 출력](#73-트리 출력)\n- [7.4 다중 일치](#74-다중 일치)\n- [8. 설치](#8-설치)\n[8.1 홈브루(macOS 및 Linux)](#81-homebrew-macos--linux)\n- [8.2 아치 리눅스(AUR)](#82-arch-linux-aur)\n- [8.3 스크립트 설치(권장)](#83-스크립트-설치-권장)\n- [8.4 수동설치](#84-수동-설치)\n- [8.5 설치 확인](#85-verify-installation)\n- [8.6 제거](#86-제거)\n- [8.7 닉스 플레이크](#87-nix-flake)\n- [9. 플랫폼 지원](#9-플랫폼-지원)\n[9.1 기능 호환성 매트릭스](#91-feature-compatibility-matrix)\n- [9.2 권한 참고](#92-permissions-note)\n- [10. 성공 기준](#10-성공 기준)\n- [11. AI 지원 면책조항](#11-ai-assistance-disclaimer)\n---\n## 1. 목적\n[](#1 목적)\n**witr**은 단일 질문에 답하기 위해 존재합니다.\n**\n이것이 실행되는 이유는 무엇입니까?**\n프로세스든, 서비스든, 포트에 바인딩된 무엇이든 시스템에서 무언가가 실행 중이면 항상 원인이 있습니다. 그 원인은 간접적이거나 명확하지 않거나 감독자, 컨테이너, 서비스 또는 셸과 같은 여러 계층에 분산되어 있는 경우가 많습니다.\n기존 도구(`ps`, `top`, `lsof`, `ss`, `systemctl`, `docker ps`)는 상태와 메타데이터를 노출합니다. 무엇이 실행 중인지* 보여주지만, 여러 도구에 걸쳐 출력을 수동으로 연관시켜 사용자가 *이유*를 추론하도록 합니다.\n**witr**은 인과관계를 명백하게 만듭니다.\n**실행 중인 항목이 어디에서 왔는지**, **어떻게 시작되었는지**, **현재 존재하는 시스템 체인이 무엇인지**를 사람이 읽을 수 있는 단일 출력으로 설명합니다.\n---\n## 2. 목표\n[](#2-골)\n### 기본 목표\n[](#기본-목표)\n- 프로세스가 존재한다는 것뿐만 아니라 **프로세스가 존재하는 이유**를 설명하세요.\n- 디버깅 및 중단 시 이해 시간 단축\n- 제로 구성으로 작업\n- 안전하고 읽기 전용이며 비파괴적이어야 합니다.\n- 완전성보다 명확성을 선호\n### 비골\n[](#논골)\n- 모니터링 도구가 아닙니다.\n- 성능 프로파일러가 아님\n- systemd/docker 도구를 대체하지 않음\n- 교정 또는 자동 수정 도구가 아님\n---\n## 3. 핵심 개념\n[](#3-핵심 개념)\nwitr은 **모든 것을 프로세스 질문**으로 처리합니다.\n포트, 서비스, 컨테이너 및 명령은 모두 결국 **PID**에 매핑됩니다. PID가 식별되면 witr은 *PID가 존재하는 이유*를 설명하는 인과 사슬을 구축합니다.\n핵심적으로 witr은 다음과 같이 대답합니다.\n- 무엇이 달리고 있나요?\n- 어떻게 시작됐나요?\n- 계속해서 운영되고 있는 이유는 무엇인가요?\n- 어떤 맥락에 속하는가?\n---\n## 4. 지원 대상\n[](#4-지원되는 대상)\nwitr은 PID 분석으로 수렴되는 여러 진입점을 지원합니다.\n---\n### 4.1 이름(프로세스 또는 서비스)\n[](#41-이름-프로세스-또는-서비스)\n````\n위트르 노드\nnginx로\n````\n단일 위치 인수(플래그 없음)는 프로세스 또는 서비스 이름으로 처리됩니다. 일치하는 항목이 여러 개 발견되면 witr은 PID를 기준으로 명확성을 묻는 메시지를 표시합니다.\n---\n### 4.2 PID\n[](#42-pid)\n````\nwitr --pid 14233\n````\n특정 프로세스가 존재하는 이유를 설명합니다.\n---\n### 4.3 포트\n[](#43-포트)\n````\nwitr --port 5000\n````\n포트에서 수신 대기하는 프로세스를 설명합니다.\n---\n## 5. 출력 동작\n[](#5-출력 동작)\n### 5.1 출력 원리\n[](#51-출력-p",
    "source": "github.com",
    "sourceUrl": "https://github.com/pranshuparmar/witr",
    "category": "AI"
  },
  {
    "title": "AI가 메모리 칩을 대량 소비하면서 기기 가격이 상승할 것",
    "content": "### \n[비즈니스](https://www.npr.org/sections/business/)\n# 메모리 손실: AI가 칩을 먹어 치우면 기기 가격이 오를 수 있습니다.\n2025년 12월 28일 오전 6시(ET)\n[고려된 모든 것](https://www.npr.org/programs/all-things-considered/nx-s1-5488194/all-things-considered-for-december-26-2025)에서 들었습니다.\n[\n![John Ruwitch 얼굴 사진](https://media.npr.org/assets/img/2021/09/07/jwr-pic_sq-328878fd008a849dd85d5979088334103fccc7e8.jpg?s=100&c=85&f=jpeg)\n](https://www.npr.org/people/815044198/john-ruwitch)\n[\n존 루위치\n](https://www.npr.org/people/815044198/john-ruwitch)\n#### 메모리 손실: AI가 칩을 먹어치우면 기기 가격이 오를 수 있습니다.\n[\n**\n**\n**\n들어봐\n**\n**\n· \n3:43\n**\n](https://ondemand.npr.org/anon.npr-mp3/npr/atc/2025/12/20251226_atc_computer_memory_shortage.mp3? t=progseg&e=nx-s1-5488194&p=2&seg=12&d=223&size=3571506&sc=siteplayer&aw_0_1st.playerid=siteplayer)\n3:43\n[\n****\n**스크립트**\n](https://www.npr.org/transcripts/nx-s1-5656190)\n**\n**\n**추가 옵션 전환**\n- [******다운로드**](https://ondemand.npr.org/anon.npr-mp3/npr/atc/2025/12/20251226_atc_computer_memory_short age.mp3?t=progseg&e=nx-s1-5488194&p=2&seg=12&d=223&size=3571506&sc=siteplayer&aw_0_1st.playerid=siteplayer)\n- \n******삽입**\n**\n**\n**삽입**\n\">\n**\n`<**iframe src=\"https://www.npr.org/player/embed/nx-s1-5656190/nx-s1-9587157\" width=\"100%\" height=\"290\"frameborder=\"0\" scrolling=\"no\" title=\"NPR 내장 오디오 플레이어\">`\n- \n[\n****\n**스크립트**\n](https://www.npr.org/transcripts/nx-s1-5656190)",
    "source": "npr.org",
    "sourceUrl": "https://www.npr.org/2025/12/28/nx-s1-5656190/ai-chips-memory-prices-ram",
    "category": "AI"
  },
  {
    "title": "리치 히키의 &quot;고마워요 AI!&quot;: 인공지능이 만드는 거대한 쓰레기통",
    "content": "# 고마워요 AI!\n[](#감사합니다-ai)\n다음 이메일을 받았습니다:\n**\n부자,\n당신이 만든 클로저...\n'알지 못하는 공인에게 편지를 쓰고, 이해하지 못하는 출처를 사용하여, 느껴지지 않는 감정을 전혀 의도 없이 표현하는 3학년 숙제에 걸 맞는 아첨꾼 헛소리'\n클로드 하이쿠 4.5\n아, 크리스마스 때구나. 바보 로봇의 소원이 우리 마음을 따뜻하게 해주는 그 때. 경험으로 인해 가슴이 뭉클하고 명절 기분으로 차세대 'AI'를 우리에게 가져온 분들께 감사의 편지를 직접 써야겠다고 생각했습니다.\n### *친애하는 'AI' 납품업체 여러분,*\n[](#dear-ai-purveyors)\n내가 어떻게 당신께 감사해야 할까요? 여러 가지 방법을 세어보겠습니다.\n창조적 인류의 역사적 결과물 전체를 불법 복제하고 전리품에 대한 소유권을 주장한 것에 대해 감사해야 합니까?\n교육을 파괴하기 위해?\n유틸리티 요금을 높이고 환경을 죽이기 위해?\nBS 생성기의 유용한 출력을 동축화하기 위해 막대한 양의 개발자 시간을 낭비하는 대신 실제로 지능적이어서 그들이 들은 내용에서 배우고 자신이 만든 것을 유지할 수 있는 인턴 및 초급 개발자와 통신하는 데 사용할 수 있는 시간을 낭비하고 있습니까?\n신입사원 일자리를 없애고 경험의 길을 열어 미래 세대의 미숙련 실업자를 보장하기 위해?\n내가 말하는 것을 이해하고 더 빨리 도와줄 수 있고 배려할 기회가 있는 실제 사람 대신 도움이 필요할 때 이야기할 가짜 사람을 주신 것에 대해?\n검색 결과를 요약 BS로 바꾸려면?\n인터넷을 엉성하게 채우는 도구를 제공하여 실제 인간 콘텐츠를 거의 찾을 수 없게 만들기 위해?\n실제로는 더 빠르지는 않지만 인건비를 몇 퍼센트나 절약하겠다고 약속하여 CEO를 유혹하여 미래의 인력 풀을 차단하는 동시에 제품 품질, 무결성 및 고객 만족도가 약간 또는 심각하게 감소하는 것을 경험하게 된다면(그들은 명백히 절충하고 싶어 하는 절충안)?\n음악적 표현을 로봇 앵무새의 지저귀는 소리로 대체하려면?\n뒤집는 모든 것에 'AI' 기능을 추가하려면 대부분의 기능에 깊은 사생활 침해가 필요합니까?\n금세기에 두 번째로 크고 가장 파괴적인 사기꾼을 운영하기 위해(처음에는 열심히 운영)?\n*아닌 것 같아요.***\n이 이메일은 에이전트 'AI'가 나머지 인간 통신 채널을 BS로 가득 채우고 많은 서비스를 압도하며 같은 방에 있지 않은 사람들과의 모든 상호 작용을 의심하게 만들고 이를 영원히 시간 소모적인 낭비로 필터링할 것이라는 사실을 상기시켜 주는 것이었습니다.\n***우리는 언제 문제를 해결하는 것보다 더 많은 문제를 일으키는 실패를 고려하지 않았습니까?***\n### *부자*\n[](#부자)",
    "source": "gist.github.com",
    "sourceUrl": "https://gist.github.com/richhickey/ea94e3741ff0a4e3af55b9fe6287887f",
    "category": "AI"
  },
  {
    "title": "누군가가 당신의 제품을 극도로 싫어한다고 말할 때 (부정적 피드백 대응 가이드)",
    "content": "# 누군가가 당신의 제품이 싫다고 뜨거운 열정으로 말할 때\n### CodeRabbit이 수행한 작업과 대신 수행할 작업\n[*\n](https://substack.com/@lulu)[Lulu Cheng Meservey](https://substack.com/@lulu)\n2025년 12월 29일\n27\n6\n2\n공유\n공개적으로 부정적인 피드백을 받았다고 가정해 보겠습니다. 무뚝뚝하고 심지어 거칠기까지 합니다. 당신은 본능적으로 강모를 곤두세우고 있습니다. 그들은 틀렸고, 이해하지 못하고, 트롤링을 하고 있습니다. 그러니 자연스럽게 뒤로 물러나게 됩니다. 그러나 당신의 반박은 비평가를 두 배로 만들 뿐이며 이제 다른 사람들도 늘어나고 있습니다. 당신은 자신의 입장을 분명히 밝혔지만 상황은 더욱 악화될 뿐입니다.\n왜 이런 일이 발생하며, 이에 대해 무엇을 할 수 있습니까?\n## 피드백은 규제 메커니즘입니다\n귀하의 신뢰성을 위한 온도 조절 장치를 상상해 보십시오. 사람들은 올바른 설정이 무엇인지에 대한 의견을 형성하고 현실이 이상해 보이면 규제합니다. 당신이 자신의 설정값보다 높으면 사람들은 당신이 과대평가되었다고 느끼고 당신을 끌어내리고 싶어합니다. 당신이 그보다 낮으면 사람들은 당신이 과소평가되었다고 느끼고 당신을 발전시키고 싶어합니다. 그리고 당신이 더 멀리 떨어져 있을수록 그들은 더 많이 과잉 교정할 것입니다.\n누군가가 귀하(또는 귀하의 회사 또는 귀하의 제품)에 대해 불만을 표시할 때 그들은 귀하가 어떤 것에 대해 얼마나 칭찬을 받아야 하는지에 대한 견해를 가지고 있습니다. 공공 장소에서의 환기는 온도 조절 장치를 원하는 설정으로 돌리는 것과 같이 평판을 조절하고 적절한 항상성을 달성하는 방법입니다.\n이는 누군가의 피드백의 내용이 좌절감이나 듣고자 하는 욕구와 완전히 별개라는 것을 의미합니다. 불만 사항은 종종 불공평해 보이고 사실 확인을 원할 수도 있지만 먼저 불만 사항을 해결하고 사람들이 실제로 듣고 있다는 느낌을 주지 않는 한 아무 소용이 없습니다. (사실은 우리의 감정에 관심이 있다는 것이 밝혀졌습니다.)\n## 저항이 확대되고 있습니다\n누군가의 피드백을 거부한다는 것은 (1) 그 사람이 틀렸고, (2) 그 사람이 멍청할 수도 있고, (3) 그 사람이 당신을 판단할 권한이 없다는 것을 암시하는 것입니다.\n분명히 말하면 때로는 그것이 모두 사실이므로 싸우거나 무시해야 합니다. 하지만 이 경우 우리는 고객과 같이 중요한 사람들의 실질적인 피드백에 초점을 맞추고 있습니다.\n반박함으로써 당신은 그들이 초기 진술을 정당화하고 방어하도록 강요하는 것입니다. 그들이 그것을 제기한 것이 틀렸거나 당신이 저항한 것이 틀렸습니다! 그들의 선택은 명백하다.\n이제 그들의 움직임은 더 많은 사례나 더 강력한 언어를 통해 더욱 확대되는 것입니다. 이것이 진행됨에 따라 구경꾼들은 비평가의 편을 드는 경향이 있을 것입니다. 왜냐하면 화난 고객이 오만한 창업자보다 더 공감하기 때문입니다.\n## 에이든 대 CodeRabbit\n온도 조절 장치 비유로 돌아가면 완고한 다이얼은 사람들을 더 세게 비틀게 만듭니다.\n최근 사례는 다음과 같습니다.\n지난주 Aiden Bai는 CodeRabbit에 불만 사항을 게시했습니다. 지금까지는 꽤 정상입니다. 사용자는 항상 제품에 대해 불평합니다. CodeRabbit 엔지니어가 피드백을 요청하기 위해 뛰어들었고 이는 좋은 결과였으며 Aiden은 자세한 내용을 제공했습니다(전체 내용은 [여기](https://x.com/aidenybai/status/2004033871244099613)).\n[*- \n](https://substackcdn.com/image/fetch/$s_!LaKm!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack -post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fce22ef33-ec40-4838-b210-aad9a30b184d_1208x786.png)CodeRabbit의 CEO인 Harjot가 채팅에 입장했습니다.\n[![](https://substackcdn.com/image/fetch/$s_!A4lW!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A %2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F016d1df7-7cd0-43e4-b2c3-ca9f5ab51ede_1184x1176.png)\n](https://substackcdn.com/image/fetch/$s_!A4lW!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubs tack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F016d1df7-7cd0-43e4-b2c3-ca9f5ab51ede_1184x1176.png)In 게시물 하나, 그 사람\n자신의 고객에게 아무것도 모르는 사람이라고 불렀습니다.\n- 그런 다음 CodeRabbit에는 이 피드백이 중요하지 않을 만큼 충분한 사용자가 있음을 암시합니다.\n- 그런 다음 그것이 유효하더라도 \"더 간단한 제어와 많은 손 잡기\"로 해결될 수 있다고 겸손하게 추측했습니다.\n- 그러면 *백합을 장식하기 위해 에이든을 개인적으로 모욕하는 것이 아니라 인디 개발자를 카테고리로 욕하는 것도 확실했습니다.\n이제 우리는 나쁜 답변을 쓰는 ​​것이 나쁜 사람이 되는 것과는 다르다는 것을 기억해야 합니다. Harjot는 자신의 회사에 대한 악의적인 공격이라고 느꼈던 것에 대해 좌절감을 느꼈고, 저는 창업자들이 싫어하는 피로감을 느끼는 것에 대해 많은 동정심을 가지고 있습니다.\n그럼에도 불구하고 객관적으로 반응은 좋지 않았고 다음은 예상 가능했습니다.\n[*- \n](https://substackcdn.com/image/fetch/$s_!SRle!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws .com%2Fpublic%2Fimages%2F067f837f-ca5d-4341-a2dc-3f9c81cf3d94_1178x1146.png)[![](https://substackcdn.com/image/fetch/$s_!vsPu!,w_1456,",
    "source": "getflack.com",
    "sourceUrl": "https://www.getflack.com/p/responding-to-negative-feedback",
    "category": "AI"
  },
  {
    "title": "ManusAI가 Meta에 합류",
    "content": "[\n](/?index=1)특징\n자원\n[이벤트\n](https://events.manus.im)[가격\n](/pricing)영어[독일어](/de/blog/manus-joins-meta-for-next-era-of-innovation)[Español](/es/blog/manus-joins-meta-for-next-era-of-innovation)[Español (라틴 아메리카)](/es-419/blog/manus-joins-meta-for-next-era-of-innovation)[프랑스어](/fr/blog/manus-joins-meta-for-next-era-of-innovation)[이탈리아어](/it/blog/manus-joins-meta-for-next-era-of-innovation)[포르투갈어 (브라질)](/pt-br/blog/manus-joins-meta-for-next-era-of-innovation)[포르투갈(포르투갈)](/pt-pt/blog/manus-joins-meta-for-next-era-of-innovation)[Tiếng 베트남](/vi/blog/manus-joins-meta-for-next-era-of-innovation)[터키어](/tr/blog/manus-joins-meta-for-next-era-of-innovation)[简体中文](/zh-cn/bl og/manus-joins-meta-for-next-era-of-innovation)[繁체중문](/zh-tw/blog/manus-joins-meta-for-next-era-of-innovation)[일본어](/ja/blog/manus-joins- Meta-for-next-era-of-innovation)[한국어](/ko/blog/manus-joins-meta-for-next-era-of-innovation)[العربية](/ar/blog/manus-joins-meta-for-next-e ra-of-innovation)[ไท้](/th/blog/manus-joins-meta-for-next-era-of-innovation)[힌디](/hi/blog/manus-joins-meta-for-next-era-of-innovation)\n시작하기영어[독일어](/de/blog/manus-joins-meta-for-next-era-of-innovation)[Español](/es/blog/manus-joins-meta-for-next-era-of-innovation)[Español (라틴 아메리카)](/es-419/blog/manus-joins-meta-for-next-era-of-innovation)[프랑스어](/fr/blog/manus-joins-meta-for-next-era-of-innovation)[이탈리아어](/it/blog/manus-joins-meta-for-next-era-of-innovation)[포르투갈어 (브라질)](/pt-br/blog/manus-joins-meta-for-next-era-of-innovation)[포르투갈(포르투갈)](/pt-pt/blog/manus-joins-meta-for-next-era-of-innovation)[Tiếng 베트남](/vi/blog/manus-joins-meta-for-next-era-of-innovation)[터키어](/tr/blog/manus-joins-meta-for-next-era-of-innovation)[简体中文](/zh-cn/bl og/manus-joins-meta-for-next-era-of-innovation)[繁체중문](/zh-tw/blog/manus-joins-meta-for-next-era-of-innovation)[일본어](/ja/blog/manus-joins- Meta-for-next-era-of-innovation)[한국어](/ko/blog/manus-joins-meta-for-next-era-of-innovation)[العربية](/ar/blog/manus-joins-meta-for-next-e ra-of-innovation)[ไท้](/th/blog/manus-joins-meta-for-next-era-of-innovation)[힌디](/hi/blog/manus-joins-meta-for-next-era-of-innovation)\n[상품](/blog?kind=PRODUCT)·12월 29일 월요일\n# 마누스, 차세대 혁신 시대를 위해 메타에 합류\n![](https://files.manuscdn.com/assets/dashboard/materials/2025/12/29/be24830250b19286eda97af3b8f076bc3e0f835a3fa818bb4c3095354c351cfe.webp)\n뉴스가 나왔고 매우 중요합니다. Manus가 Meta에 합류한다는 것입니다.\n이번 발표는 단순한 헤드라인 그 이상입니다. 이는 General AI Agents에 대한 우리의 선구적인 작업을 입증하는 것입니다.\nManus는 출시 이후 사용자가 연구, 자동화 및 복잡한 작업을 처리할 수 있도록 설계된 범용 AI 에이전트를 구축하는 데 중점을 두었습니다. 지속적인 제품 반복을 통해 우리는 점점 더 다양해지는 실제 사용 사례에서 이러한 기능을 더욱 안정적이고 유용하게 만들기 위해 열심히 노력해 왔습니다. 단 몇 달 만에 우리 에이전트는 147조 개 이상의 토큰을 처리했으며 8천만 대가 넘는 가상 컴퓨터 생성을 지원했습니다.\n우리는 자율 에이전트의 잠재력을 믿으며, 이번 개발은 실행 계층으로서의 Manus의 역할을 강화하여 고급 AI 기능을 실제 환경에서 엔드투엔드 작업을 수행할 수 있는 확장 가능하고 안정적인 시스템으로 전환합니다.\n우리의 최우선 과제는 이러한 변화가 고객에게 지장을 주지 않도록 하는 것입니다. 당사는 앞으로도 앱과 웹사이트를 통해 상품 구독 서비스를 판매 및 운영할 예정입니다. 회사는 싱가포르에서 계속 운영될 예정입니다.\n우리의 솔루션은 오늘날 전 세계 수백만 명의 사용자에게 가치를 제공하고 있습니다. 시간이 지나면 우리는 Meta 플랫폼을 사용하는 수백만 개의 기업과 수십억 명의 사람들에게 이 구독을 확대할 수 있기를 바랍니다.\nManus의 CEO인 Xiao Hong은 “Meta에 합류함으로써 Manus의 업무 방식이나 의사결정 방식을 바꾸지 않고도 더욱 강력하고 지속 가능한 기반을 구축할 수 있게 되었습니다.”라고 말했습니다. \"우리는 Meta와 Manus가 함께 협력하여 미래가 어떻게 될지 기대하고 있습니다. 우리는 계속해서 제품을 반복하고 처음부터 Manus를 정의한 사용자에게 서비스를 제공할 것입니다.\"\n자세한 내용은 [Meta의 공지사항](https://www.facebook.com/business/news/manus-joins-meta-accelerating-ai-innovation-for-businesses)을 참조하세요.\n## 구조가 적고,\n더 많은 지능.\n### 제품\n[가격](/pricing)[웹 앱](/features/webapp)[AI 디자인](/tools/ai-design)[AI 슬라이드](/tools/nano-banana-pro-slides)[Manus 브라우저 운영자](/features/manus-browser-operator)[와이드 리서치](/features/wide-research)",
    "source": "manus.im",
    "sourceUrl": "https://manus.im/blog/manus-joins-meta-for-next-era-of-innovation",
    "category": "AI"
  },
  {
    "title": "실무 중심의 심도 있는 내용을 다루는 최고의 엔지니어링 블로그는 무엇인가요?",
    "content": "[*](https://news.ycombinator.com)**[해커 뉴스](뉴스)**[신규](최신) | [과거](앞) | [댓글](새 댓글) | [질문](질문) | [쇼](쇼) | [취업](취업) | [제출](제출)[로그인](login?goto=item%3Fid%3D46363921)\n[HN에게 물어보세요: 실제 깊이를 갖춘 최고의 엔지니어링 블로그는 무엇입니까?](item?id=46363921)461 포인트 by [nishilpatel](user?id=nishilpatel) [6일 전](item?id=46363921) | [숨기기](hide?id=46363921&goto=item%3Fid%3D46363921) | [과거](https://hn.algolia.com/?query=Ask%20HN%3A%20What%20are%20the%20best%20engineering%20blogs%20with%20real-world%20length%3F&type=story&dateRange=all&sort=byDate&storyText=false&prefix&page=0) | [즐겨찾기](fave?id=46363921&auth=e95b7fed59a69774119812f886e8bd69edd1f2ec) | [댓글 139개](item?id=46363921)저는 특히 표면 수준의 설명을 뛰어 넘는 기술 회사 블로그에서 고품질 엔지니어링 블로그 게시물의 예를 찾고 있습니다. 특히 다음과 같은 게시물에 관심이 있습니다.\n1. 기술적인 개념을 명확하고 간결하게 설명하세요.\n2. 실제 구현 세부 사항, 장단점 및 실패 표시\n3. 구조가 잘 구성되어 있고 읽기 쉽습니다.\n4. 엔지니어링 결정을 비즈니스 또는 제품 결과와 연결하십시오. 정기적으로 배우는 눈에 띄는 블로그, 게시물 또는 플랫폼이 있습니까?\n![](s.gif)\n[pella](user?id=pella) [6일 전](item?id=46364274) | [다음](#46364321) [[–]](javascript:void(0))\n> 특히 기술 회사에서 블로그,[https://engineering.fb.com/](https://engineering.fb.com/)[https://netflixtechblog.com/](https://netflixtechblog.com/)[https://stripe.com/blog/ 엔지니어링](https://stripe.com/blog/engineering)[https://eng.uber.com](https://eng.uber.com)[https://engineering.linkedin.com/](https://engineering.l inkedin.com/)[https://engineering.atspotify.com/](https://engineering.atspotify.com/)[https://tailscale.com/blog](https://tailscale.com/blog)[https://careersatdoordash.com/engineering-blog/](https://careersatdoordash.com/engineering-blog/)[https://dropbox.tech/](https://dropbox.tech/)--집합자:( [https://engineering.fyi/](https://engineering.fyi/) ; [https://diff.blog/](https://diff.blog/) )+ [https://hn.algolia.com/?query=engineering%20blog](https://hn.algolia.com/?query=engineering%20blog)---공개 엔지니어링 블로그 SKILL.md를 만듭니다.\n(~HN에서 작동하는 쓰기 패턴을 수집합니다)\n[답글](reply?id=46364274&goto=item%3Fid%3D46363921%2346364274)\n![](s.gif)\n[javcasas](user?id=javcasas) [5일 전](item?id=46374999) | [부모](#46364274) | [다음](#46364336) [[–]](javascript:void(0))\n> [https://engineering.fyi/](https://engineering.fyi/)으윽. 그것은 AI, LLM, Agent와 같습니다. 데이터베이스, 분산 시스템은 어디에 있고 소프트웨어 검증은 어디에 있습니까?\n[답글](reply?id=46374999&goto=item%3Fid%3D46363921%2346374999)\n![](s.gif)\n[i_k](user?id=i_k) [6일 전](item?id=46364336) | [부모](#46364274) | [이전](#46374999) | [다음](#46397914) [[–]](javascript:void(0))\nRSS가 거의 없다는 사실에 상당히 놀랐고 약간 실망했습니다. 하지만 감사합니다!\n[답글](reply?id=46364336&goto=item%3Fid%3D46363921%2346364336)\n![](s.gif)\n[reallydoubtful](user?id=reallydoubtful) [6일 전](item?id=46366119) | [루트](#46364274) | [부모](#46364336) | [다음](#46364494) [[–]](javascript:void(0))\n대부분 피드가 있습니다.* [https://engineering.fb.com/feed](https://engineering.fb.com/feed)* [https://netflixtechblog.com/feed](https://netflixtechblog.com/feed)* 스트라이프에 대한 피드 없음* [https://www.uber.com/en-GB/blog/london/engineering/rss/](https://www.uber.com/en-GB/blog/london/engineering/rss/)* LinkedIn*에 대한 피드가 없습니다. [https://careersatdoordash.com/engineering-blog/feed](https://careersatdoordash.com/engineering-blog/feed)* [https://dropbox.tech/feed](https://dropbox.tech/feed)\n[답글](reply?id=46366119&goto=item%3Fid%3D46363921%2346366119)\n![](s.gif)\n[KomoD](user?id=KomoD) [6일 전](item?id=46369144) | [루트](#46364274) | [부모](#46366119) | [다음](#46368430) [[–]](javascript:void(0))\n링크드인 피드: [https://www.linkedin.com/blog.rss](https://www.linkedin.com/blog.rss)\n[답글](reply?id=46369144&goto=item%3Fid%3D46363921%2346369144)\n![](s.gif)\n[omgitspavel](user?id=omgitspavel) [6일 전](item?id=46368430) | [루트](#46364274) | [부모](#46366119) | [이전](#46369144) | [다음](#46364494) [[–]](javascript:void(0))\n스트라이프에 대한 피드가 있습니다: [https://stripe.com/blog/feed.rss](https://stripe.com/blog/feed.rss)\n[답글](답글?id=46368430&got",
    "source": "news.ycombinator.com",
    "sourceUrl": "https://news.ycombinator.com/item?id=46363921",
    "category": "AI"
  },
  {
    "title": "타다 리스트를 1년 동안 유지하며 느낀 점 (One year of keeping a tada list)",
    "content": "# 1년간의 타다 리스트 유지\n### 할 일 목록이라고도 합니다.\n[![아디티야 바르가바의 아바타](https://substackcdn.com/image/fetch/$s_!uDxW!,w_36,h_36,c_fill,f_auto,q_auto:good,fl_progressive:steep/http s%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3ca60dd5-1f9f-4007-9ea0-021bea9db81a_400x400.png)\n](https://substack.com/@ducktyped)[Aditya Bhargava](https://substack.com/@ducktyped)\n2025년 12월 22일\n19\n1\n공유\n타다 목록(tada list) 또는 할일 목록(to-done list)은 매일 성취한 일을 적는 곳입니다. 아직 해야 할 일이 얼마나 되는지에 초점을 맞추는 대신, 완료한 일에 집중하게 만드는 것입니다. 내 타다 목록은 다음과 같습니다.\n[![6월의 짜잔 목록 2025](https://substackcdn.com/image/fetch/$s_!-pJb!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3 A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3c1a2a05-8c3c-4097-817d-cd7b38fad31c_837x1060.png)- \n](https://substackcdn.com/image/fetch/$s_!-pJb!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsub stack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3c1a2a05-8c3c-4097-817d-cd7b38fad31c_837x1060.png)I 매달 페이지가 있어요. 매일 나는 내가 한 일을 적는다. 월말에는 그 달에 무엇을 했는지 보여주기 위해 머리글에 그림을 그립니다. 다음은 몇 가지 그림입니다.\n[![헤더 1월](https://substackcdn.com/image/fetch/$s_!C4jZ!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3 A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F725cc9e9-1559-4161-9ea8-e87ef35e93b8_799x282.png)\n](https://substackcdn.com/image/fetch/$s_!C4jZ!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsub stack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F725cc9e9-1559-4161-9ea8-e87ef35e93b8_799x282.png)In 1월에 나는 Substack을 시작했고, 친구들을 위해 그림을 그렸고, 보안에 관한 두 개의 Substack 게시물을 썼습니다.\n[![헤더 2월](https://substackcdn.com/image/fetch/$s_!mWT8!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3 A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdfa774d9-033b-4369-8634-7304f4c80a80_802x321.png)\n](https://substackcdn.com/image/fetch/$s_!mWT8!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsub stack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdfa774d9-033b-4369-8634-7304f4c80a80_802x321.png)In 2월에는 CSS 강좌를 듣고 스스로 구성 요소 라이브러리를 만들었습니다.\n[![헤더 3월](https://substackcdn.com/image/fetch/$s_!hLxK!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https% 3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8d78584c-a30a-4b11-b707-0b56ee3c357e_795x304.png)\n](https://substackcdn.com/image/fetch/$s_!hLxK!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsub stack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8d78584c-a30a-4b11-b707-0b56ee3c357e_795x304.png)In 3월에는 몇 권의 책을 읽고, 글쓰기 앱 작업을 하고, 뉴욕으로 여행을 떠났으며, 이 서브스택에 대한 선형 대수학에 관한 여러 게시물의 초안을 작성했습니다.\n(이 게시물이 어디에 있는지 궁금하신가요? 초안과 게시 사이에 지연 시간이 있습니다. 여기서 기술 검토를 위해 게시물을 보내고 몇 차례 다시 작성합니다.)\n## 장점\n나는 내 성취를 축하하는 데 많은 시간을 소비하지 않습니다. 일단 뭔가를 성취하고 나면 \"그래, 해냈어\"라는 생각이 살짝 들다가 \"그럼 이제 뭘 더 할 거야?\"라고 생각하게 됩니다. 예를 들어, [내 책](https://www.manning.com/books/grokking-algorithms-second-edition)(3년 간의 노력)을 마쳤을 때 이것이 정상적인 삶의 일부가 되기 전에 몇 주 동안 \"그래, 책을 썼어\"라고 생각하다가 \"예, 책을 썼는데 그 이후로 또 무엇을 했나요?\"로 바뀌었습니다.\n나는 타다 목록이 “내가 뭔가를 했어!”를 강화하는 데 도움이 될 것이라고 생각했습니다. 그런데 '내가 이 일을 할 수 있었던 건 아까부터 다른 일을 했기 때문이다'로 바뀌기도 했습니다. 으로 설명하겠습니다 \n### 예\n수년 동안 저는 가족과 친구들을 위해 미네소타의 그림으로 카드 세트를 만들고 싶었습니다. 문제는 미네소타의 그림이 많지 않았고 내가 가지고 있던 그림도 마음에 들지 않았다는 것입니다.\n그래서 저는 2024년에 수채화 물감과 수백 가지 녹색의 색상 혼합에 대해 많은 것을 배우고 풍경에 어떤 녹색을 사용하고 싶은지 파악했습니다.\n[![](https://substackcdn.com/image/fetch/$s_!zqkV!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3 A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F284141da-1889-4c6c-b668-904c7d1bdbee_888x656.png)\n](https://substackcdn.com/image/fetch/$s_!zqkV!",
    "source": "ducktyped.org",
    "sourceUrl": "https://www.ducktyped.org/p/one-year-of-keeping-a-tada-list",
    "category": "AI"
  },
  {
    "title": "소프트웨어 제품이 실제로 어떻게 돌아가는지는 아무도 모른다 [번역글]",
    "content": "# 소프트웨어 제품이 실제로 어떻게 돌아가는지는 아무도 모른다\n- [Translation](https://blogbyash.com/category/translation/), [Product](https://blogbyash.com/category/translation/product/)\nTable of Contents\n[Toggle](#)\n*\n빠르게 성장하고 움직이는 대형 테크 회사들은, 자기들이 만든 시스템에 대해서조차 늘 일종의 “전쟁터의 안개(fog of war)” 속에서 일하고 있다. “Y 타입 유저가 기능 X를 쓸 수 있나?”, “이 상황에서 액션 Z를 하면 정확히 어떤 일이 벌어지지?”, “우리는 지금 요금제가 몇 가지나 있지?” 같은 아주 단순해 보이는 질문조차, 조직 안에서 겨우 몇 명만 제대로 답을 할 수 있는 경우가 많다. 심하면 그런 질문에 정확히 답할 수 있는 사람이 단 한 명도 없어서, 누군가를 아예 “연구자처럼 파서 조사하는” 역할로 지정해야 할 때도 있다.\n어떻게 이럴 수 있을까? 소프트웨어를 만든 엔지니어들은 자기들이 만든 게 어떻게 동작하는지 알고 있어야 하는 것 아닌가? 이런 내용이 내부 문서에 정리되어 있는 것 아닌가? 더 나아가, 이런 질문들은 사용자용 공개 문서만 봐도 금방 답이 나와야 하는 것 아닌가? 테크 회사에는, 자기 일에 능숙한 고연봉 인재들이 잔뜩 있다. 그런 사람들조차 정작 자기 회사 제품이 정확히 무엇을 하는지 명확하게 말해주지 못하는 이유는 무엇일까?\n## 소프트웨어는 원래 어렵다\n큰 소프트웨어 제품은 상상을 초월할 정도로 복잡하다. 이건 예전에 내가 쓴 글 “Wicked Features”에서 길게 다룬 주제인데, 요약하자면 “복잡한 기능을 추가함으로써 얻을 수 있는 비즈니스 가치가 정말 크다”는 것이다. 대표적인 예시는, 코어 제품을 더 많은 사용자에게 열어 주는 종류의 기능들이다. 예를 들면, 사용자가 직접 소프트웨어를 **Self-hosting**할 수 있게 한다든지, 무료 체험을 제공한다든지, 대규모 조직이 중앙집중식 정책 관리 기능과 함께 쓰게 한다든지, 여러 언어로 로컬라이징해서 제공한다든지, 소프트웨어 운영 방식에 엄격한 규제가 있는 국가에서도 쓸 수 있게 만든다든지, 정부처럼 규제가 심한 고객도 쓸 수 있게 만든다든지 하는 것들이다. 이런 기능들은 (바라건대) 대부분의 일반 사용자에게는 거의 보이지 않는 투명한 존재여야 한다. 하지만 그 기능들이 **테크 회사 내부에까지 투명할 수는 없다.**\n왜 이런 기능들이 그렇게까지 복잡할까? 그 이유는, 이런 것들이 **새로 만드는 모든 다른 기능 하나하나에 전부 영향을 미치기 때문**이다. 조직(Organization)과 정책(Policy) 제어 기능을 한 번 넣기 시작하면, 새 기능을 만들 때마다 그 기능에 대해 또 하나의 정책 제어를 구현해야 한다. 제품을 여러 언어로 로컬라이즈하기 시작하면, 새로운 기능을 추가할 때마다 그 기능에 대한 번역도 항상 함께 따라가야 한다. 그리고 이런 일들이 계속 반복된다.\n어느 순간이 되면, 이런 질문을 마주하게 된다. “EU 리전에 있는, Self-hosting을 쓰는 엔터프라이즈 고객이 이 특정 기능에 접근할 수 있어야 하지 않나?” 그런데 아무도 모른다. 결국 코드를 직접 뒤져보거나, 실제로 여러 가지 실험을 해 보면서, 어떻게 동작하는지 하나하나 밝혀내야 한다.\n“애초에 이런 기능들을 아예 안 만들면 되는 것 아닌가?” 라고 물을 수도 있다. 물론 그럴 수는 있다. 하지만 그러면 정말 **엄청난 돈을 포기**해야 한다. 어쩌면 작은 테크 회사와 큰 테크 회사를 가르는 가장 큰 차이 중 하나가 바로 이것일지도 모른다. 큰 회사일수록, 이렇게 자질구레하고 까다로운 기능들까지 다 포함해서 **그 안에 숨은 가치까지 최대한 회수해 갈 수 있도록 설계**되어 있다는 점이다.\n## 문서화\n“그럼 새 기능을 만들 때마다, 관련된 상호작용을 한 번씩만 꼼꼼하게 문서화해 두면 되는 것 아닌가?”라는 질문이 자연스럽게 떠오른다. 이론상으로는, 굉장히 많은 노력과 강력한 톱다운 지원이 붙는다면 가능할 수도 있다고 본다. 하지만 실제로는 이게 정말, 정말 어려운 일이다.\n핵심 문제는, **문서화를 하는 동안에도 시스템이 계속 빠르게 변하고 있다는 것**이다. 정적인 복잡한 시스템이라면, 한 사람이라도 충분한 시간을 들여서 차근차근 훑어가며 문서를 만들 수 있다. 하지만 시스템이 변하기 시작하는 순간, 문서를 쓰는 사람은 시스템이 변하는 속도보다 더 빨리 움직여야만 한다.**이게 어느 순간부터는, 말 그대로 말도 안 되는 인력을 쏟아붓지 않는 이상 불가능한 일이 되기도 한다.\n더 안 좋은 점은, 시스템의 많은 동작이 애초에 누군가의 명시적인 의도**로 만들어진 것조차 아니라는 점이다. 여러 가지 “디폴트 설정”이 겹겹이 쌓여 상호작용하면서, 그 결과로 **어쩌다 보니 그렇게 동작하게 된 것**도 많다. 그래서 문서를 쓰는 사람들은, 단순히 엔지니어들이 내린 의사결정을 받아 적는 역할을 하는 게 아니다. 실제로는, **이 시스템이 어떻게 돌아가는지 처음부터 새로 탐사해서 발견하고 있는 셈**이다.\n## 그래서 답을 아는 사람은 누구인가?\n이런 질문들 중 많은 것에 답하려면, 가장 확실한 방법은 **코드베이스(codebase)를 직접 들여다보는 것**뿐이다. 이게 사실 대형 테크 회사에서 엔지니어들이 조직 내에서 구조적으로 권력을 갖는 근본 이유라고 본다. 물론 엔지니어들은 소프트웨어를 **작성**하는 사람들이지만, 그보다 더 중요한 건 그들이 소프트웨어에 대해 **질문에 답할 수 있는 사람**이라는 점이다.\n사실, **소프트웨어에 대한 질문에 답하는 능력 자체가 엔지니어링 팀의 핵심 기능 중 하나**다. 특정 소프트웨어 조각에 대한 가장 깊은 이해는, 보통 그걸 매일 다루는 엔지니어들의 머릿속에 살아 있다. 건강한 엔지니어링 팀이 코드베이스를 소유하고 있다면, 별도로 누군가 조사할 필요 없이 팀 전체에 물어보면 된다. 그러면 적어도 한 명은 머릿속에 바로 답을 꺼내줄 것이다. 왜냐하면 그 부분 코드를 이미 잘 알기 때문이다.\n테크 회사들이 팀을 재편(reorg)할 때, 이런 암묵적 지식(tacit knowledge)이 종종 파괴된다. 특정 소프트웨어에 경험이 있는 팀이 사라지면, 질문에 답하려면 조사(investigation)로 돌아갈 수밖에 없다. 누군가 엔지니어가 직접 파헤쳐야 한다는 거다. 보통은 제품과 직접 상호작용하면서(개발 환경에서 특정 시나리오를 쉽게 세팅해서), 코드베이스를 읽어보거나, 심지어 “탐색적 수술(exploratory surgery)”을 하면서 코드 일부를 바꾸거나 특정 체크를 무조건 true로 강제해서 무슨 일이 일어나는지 확인하는 식으로 이뤄진다. 이건 코드를 작성하는 것과는 별개의 기술 스킬이다(물론 두 스킬은 서로 관련이 있지만).\n## 소프트웨어를 짜는 건 설명하는 것보다 쉽다\n내 경험상, 대부분의 엔지니어는 소프트웨어를 작성할 수 있지만, 그 소프트웨어에 대해 **신뢰할 수 있게 질문에 답하는** 사람은 거의 없다. 왜 그럴까? 새 소프트웨어를 작성하려면 그 소프트웨어에 대한 질문을 답할 줄 알아야 하는 것 아닌가? 그래도 이건 사실이다. 내 가장 그럴듯한 이론은 **자신감 문제**다. 많은 엔지니어들은 최소한 자기 머신에서 돌아가는 **코드**에 책임을 지는 건 감수할 수 있지만, 완전히 틀릴 수 있는 **답변**에 책임을 지는 건 싫어한다.\n이 주제는 예전에 쓴 “How I provide technical clarity to non-technical leaders”에서 자세히 다뤘다. 핵심 어려움은, 답변할 때마다 **항상 위험을 무릅쓰고 나간다**는 점이다. 네가 완전히 틀릴 가능성을 편안하게 받아들여야 하는데, 이는 코드를 작성할 때(작업이 맞다는 걸 증명할 수 있으니까)와는 완전히 다른 마인드셋이다. 코드 작성 때는(특히 테스트 코드에서는) 아무리 장황하게 써도 되지만, 질문에 답할 때는 모든 걸 **요약**으로 압축해야 한다. 많은 소프트웨어 엔지니어들은 이런 디테일 생략을 정말 싫어한다.\n## 요약\n소프트웨어 제품과 함께 일해본 경험이 부족한 비기술직 사람들은, 종종 소프트웨어 시스템이 그걸 만든 엔지니어들에게는 완벽히 이해되어 있을 거라고 믿는다. 이 믿음의 근거는, 시스템이 (대체로) 결정론적(deterministic) 컴포넌트들을 한 줄 한 줄 쌓아 올린 결과물이기 때문에 이해하기 쉽다는 생각이다.\n하지만 작은 소프트웨어 조각에서는 이게 맞을 수 있어도, **대형 소프트웨어 시스템에서는 거의 항상 틀린 믿음**이다. 대형 소프트웨어 시스템은, 이해할 위치에 있는 가장 가까운 사람들조차도 **매우 제대로 이해하지 못한다**. 소프트웨어가 정확히 무엇을 하는지에 대한 아주 기본적인 질문조차 답하려면 조사(research)가 필요하다. 게다가 한 번 제대로 된 답을 얻었다 해도 오래가지 않는다. 코드베이스에 변화가 생길 때마다 미묘한 뉘앙스나 예외가 생기기 때문에, 같은 질문을 여러 번 다시 조사해야 하는 경우가 많다.\n이 모든 이유로, **대형 소프트웨어 시스템에 대해 정확하게 질문에 답할 수 있는 능력은 극도로 가치 있다*",
    "source": "blogbyash.com",
    "sourceUrl": "https://blogbyash.com/translation/nobody-knows-how-software-product-work/",
    "category": "AI"
  },
  {
    "title": "OpenRouter의 AI 현황 보고서 : 100조 토큰 실증 연구",
    "content": "## 요약\n지난 해는 대규모 언어 모델(LLM)의 발전과 실제 사용에 있어 전환점이 되었습니다. 2024년 12월 5일 최초로 널리 채택된 추론 모델인 *o1*이 출시되면서 해당 분야는 단일 패스 패턴 생성에서 다단계 심의 추론으로 전환되어 배포, 실험 및 새로운 종류의 애플리케이션이 가속화되었습니다. 이러한 변화가 빠른 속도로 전개됨에 따라 이러한 모델이 실제로 어떻게 사용되었는지에 대한 우리의 경험적 이해는 뒤쳐졌습니다. 이 작업에서 우리는 다양한 LLM에 걸쳐 AI 추론 제공자인 OpenRouter 플랫폼을 활용하여 작업, 지역 및 시간에 걸쳐 100조 개가 넘는 실제 LLM 상호 작용 토큰을 분석합니다. 우리의 실증적 연구에서 우리는 개방형 모델의 상당한 채택, 창의적인 역할극(많은 사람들이 지배한다고 가정하는 생산성 작업을 넘어)의 엄청난 인기, 코딩 지원 범주, 그리고 에이전트 추론의 증가를 관찰했습니다. 또한, 당사의 유지 분석에서는 *기초 코호트*, 즉 후기 코호트보다 참여가 훨씬 오래 지속되는 초기 사용자를 식별합니다. 우리는 이 현상을 신데렐라 *\"유리 구두\"* 효과라고 부릅니다. 이러한 결과는 개발자와 최종 사용자가 \"야생\"에서 LLM에 참여하는 방식이 복잡하고 다면적이라는 것을 강조합니다. 모델 빌더, AI 개발자 및 인프라 제공업체에 대한 영향을 논의하고 데이터 기반 사용법 이해가 LLM 시스템의 더 나은 설계 및 배포에 어떻게 도움이 될 수 있는지 간략하게 설명합니다.",
    "source": "openrouter.ai",
    "sourceUrl": "https://openrouter.ai/state-of-ai",
    "category": "AI"
  },
  {
    "title": "지난 1년의 Mac: 믿기 힘든 상태를 되돌아보다",
    "content": "[호클리\n](https://electiclight.co/author/hoakley/)\n[2025년 12월 28일](https://electiclight.co/2025/12/28/last-year-on-my-mac-look-back-in-disbelief/) \n[Mac](https://electiclight.co/category/macs/), [기술](https://electiclight.co/category/technology/) \n# **지난해 내 Mac에서:** 믿기지 않는 마음으로 되돌아보세요.\n* \n만약 누군가가 12개월 전에 나에게 작년에 무슨 일이 일어날지 말해주었다면 나는 그 말을 믿지 않았을 것입니다. 모든 정치적, 경제적, 사회적 혼란을 빠르게 건너뛰고 Liquid Glass를 탑재한 macOS Tahoe에 가져온 인터페이스 변화에 대해 살펴보겠습니다. 베타 테스트 중 3개월간 강력한 피드백을 받은 후, 9월 15일 Tahoe가 출시되었을 때 거의 해결되지 않은 것을 보고 실망했습니다. 11월 3일에 26.1이 뒤따랐을 때 그것은 단지 퇴보했을 뿐이었고 26.2는 아무것도 하지 않았습니다. 여기에서는 Tahoe의 점검이 어디에서 잘못되었는지에 대한 내 의견을 요약합니다.\n#### 무슨 일이 일어나고 있나요?\n창에 표시되는 거의 모든 콘텐츠는 직사각형 보기에 가장 적합합니다. 이미지, 비디오, 웹페이지 및 기타 텍스트는 직각으로 둘러싸인 영역을 갈망합니다. Sequoia에서와 같이 모서리를 부드럽게 둥글게 만드는 것은 괜찮지만 Tahoe에서 시행된 크게 증가된 반경은 부적합합니다. 이로 인해 내용이 잘리거나 보기 크기 및 낭비되는 공간이 줄어듭니다.\n[![](https://electiclight.co/wp-content/uploads/2025/06/roundect1.jpg)](https://electiclight.co/wp-content/uploads/2025/06/roundect1.jpg)\n아래에 표시된 더 큰 버전과 비교하여 Finder 갤러리 보기의 축소판 이미지 확대 보기에서 볼 수 있듯이 자르기는 오해의 소지가 있습니다. 미리보기 이미지가 원본 내용을 잘못 표현하고 있습니다.\n[![](https://electiclight.co/wp-content/uploads/2025/06/roundect2.jpg)](https://electiclight.co/wp-content/uploads/2025/06/roundect2.jpg)\n이 새로운 모습에 대한 Apple의 주장 중 하나는 일관성이 더 높다는 것입니다. 그러나 SwiftUI를 사용하여 생성된 동일한 앱의 두 창은 아래 macOS 26.2에서 실행되는 Providable에 표시된 것처럼 공통 반경을 공유할 수도 없습니다.\n[![](https://electiclight.co/wp-content/uploads/2025/12/understab1.jpg)](https://electiclight.co/wp-content/uploads/2025/12/understab1.jpg)\n#### 통제 불능\nTahoe는 또한 명확성을 향상하기 위해 컨트롤을 사용하지 않고 컨트롤의 크기를 늘렸습니다. 이를 확인하는 가장 좋은 방법은 내 Mallyshag 데모 앱을 사용하는 것입니다.\n[![](https://electiclight.co/wp-content/uploads/2025/06/mallyshag2.png)](https://electiclight.co/wp-content/uploads/2025/06/mallyshag2.png)\n위의 Sequoia에서는 괜찮아 보이지만 Tahoe(아래)에서는 변경된 제어 크기로 인해 엉망이 됩니다.\n[![](https://electiclight.co/wp-content/uploads/2025/06/mallyshag3.png)](https://electiclight.co/wp-content/uploads/2025/06/mallyshag3.png)\n이 세 개의 버튼은 훨씬 더 넓어서 이제 서로 겹쳐지고 아래 텍스트 상자보다 더 넓어집니다. 그러나 컨트롤 내의 텍스트가 동일하므로 사용자는 이에 대한 이점을 느끼지 못합니다.\n#### 우상 파괴\n앱 아이콘은 구별 가능하고 쉽게 기억할 수 있어야 합니다. 첫 번째는 우리가 서로 구별할 수 있도록 보장하고 색상, 형태 및 내용을 포함하여 우리가 수집할 수 있는 모든 시각적 단서에 의존합니다. Tahoe는 아이콘의 모든 것이 모서리가 둥근 균일한 정사각형 안에 들어가야 한다는 규칙을 시행하므로 단서를 색상과 내용으로 제한합니다. 결과적으로 많은 번들 앱과 기타 Apple 앱의 아이콘은 혼잡한 Dock에서 구별하기가 더 어려워졌습니다. Apple의 개발자 앱과 App Store를 포함한 일부는 구별할 수 없는 반면, 일부는 모호한 얼룩으로 변질되었습니다.\n[![](https://electiclight.co/wp-content/uploads/2025/12/unicon15.jpg)](https://electiclight.co/wp-content/uploads/2025/12/unicon15.jpg)\n위는 Sequoia에 번들로 제공되는 대부분의 앱이고 아래는 Tahoe에 포함된 앱입니다.\n[![](https://electiclight.co/wp-content/uploads/2025/12/unicon26.jpg)](https://electiclight.co/wp-content/uploads/2025/12/unicon26.jpg)\n#### 화이트아웃\n현실에서 화이트아웃은 방향 감각을 혼란스럽게 하기 때문에 위험합니다. 지평선도 없고, 풍경 속에 특징도 없고, 길을 찾을 단서도 없습니다. 우리는 색상과 색조 대비가 풍부한 시각적 환경에서 가장 잘 보고 작업합니다. Tahoe는 라이트 모드가 하얗게 표백되고 다크 모드가 달 없는 밤이 되는 추세를 이어갔습니다. 컨트롤, 뷰 및 콘텐츠가 시작하고 끝나는 위치를 확인하는 것은 어렵고 화이트아웃 상태로 유지됩니다.\n[![](https://electiclight.co/wp-content/uploads/2025/09/tahoelightstd.jpg)](https://electiclight.co/wp-content/uploads/2025/09/tahoelightstd.jpg)\n조명 모드에서 defa 사용",
    "source": "eclecticlight.co",
    "sourceUrl": "https://eclecticlight.co/2025/12/28/last-year-on-my-mac-look-back-in-disbelief/",
    "category": "AI"
  },
  {
    "title": "연봉 값을 하는 엔지니어의 비밀: &quot;모르는 것(Ambiguity)&quot;을 &quot;할 수 있는 것&quot;으로 바꾸는 기술",
    "content": "사람들은 아키텍처, 커뮤니케이션, 소유권, 리더십 등의 큰 체크리스트를 사용하여 수석 엔지니어를 설명하는 것을 좋아합니다.\n하지만 직위, 급여, 경력 연수를 제외하면 수석 엔지니어와 다른 엔지니어를 구별하는 핵심 기술이 하나 있습니다. 바로 **모호함 줄이기**입니다. 다른 모든 것은 그것으로부터 흘러나옵니다.\n내가 의미하는 바는 다음과 같습니다. 중간 수준의 엔지니어는 잘 정의된 문제를 완벽하게 해결할 수 있습니다. 그들에게 명확한 사양과 몇 가지 합리적인 제약 조건을 주면 견고한 작업을 제공할 것입니다. 오해하지 마세요. 그것은 *귀중합니다*.\n하지만 *\"성능을 개선해야 합니다\"*, *\"사용자가 온보딩 흐름에 대해 불평하고 있습니다\"* 또는 *\"확장을 고려해야 합니다\"*와 같은 모호한 내용을 전달하는 순간 차이를 알 수 있습니다. 중간 수준의 엔지니어가 일을 잘 못해서가 아니라 모호한 문제에는 더 많은 것이 필요하기 때문입니다.\n수석 엔지니어들은 크고 지저분하며 추상적인 것을 살펴보고 파헤치기 시작합니다.\n- 그들은 누구도 묻지 못할 질문을 합니다.\n- 중요한 것과 소음을 분리합니다.\n- 지금 해야 할 일과 펀트할 일을 식별합니다.\n이것이 수석 엔지니어가 급여를 받을 가치가 있는 이유 중 하나입니다. 좋은 코드를 작성하기 때문이 아니라(종종 그렇게 합니다!) **프로젝트를 망치기** 때문입니다. 그들은 *\"이게 뭔지도 모르겠어요\"*를 *\"작은 프로젝트가 두 개 있고 한 가지는 잘라야 해요\"*로 바꿉니다.\n그리고 웃긴 게 뭔지 아세요? 선임 엔지니어들이 이 일을 잘하면 쉬워 보입니다. 아무 일도 일어나지 않은 것처럼. 프로젝트는… 순조롭게 진행되고 있어요. 놀라움, 생산 화재 또는 긴급 회의가 줄어듭니다. 그러나 실제로 일어난 일은 누군가가 눈에 보이지 않는 많은 일을 미리 해냈다는 것입니다.\n예를 들어 수석 엔지니어가 묻는 몇 가지 질문은 다음과 같습니다.\n- **우리가 실제로 해결하려는 문제는 무엇입니까?** (우리가 원하는 솔루션이 아니라 근본적인 문제가 무엇입니까?)\n- **여기서 사용자는 누구이며 그들에게 고통스러운 것은 무엇입니까?** (구체적으로 설명하려고 합니다. \"사용자\"는 대답이 아닙니다.)\n- **우리는 그것이 틀릴 수 있다고 가정하고 있습니까?** (모든 계획에는 숨겨진 가정이 있습니다.)\n- **우리가 틀려서 이걸 배송하면 어떻게 되나요?** (단점은 얼마나 나쁜가요?)\n즉, 그들은 먼저 문제를 명확하게 합니다. 그런 다음에야 그들은 문제를 해결하러 갑니다.\n실망스러운 부분 중 하나는 많은 회사가 여전히 이를 채용하는 데 형편없다는 것입니다. 직무 설명에는 기술과 수년간의 경험이 나열되어 있습니다. 인터뷰는 LeetCode에 중점을 둡니다. 그 어느 것도 모호한 제품 요구 사항을 취하여 이를 배송 가능한 계획으로 전환하는 능력을 실제로 측정하지 않습니다.\n그래서 우리는 화이트보드에서 이진 트리를 뒤집을 수 있지만 사양이 반쯤 익었을 때 멈추는 \"선임\" 엔지니어를 갖게 됩니다.\n다른 것들이 중요하지 않다고 말하는 것이 아닙니다. 건축이 중요합니다. 의사소통이 중요합니다. **그러나 실제로 무엇을 만들고 있는지 파악하고 나면 이러한 것들은 훨씬 더 가치가 있습니다**. 모호성을 줄일 수 없다면 다른 모든 기술은 잘못된 문제를 해결하는 우아한 방법일 뿐입니다.\n따라서 귀하가 고위급 이상 수준에서 운영되고 있는지 궁금하다면 여기에 한 가지 테스트가 있습니다. 누군가가 당신에게 추상/모호/복잡한 것을 건네주면 어떻게 될까요? 다른 사람이 당신을 위해 그것을 명확히 해줄 때까지 기다리십니까? 즉시 코딩을 시작하고 최선을 다하길 바라시나요? 아니면 당신과 당신의 팀이 실제로 확신을 가지고 실행할 수 있을 만큼 충분히 구체적으로 만들기 위해 사전에 시간을 투자하고 있습니까?\n마지막이라면 아마 이미 거기에 있을 겁니다. 그렇지 않다면 좋은 소식은 이것이 재능이 아니라 연습이라는 것입니다. 당신에게 할당된 다음 모호한 티켓부터 시작하세요.\n### 이것을 공유하세요:\n- [\nFacebook에 공유하려면 클릭하세요(새 창에서 열림)\n페이스북\n](https://terriblesoftware.org/2025/11/25/what-actually-makes-you-senior/?share=facebook)\n- [\nLinkedIn에 공유하려면 클릭하세요(새 창에서 열림)\n링크드인\n](https://terriblesoftware.org/2025/11/25/what-actually-makes-you-senior/?share=linkedin)\n- [\n스레드에 공유하려면 클릭하세요(새 창에서 열림)\n스레드\n](https://terriblesoftware.org/2025/11/25/what-actually-makes-you-senior/?share=threads)\n- [\nBluesky에 공유하려면 클릭하세요(새 창에서 열림)\n블루스카이\n](https://terriblesoftware.org/2025/11/25/what-actually-makes-you-senior/?share=bluesky)\n- [\nMastodon에 공유하려면 클릭하세요(새 창에서 열림)\n마스토돈\n](https://terriblesoftware.org/2025/11/25/what-actually-makes-you-senior/?share=mastodon)\n- [\nX에서 공유하려면 클릭하세요(새 창에서 열림)\nX\n](https://terriblesoftware.org/2025/11/25/what-actually-makes-you-senior/?share=x)\n-",
    "source": "terriblesoftware.org",
    "sourceUrl": "https://terriblesoftware.org/2025/11/25/what-actually-makes-you-senior/",
    "category": "AI"
  },
  {
    "title": "Show GN: 리눅스를 위한 노트북 배터리 모니터 'Watt Monitor'",
    "content": "[![와트 모니터 스크린샷](https://raw.githubusercontent.com/jookwang-park/watt-monitor-rs/refs/heads/main/assets/preview.png)](https://raw.githubusercontent.com/jookwang-park/watt-monitor-rs/refs/heads/main/assets/preview.png)\n# 와트 모니터\n[](#와트-모니터)\n**Linux 노트북을 위한 경량 터미널 기반 전력 모니터링 도구입니다.**\n배터리 소비, 전력 소모(와트) 및 절전 효율성을 실시간으로 시각화합니다.\n---\n## 소개\n[](#소개)\n**Watt Monitor**는 Rust로 작성된 TUI(텍스트 사용자 인터페이스) 애플리케이션입니다. 실시간 차트에 배터리 용량(%)과 전력 소모량(W)을 표시하여 Linux 사용자가 노트북의 에너지 사용 패턴을 이해하는 데 도움이 됩니다.\n단순한 배터리 애플릿과 달리 Watt Monitor는 **Sleep/Suspend 기간**을 구체적으로 캡처하고 분석합니다. 노트북이 절전 모드인 시간을 시각화하고 해당 시간 동안의 배터리 소모율을 계산하여 \"수면 소모\" 문제를 식별하는 데 도움이 됩니다.\n### 주요 기능\n[](#주요 기능)\n- **실시간 대시보드**: 용량(청록색)과 전력(노란색)을 표시하는 이중 축 차트.\n- **지능형 수면 감지**: 수면 기간을 자동으로 감지하고 차트에서 빈 공백을 제거하며 기상 시간을 표시합니다.\n- **수면 분석**: 수면 중 지속 시간과 배터리 손실 비율을 표시합니다.\n- **유연한 보기 모드**: 최근 보기(30분, 1시간, 4시간, 12시간)와 하루 종일 보기 간에 전환합니다.\n- **이력 탐색**: 자동으로 보관된 지난 일일 로그를 찾아보세요.\n- **경량 데몬**: 백그라운드 서비스(systemd 또는 OpenRC)를 사용하여 리소스에 미치는 영향을 최소화하면서 데이터를 기록합니다.\n## 설치\n[](#설치)\n### 전제 조건\n[](#전제조건)\n- 러스트(화물)\n-만들다\n- Systemd 또는 OpenRC(백그라운드 로거용)\n### 소스에서 빌드\n[](#소스에서 빌드)\n저장소를 복제하고 제공된 Makefile을 사용하여 설치합니다.\n````\n자식 클론 https://github.com/jookwang-park/watt-monitor-rs.git\nCD 와트-모니터-rs\nsudo make 설치\n````\n이렇게 하면 바이너리가 `/usr/local/bin`에 설치되고 서비스 파일이 적절한 시스템 디렉터리에 설치됩니다.\n## 사용법\n[](#사용법)\nWatt Monitor는 데이터를 수집하는 백그라운드 **데몬**과 이를 보기 위한 **TUI** 인터페이스의 두 부분으로 구성됩니다.\n### 1. 백그라운드 데몬 활성화\n[](#1-백그라운드 데몬 활성화)\n배터리 데이터 수집을 시작하려면 서비스를 활성화하세요. 이는 백그라운드에서 자동으로 실행되며 4초마다 상태를 기록합니다.\n**시스템의 경우:**\n````\nsudo make 활성화\n# 또는 수동으로: sudo systemctl 활성화 --now watt-monitor.service\n````\n**\n참고**: SSD 수명을 보호하기 위해 처음에는 데이터가 `/tmp`에 기록되고 자정에 `~/.local/share/watt-monitor/`로 순환됩니다.\n### 2. 모니터 실행\n[](#2-모니터 실행)\n터미널을 열고 다음을 실행하세요.\n````\n와트 모니터\n````\n### 3. 주요 컨트롤\n[](#3-키 컨트롤)\n열쇠\n액션\n`탭`\n사이클 보기 모드(30분 → 1시간 → 4시간 → 12시간 → 전체)\n`h` 또는 `←`\n전날의 로그 보기\n`l` 또는 `→`\n다음 날의 로그 보기\n`q` 또는 `Esc`\n애플리케이션 종료\n## 제한\n[](#제한)\n배터리가 충전되는 동안 전력 사용량은 와트 단위로 확인할 수 있지만, 충전이 완료되면 0W로 보고됩니다. 이는 시스템이 AC 전원으로 직접 실행되기 때문입니다. 이 문제는 고칠 수 있지만 `sudo` 권한이 필요합니다. 현재 이 애플리케이션을 실행하기 위해 루트 액세스를 요구하는 것은 적절하지 않다고 생각합니다.\n## 🤝 기여하기\n[](#-기여)\n기여를 환영합니다! 버그 보고, 기능 제안, Pull Request 제출 등 여러분의 의견은 소중합니다.\n- 저장소를 포크하세요.\n- 기능 브랜치를 만듭니다(`git checkout -b feature/amazing-feature`).\n- 변경 사항을 커밋합니다.\n- 지점으로 푸시\n- 풀 리퀘스트 열기\n## 라이선스\n[](#라이센스)\n이 프로젝트는 MIT 라이선스에 따라 라이선스가 부여됩니다. 자세한 내용은 [LICENSE](/jookwang-park/watt-monitor-rs/blob/main/LICENSE) 파일을 참조하세요.",
    "source": "github.com",
    "sourceUrl": "https://github.com/jookwang-park/watt-monitor-rs",
    "category": "AI"
  },
  {
    "title": "Mac이 열로 인해 성능 저하(thermal throttling) 상태인지 알려주는 macOS 앱 개발기",
    "content": "# 내 Mac이 열 조절 중일 때를 알 수 있는 macOS 앱 구축\n2025년 12월 27일·2317 단어·11분\n마코스\n프로그래밍\n*\n목차\n**\n이 게시물은 [에서 논의되었습니다.\nHacker News](https://news.ycombinator.com/item?id=46410402) MacThrottle을 어떻게 구축했는지에 대한 이야기입니다.\n저는 지난 몇 년 동안 M2 MacBook Air에 매우 만족했습니다. 그러나 외부 디스플레이, 특히 4K 120Hz 디스플레이와 같이 매우 까다로운 디스플레이를 사용할 때 더 많은 어려움을 겪기 시작하는 것으로 나타났습니다. 팬이 부족하기 때문에 고군분투하는 소리는 들리지 않지만 모든 것이 매우 느리거나 응답하지 않게 되는 것을 느낄 수 있습니다. 이때 열 조절이 시작됩니다.\niStat 메뉴에서 CPU 사용량이 100%이고 전력 사용량(와트)이 감소하는 것을 볼 수 있기 때문에 열 조절이라는 것을 알고 있습니다.\nMX Power Gadget을 사용하면 더욱 분명해집니다. 사용량이 100%로 유지되면서 성능 코어의 전력 사용량과 빈도가 떨어지는 것을 볼 수 있습니다.\n또한 내 업무용 MacBook Pro에서도 열 조절이 발생했습니다. 14인치 M4 Max 변형은 [최악의 변형임](https://www.bestlaptop.deals/articles/m4-macbook-pros-ultimate-review-performance-power-efficiency-battery-life?utm_source=chatgpt.com#Sustained-Performance)입니다. 14인치의 열 포락선이 M4 Max의 최대 출력에 비해 너무 작기 때문입니다. 이전 14인치 M1 Pro MacBook Pro에서는 3년 동안 팬 소리를 들어본 적이 없습니다&mldr;\n그렇긴 하지만, 나는 여전히 성능과 전력 사용량 면에서 Apple Silicon을 좋아합니다. Intel 시대에 비해 여전히 극적인 개선이 이루어진 것입니다. 🫶\n어쨌든, 저는 알고 싶었습니다. Apple Silicon SoC가 내 스크린샷과 같은 경험적 방법을 기반으로 하지 않고 열 조절 기능을 수행하는지 알 수 있는 방법이 있습니까?\n## 프로그래밍 방식으로 열 상태 가져오기 #\n이것은 내가 예상했던 것보다 더 거친 여행이었습니다. Mac이 제한되어 있는지 프로그래밍 방식으로 알 수 있습니다. macOS는 다양하지만 일관되지 않은 방식으로 이를 노출하기 때문입니다.\nApple이 권장하는 접근 방식은 `Foundation`의 `ProcessInfo.thermalState`를 사용하는 것입니다.\n````\n➜ ~ Swift -e '재단 가져오기; print([\"명목\", \"공정\", \"심각함\", \"위험\"][ProcessInfo.processInfo.thermalState.rawValue])'\n명목상의\n````\n좋은 것 같죠? 그러나 루트가 필요하더라도 다른 도구가 이 정보를 제공할 수 있다는 것을 알고 있었습니다: `powermetrics`.\n````\n➜ ~ sudo powermetrics -s 열\n비밀번호:\n기계 모델: Mac14,2\nOS 버전: 25B78\n부팅 인수:\n부팅 시간: 2025년 11월 23일 일요일 10:19:29\n*** 샘플링된 시스템 활동(Wed Dec 17 09:48:34 2025 +0100) (5001.07ms 경과) ***\n**** 열압력 ****\n현재 압력 수준: 공칭\n*** 샘플링된 시스템 활동(Wed Dec 17 09:48:39 2025 +0100) (5001.25ms 경과) ***\n**** 열압력 ****\n현재 압력 수준: 공칭\n````\n(예, 출력에 줄 바꿈이 너무 많습니다)\n둘 다 압력 수준이 \"명목상\"이라고 보고하므로 동일해야 합니다. 맞습니까?\n몇 가지 스트레스 테스트 `stress-ng --cpu 0 -t 600`을 실행한 후 두 값이 갈라지는 것을 확인하기 시작했습니다!\n어떤 이유로 `ProcessInfo.thermalState`와 `powermetrics` 사이의 세분성이 다릅니다. 가능한 상태의 양이 다르며 정렬되지 않습니다.\n내 경험적 경험은 다음과 같습니다.\n`ProcessInfo.thermalState``powermetrics`nominalnominalfair****moderate****fair****heavy**이러한 상태에 도달한 적이 없어서 일치하는지 모르겠지만 기술적으로 정의되어 있습니다.\n`ProcessInfo.thermalState``powermetrics`심각한 트랩핑중요수면실제로 내 Mac이 뜨거워지기 시작하면 `powermetrics' 관점에서 보면 '보통'으로 들어가고 조절이 시작되면 '무거움'으로 들어갑니다. 문제는 `ProcessInfo`를 사용하면 둘 다 `fair` 상태에 포함되므로 Mac이 실제로* 조절 중인지 아는 것이 실제로 유용하지 않다는 것입니다. ☹️\n아마도 이것이 iOS와 macOS의 문제인 줄 알았는데? 그러나 Apple은 macOS 문서에서도 이를 참조합니다. Intel Mac에서는 더 일관성이 있었을까요?\n나는 2020년부터 Apple 관련 작업을 하고 있는 Google 직원인 Dave MacLachlan의 이 기사를 우연히 발견했습니다. 열 데이터를 얻을 수 있는 다른 CLI 도구가 있다는 것을 알게 되었지만 내 Apple Silicon MacBook에서는 작동하지 않는 것 같습니다.\n````\n➜ sudo 열 수준\n이 시스템에서는 열 수준이 지원되지 않습니다.\n````\n````\n➜ sudo pmset -g thermolog\n참고: 열 경고 수준은 기록되지 않았습니다.\n참고: 성능 경고 수준은 기록되지 않았습니다.\n참고: CPU 전원 상태는 기록되지 않았습니다.\n^C\n````\n하지만 제가 배운 가장 흥미로운 점은 'powermetrics'가 보여주는 데이터가 실제로 'thermald'에서 나온다는 것입니다. 그리고 'thermald'는 현재 열압력을 Darwin 알림 시스템에 기록합니다.",
    "source": "stanislas.blog",
    "sourceUrl": "https://stanislas.blog/2025/12/macos-thermal-throttling-app/",
    "category": "AI"
  },
  {
    "title": "바이브의 해",
    "content": "[Armin Ronacher](/about/)의 생각과 글\n[블로그](/)\n[아카이브](/아카이브/)\n[프로젝트](/프로젝트/)\n[여행](/여행/)\n[대화](/대화/)\n[정보](/정보/)\n# 바이브의 한 해\n2025년 12월 22일에 작성됨\n2025년이 다가오고 꽤 1년이 지났습니다. 제가 작년 이맘때쯤에\n[내 삶을 돌아보는](/2024/12/26/reflecting-on-life/) 글을 작성했습니다. 있었다\n프로그래밍에 관해 글을 썼는데, 2025년이 1년이 되었기 때문에 너무 오래됐을 수도 있습니다.\n내 직업에는 다른 어떤 것과도 같지 않습니다.\n## 2025년은 달랐다\n2025년은 변화의 해였습니다. 나는 Sentry를 떠나 새로운 일을 시작했을 뿐만 아니라\n회사에서는 제가 이전에 하던 방식으로 프로그래밍을 중단한 해이기도 했습니다. [에\nJune](/2025/6/4/changes/) 마침내 그것을 내 방식대로 공유할 수 있을 만큼 자신감이 생겼습니다.\n일하는 방식이 달랐어요:\n> \nCursor에서 대부분의 시간을 보냈던 곳에서는 지금은 Claude Code를 주로 사용합니다.\n거의 완전히 손을 떼고 있습니다. [...] 딱 6개월만이라도 말해줬으면\n그 전에는 가상 프로그래머 인턴보다 엔지니어링 리드가 되는 것을 더 선호했습니다.\n직접 건반을 치는 것에 대해 나는 그것을 믿지 않았을 것입니다.\n작년에 더 많은 글을 쓰고 싶었지만 그 욕망은 아무 상관이 없었습니다.\n에이전트 코딩으로. 하지만 나는 36개의 게시물을 게시했습니다. 이는 이 게시물의 전체 게시물 중 거의 18%에 해당합니다.\n2007년부터 블로그를 운영했습니다. 프로그래머들과도 백 번 정도 대화를 나눴습니다.\n창립자들과 다른 사람들이 AI에 대해 궁금해한 이유는\n요원의 토끼굴에 빠지다.\n2025년은 또한 세계적으로 그다지 좋지 않은 해였습니다. 나는 그것과 평화를 이루기 위해\n내 생각을 정리하기 위해 [별도의 블로그를 시작했습니다](https://dark.ronacher.eu/)\n여기에서.\n## 에이전트의 해\n4~5월 클로드 코드에 대한 집착이 커지면서 시작됐고,\n내 에이전트를 구축하고 다른 에이전트를 사용하는 데 몇 달이 걸렸습니다. 소셜 미디어가 폭발했다\nAI에 대한 의견: 좋은 것도 있고 나쁜 것도 있습니다.\n이제 나는 우리가 어디에 있는지 추론하는 방법에 대한 새롭고 안정적인 현상 유지를 발견했다고 느낍니다.\n우리는 어디에 있고 어디로 가는지. 코드 생성, 파일 시스템,\n통역사 글루를 통한 프로그래밍 방식 도구 호출 및 기술 기반 학습.\n기본적으로 Claude Code가 혁신한 것은 여전히 ​​나에게 최첨단 기술입니다. 그\n지난 몇 달 동안 매우 잘 작동했으며 기초 모델을 보았습니다.\n제공업체가 기술을 두 배로 늘리면 이 접근 방식에 대한 나의 믿음이 강화됩니다.\n저는 TUI가 어떻게 그렇게 강력한 복귀를 했는지 아직도 당황스럽습니다. 지금 이 순간 나는\n[Amp](https://ampcode.com/) 사용, [Claude\n코드](https://claude.com/product/claude-code) 및\n[Pi](https://shittycodingagent.ai/), 모두 명령줄에서 가능합니다. 앰프는 이런 느낌이에요\n에이전트 코딩 도구의 Apple 또는 Porsche, Claude Code는 저렴한 가격으로 제공됩니다.\nVolkswagen과 Pi는 해커가 선택한 오픈 소스입니다. 그들 모두는 느낀다\n나처럼 건강에 해로운 정도로 사용하는 사람들이 만든 프로젝트처럼\n자신만의 제품을 만들지만 서로 다른 장단점이 있습니다.\n저는 도구 실행과 결합된 LLM이 할 수 있는 일에 계속해서 놀랐습니다. 에\n연초에는 주로 코드 생성에 사용했지만 지금은\n내 에이전트 사용 횟수는 일상적인 것입니다. 우리가 좀 볼 거라고 확신해요\n2026년 소비자 제품에 대한 흥미진진한 추진이 이루어지고 있습니다. 이제 LLM이 저를 도와주고 있습니다.\n내 삶을 정리하고, 그것이 더욱 성장할 것으로 기대합니다.\n## 기계와 나\n이제 LLM은 프로그래밍에 도움을 줄 뿐만 아니라 내 인생을 다시 생각하게 되었어요.\n그 기계와의 관계. 창조하지 않는 것이 점점 더 어려워진다\n내가 사용하는 일부 도구와의 준사회적 유대감. 나는 이것이 이상하다고 생각하고\n불편하다. 오늘날 우리가 사용하는 대부분의 에이전트는 기억력이 부족하고\n성격은 별로 없지만 그런 성격을 스스로 만드는 것은 쉽습니다. LLM\n기억은 떨쳐내기 힘든 경험이다.\n흥미롭기도 하고 의심스럽기도 합니다. 나는 두 가지를 위해 나 자신을 훈련하려고 노력했습니다.\n이러한 모델을 단순한 토큰 텀블러로 생각하기에는 몇 년이 걸렸지만, 그 환원적인 관점은\n더 이상 작동하지 않습니다. 우리가 지금 만들고 있는 이 시스템에는 인간이 있습니다.\n그러나 그것을 인간 수준으로 끌어올리는 것은 실수입니다. 나\n점점 더 이 기계를 \"에이전트\"라고 부르는 것에 대해 문제를 제기하고 있습니다.\n더 나은 단어입니다. 나는 \"대리인\"이라는 용어에 대해 문제를 제기합니다.\n책임은 인간에게 남아야 한다. 그들이 무엇이 되든, 그들은 할 수 있다\n우리 안에서 감정적인 반응을 촉발합니다.\n해롭지 않은 경우](https://en.wikipedia.org/wiki/Chatbot_psychosis)\n조심해. 이러한 창조물에 적절한 이름을 지정하고 관련성을 배치하는 우리의 무능력\n우리에게는 해결해야 할 과제가 있습니다.\n의도하지 않은 의인화 때문에 저는 정말 힘들어요.\n방법에 대한 올바른 단어를 찾는 시간",
    "source": "lucumr.pocoo.org",
    "sourceUrl": "https://lucumr.pocoo.org/2025/12/22/a-year-of-vibes/",
    "category": "AI"
  },
  {
    "title": "uv가 이렇게 빨라진 이유",
    "content": "# UV는 어떻게 그렇게 빨리 변했나요?\n2025년 12월 26일\nuv는 pip보다 훨씬 빠르게 패키지를 설치합니다. 일반적인 설명은 \"Rust로 작성되었습니다.\"입니다. 그것은 사실이지만 많은 것을 설명하지는 않습니다. 많은 도구가 Rust로 작성되었지만 그다지 빠르지는 않습니다. 흥미로운 질문은 어떤 디자인 결정이 변화를 가져왔는지입니다.\nCharlie Marsh의 [Jane Street talk](https://www.janestreet.com/tech-talks/uv-an-extremely-fast-python-package-manager/) 및 [Xebia 엔지니어링 심층 분석](https://xebia.com/blog/uv-the-engineering-secrets-behind-pythons-speed-king/)에서 기술적인 세부 사항을 잘 다루고 있습니다. 흥미로운 부분은 디자인 결정입니다. 빠른 경로를 가능하게 하는 표준, pip가 지원하는 uv drop, Rust가 전혀 필요하지 않은 최적화입니다.\n## UV를 가능하게 한 기준\npip의 느린 속도는 구현 실패가 아닙니다. 수년 동안 Python 패키징에서는 패키지에 필요한 것이 무엇인지 알아내기 위해 코드를 실행해야 했습니다.\n문제는 [setup.py](https://setuptools.pypa.io/)였습니다. 설정 스크립트를 실행하지 않으면 패키지의 종속성을 알 수 없습니다. 그러나 빌드 종속성을 설치하지 않으면 설정 스크립트를 실행할 수 없습니다. 2016년 [PEP 518](https://peps.python.org/pep-0518/)에서는 이를 명시적으로 언급했습니다. \"종속성을 알지 못하면 setup.py 파일을 실행할 수 없습니다. 그러나 현재 setup.py 파일을 실행하지 않고 자동화된 방식으로 이러한 종속성이 무엇인지 알 수 있는 표준 방법은 없습니다.\"\n이 닭과 달걀 문제로 인해 pip는 패키지를 다운로드하고, 신뢰할 수 없는 코드를 실행하고, 실패하고, 누락된 빌드 도구를 설치하고, 다시 시도해야 했습니다. 모든 설치는 잠재적으로 일련의 하위 프로세스 생성 및 임의 코드 실행이었습니다. 소스 배포판을 설치하는 것은 본질적으로 `curl | 추가 단계를 거쳐 bash`를 실행합니다.\n수정 사항은 단계적으로 이루어졌습니다.\n- [PEP 518](https://peps.python.org/pep-0518/)(2016)은 pyproject.toml을 생성하여 패키지에 코드 실행 없이 빌드 종속성을 선언할 수 있는 장소를 제공합니다. TOML 형식은 Rust의 Cargo에서 빌려왔기 때문에 Python 패키징을 수정하기 위해 돌아오는 Rust 도구가 우연처럼 느껴지지 않습니다.\n- [PEP 517](https://peps.python.org/pep-0517/) (2017)은 빌드 프런트엔드를 백엔드에서 분리했으므로 pip는 setuptools 내부를 이해할 필요가 없었습니다.\n- [PEP 621](https://peps.python.org/pep-0621/)(2020)은 `[project]` 테이블을 표준화하여 Python을 실행하는 대신 TOML을 구문 분석하여 종속성을 읽을 수 있었습니다.\n- [PEP 658](https://peps.python.org/pep-0658/)(2022)은 패키지 메타데이터를 Simple Repository API에 직접 넣으므로 해석기가 휠을 전혀 다운로드하지 않고도 종속성 정보를 가져올 수 있습니다.\nPEP 658은 2023년 5월 PyPI에 출시되었습니다. uv는 2024년 2월에 출시되었습니다. uv는 마침내 생태계에 이를 지원하는 인프라가 갖춰져 있었기 때문에 빠를 수 있었습니다. uv와 같은 도구는 2020년에 출시될 수 없었습니다. 표준은 아직 없었습니다.\n다른 생태계에서는 이를 더 일찍 알아냈습니다. Cargo에는 처음부터 정적 메타데이터가 있었습니다. npm의 package.json은 선언적입니다. Python의 패키징 표준은 마침내 이를 동등하게 만듭니다.\n## 자외선이 떨어지는 것\n속도는 제거에서 비롯됩니다. 가지고 있지 않은 모든 코드 경로는 기다리지 않는 코드 경로입니다.\nuv의 [호환성 문서](https://docs.astral.sh/uv/pip/compatibility/)에는 수행되지 않는 작업의 목록이 나와 있습니다.\n**.egg는 지원되지 않습니다.** 계란은 휠 이전 바이너리 형식이었습니다. pip는 여전히 이를 처리합니다. uv는 시도조차 하지 않습니다. 이 형식은 10년 넘게 사용되지 않았습니다.\n**pip.conf 없음.** uv는 pip의 구성 파일을 완전히 무시합니다. 구문 분석, 환경 변수 조회, 시스템 전체 및 사용자별 위치에서의 상속이 없습니다.\n**기본적으로 바이트코드 컴파일은 없습니다.** pip는 설치 중에 .py 파일을 .pyc로 컴파일합니다. uv는 이 단계를 건너뛰므로 설치할 때마다 시간이 단축됩니다. 원하는 경우 선택할 수 있습니다.\n**가상 환경이 필요합니다.** pip를 사용하면 기본적으로 Python 시스템에 설치할 수 있습니다. uv는 이를 반전시켜 명시적인 플래그 없이 시스템 Python을 터치하는 것을 거부합니다. 이렇게 하면 권한 확인 및 안전 코드의 전체 범주가 제거됩니다.\n**더 엄격한 사양 적용.** pip는 기술적으로 패키징 사양을 위반하는 잘못된 형식의 패키지를 허용합니다. uv는 그들을 거부합니다. 허용 오차가 적다는 것은 대체 논리가 적다는 것을 의미합니다.\n**파이썬 상한값 무시.** 패키지에 `python<4.0`이 필요하다고 표시되면 uv는 상한값을 무시하고 하한값만 확인합니다. 이는 상한이 거의 항상 틀리기 때문에 리졸버 역추적을 극적으로 줄여줍니다. 패키지는 `python<4.0`을 선언합니다. 왜냐하면 실제로 중단될 것이기 때문이 아니라 Python 4에서 테스트되지 않았기 때문입니다. 제약 조건은 예측이 아닌 방어적입니다.\n**첫번째 인덱스 승리",
    "source": "nesbitt.io",
    "sourceUrl": "https://nesbitt.io/2025/12/26/how-uv-got-so-fast.html",
    "category": "AI"
  },
  {
    "title": "Show GN: VSCode Run Configurations - IntelliJ 스타일의 실행 환경 구성 Extension",
    "content": "[\r*\r| 마켓플레이스\n](/)\r[\r로그인\r](https://app.vssps.visualstudio.com/_signin?realm=marketplace.visualstudio.com&reply_to=https%3A%2F%2Fmarketplace.visualstudio.com%2Fitem s%3FitemName%3Dmansukim.run-configurations&redirect=1&context=eyJodCI6MywiaGlkIjoiMjY2M2IxM2YtNTBlMy1hNjU1LWExNTktMjJmNmY0NzI1ZmFiIiwicXMi Ont9LCJyciI6IiIsInZoIjoiIiwiY3YiOiIiLCJjcyI6IiJ90&lltid=8468c86e-5082-4e50-a714-180b203004f7&workflowId=marketplace&wt.mc_id=o~msft~market 장소~signIn#ctx=eyJTaWduSW5Db29raWVEb21haW5zIjpbImh0dHBzOi8vbG9naW4ud2luZG93cy5uZXQiLCJodHRwczovL2xvZ2luLm1pY3Jvc29mdG9ubGluZS5jb20iXX01)\r**\r[Visual Studio Code](/vscode)>[기타](/search?sortBy=Installs&category=Other&target=VSCode)>실행 구성Visual Studio Code를 처음 사용하시나요? [지금 다운로드하세요.](https://go.microsoft.com/fwlink?linkid=846418&pub=mansukim&ext=run-configurations&utm_source=vsmp&utm_campaign=mpdetails)\n![구성 실행](https://cdn.vsassets.io/v/M266_20251205.4/_content/Header/default_icon_128.png)\n# 구성 실행\n## [만수김](출판사/만수킴)\n| \n33개 설치[ | ![](https://cdn.vsassets.io/v/M266_20251205.4/_content/EmptyStarDark.svg)![](https://cdn.vs 자산.io/v/M266_20251205.4/_content/EmptyStarDark.svg)![](https://cdn.vsassets.io/v/M266_2 0251205.4/_content/EmptyStarDark.svg)![](https://cdn.vsassets.io/v/M266_20251205.4/_content /EmptyStarDark.svg)![](https://cdn.vsassets.io/v/M266_20251205.4/_content/EmptyStarDark.svg) (0)](#review-details) | VSCode용 FreeRun/디버그 구성\n[설치\n](vscode:extension/mansukim.run-configurations)[설치에 문제가 있습니까?*](https://aka.ms/vscode_extn_install)\n개요버전 내역Q & AR평가 & 리뷰\n# 구성 실행\n[![](https://img.shields.io/badge/version-0.1.4-blue.svg)](https://github.com/mansukim1125/run-configurations)\n[![](https://img.shields.io/badge/license-MIT-green.svg)](https://github.com/mansukim1125/run-configurations/blob/HEAD/LICENSE)\n[![](https://img.shields.io/badge/VSCode-%5e1.107.0-007ACC.svg)](https://code.visualstudio.com/)\n직관적인 GUI를 통해 환경 변수로 명령 구성을 관리하기 위한 Visual Studio Code 확장입니다. 자주 사용하는 명령과 환경 설정을 한 곳에 정리하여 작업 흐름을 단순화하세요.\n## 기능\n- 시각적 구성 관리**: 전용 사이드바에서 모든 실행 구성을 찾아보고 관리합니다.\n- **단순화된 환경 변수**: 사용하기 쉬운 키-값 테이블 인터페이스를 통해 환경 변수를 설정하세요. 더 이상 수동으로 터미널을 내보낼 필요가 없습니다.\n- **GUI 기반 편집기**: JSON을 수동으로 편집하는 대신 WebView 양식을 사용하여 구성을 생성하고 편집합니다.\n- **터미널 통합**: 환경 변수가 자동으로 주입된 전용 터미널에서 구성을 실행합니다.\n- **Clean Execution**: 각 구성은 체계적인 실행 기록을 위해 터미널을 재사용합니다.\n## 스크린샷\n![구성 확장 실행](https://github.com/mansukim1125/run-configurations/raw/HEAD/assets/images/screenshot.png)\n## 요구 사항\n- Visual Studio Code 버전 1.107.0 이상\n- Node.js 및 npm(개발용)\n## 설치\n### VS Code 마켓플레이스에서\n[Visual Studio Code Marketplace](https://marketplace.visualstudio.com/items?itemName=mansukim.run-configurations)에서 직접 설치하세요.\n또는 VSCode 확장 보기(`Ctrl+Shift+X` / `Cmd+Shift+X`)에서 \"구성 실행\"을 검색하세요.\n### 소스/VSIX에서\n- 이 저장소를 복제하세요.\n- `npm install`을 실행하여 종속성을 설치합니다.\n- 확장 패키지: `npx vsce package`\n- 생성된 `.vsix` 파일을 VSCode에 설치합니다.\n## 사용법\n### 구성 만들기\n- 활동 표시줄에서 \"구성 실행\" 아이콘을 클릭합니다.\n- 사이드바 헤더에서 **++**(추가) 버튼을 클릭합니다.\n- 구성 양식을 작성하십시오.\n**이름**: 표시 이름(예: \"백엔드 서버 실행\")\n- **명령**: 실행할 실행 파일(예: `npm`, `python`, `mvn`)\n- **인수**: 공백으로 구분된 인수(예: `start --port 3000`)\n- **작업 디렉터리**: 실행할 경로(기본값: `${workspaceFolder}`)\n- **환경 변수**: 환경 변수에 대한 키-값 쌍\n- **저장**을 클릭하세요.\n### 구성 실행\n- 사이드바 구성 옆에 있는 **▶**(실행) 버튼을 클릭하세요.\n- 명령은 \"실행: {구성 이름}\"이라는 전용 터미널에서 실행됩니다.\n- 환경 변수가 터미널 세션에 자동으로 주입됩니다.\n### 구성 편집\n- 사이드바 구성 옆에 있는 **⚙** (편집) 버튼을 클릭하세요.\n- 편집기에서 필드 수정\n- 변경사항을 유지하려면 **저장**을 클릭하세요.\n### 구성 삭제",
    "source": "marketplace.visualstudio.com",
    "sourceUrl": "https://marketplace.visualstudio.com/items?itemName=mansukim.run-configurations",
    "category": "AI"
  },
  {
    "title": "기계가 되지 말라",
    "content": "# 기계가 되지 마세요\n*\n2025년 12월 24일\n*\n최근에 다음 제목의 YouTube 동영상을 추천받았습니다.\n**\n오직 노예만이 생산성을 통해 자신의 존재를 수량화합니다.\n````\n'''''',,,,,,,,,,,,'''''.''''''..''''''.................................................................................................................. ... \n'''''',,,,,,,,,,,'''''''''''''''''''''............................................................................................................................ \n''''';;,,,,,,''''''''''''''''''''''''................................................................................................................................ ...... \n''',,,;;,,,,,,,'''''''''''''..................................................................................................................................................... \n''',,,,,,,,,,,,,''''''''''.................................................................................................................................................. . \n'''''',,,,,,,,,,,,'''''''..................................................................................................................................................................... \n''''''',,,,,;;,,,'''''''................................................................................................................''.,:cclcllllllooooodxddxxxxkkxdddddddolcc:;, \n'''''',,,,,,,,,,,''''''''...................................................................................................'',:::cloooxOXNNXXXKKK0000OOO0K00OOOkOOkkkOOOOOOOO000OOkxdolcccc:, \n'''',,,',,,,,,,,'''''''''.....................................................................................:cooolodolllodoolloxkk0KXXXKK00kkkxxdddddxO000OxxxxxxddddxxkkO000KKKKKKKKKKKXXK0Oxoc: \n''',,,,'',,,,,,,,,,,'''''.....................................................................................,:ldkKXNNX0xoolccccllodk0KKKK0OkOkkxxxdoollccclodoolllllllllcllooddxxkOOO0KKXXXXXXXXXKK000Okxo:;;::,...... \n'','''''',,,,,',,,'''''''........................................................................... cox0XNWWWWWNNNXK0OOkkOO0KXKK0Okxollc::;;;,''..........................'',,,;:codxk0KKKKK00000OOOkxlclkklcllol'. \n''',,,,'',,,,,,'','''''''................................................................................';lkKXXXXXNWNNNNNNNXNNXXKKK0Oxdol:;'.......'''''......''''.'',:ccc:,'''.''..........',,:ldxO00Okkkkocldl,;;cxkl,... \n''',,,,''',,,,,,,,''''''''..................................................................':lx0XNNXK0KXXXNN NNNXXNXKKOxdo:;,.......'''''''',,,.......',,'''',;,'''''',;,.''..'..''..........':dkkkxkOocll;,:c::ll;;:;;,.. \n''''',,,'',,,,'''...'''.....................................................';lx0XNXKOdoc;,cOXXNNXXKKKKOoc,...............'...,'..,;,...'.....,::,,c:,:c;..,''cl,;l;.;c;........:dxxxdc;:;,cxOOkxl,';oxkdl:,.. \n''',,,,''',,,,,''''....'''..................................................................coxOKK0kxxl,....;o0NNX00000O d;...''..............;'';:;,';:,,;cc,,c;.,:;;cc;,c:';:,.';.,c,';:,':c,'::'';..lxxxl;,,;:lodxOKK0xlclokOOkxo:'.... . \n,,,,,,,',,,,,''''''''''''................................................,;:codkOOxol::;'..':d0X0xo:;:xOOx, ..':cc,...'..,::'';;,,:c:;:lc;';c;,::,;:,,;;',c:',,.';;..;'.,,.';;..;,.,;'',,:ooddoooddlloxko:o0NN0xollxOKK0kdc;'.. .. \n,'''''''',,,'''''''''''''.....................................................lxkOkdddolcc;'..',cxOOdc;,,'.;dO0k:.. ,;,,;'',;cc:;;;,;:;,:l:,:c;.':;,'':;'';,''..,;'....''..'..''',;;;:clllloodkOKXXXXNNKkxdxxkKKl'lOkkKX0xolxO0XXXKkdc,.... .. \n''''''''',,,,''''''''''.....................................................'lk0KOdoolooddolc:coxo:;;,'...'lkO00x;',,, ,;cc;,,:lc'';;',:,.,;'.,,..,;;'.',..'.....',,',,,;,:lloddkOOOO0KKKKXX00KXNWWWWMWxlOOOOlxNx.,d:.;oOXXOxox0XXXXNXKOd:'..... \n,,''''',,,,,,,,,''''''''................................................................':xKNKd::clodxkkkxdddddddoclc,...:xkkkkOxc:::c :,,;c;.,c:'.'......''.....',,'.',;;::cloddddddxxxOKKXXXNNNNWNNNNNNNX000XWMWWWWWKdollookk;.lkc',',:d0XKOxk00OOOO0KK0xl;'... \n'''''',,,,,,,,,''''''''''.................................................................lxOXNKkooooodxxxkkOkdollolloollc;coodxkxkkdc;,; ,..,;,';cccclooollllloodxkkkkOOkkkkO0OOOOkxddxOKXXNWNWWWWMMWWWWWNX0OO00KXXXXK0Oxl:;;:;',lOOc,::;;;:cxKXKko:,',;:lk0KKOdc'.. . \n''''',,,,,'',,,''''''''''...............................................locccc:cllllccloodxxxdlcclooooodxkkdlc:lc:lddddood dxO0K0OO0000KKKKKXXXNNWWWWNNNNX0OkkkOOkkkOOkOKXNWWWWWWWWWWWWNNXK0OOxdoolc::::'''....,cxOKk:,;cllllc::lkXXOl,.....,:lxOK0kl;.",
    "source": "armeet.bearblog.dev",
    "sourceUrl": "https://armeet.bearblog.dev/becoming-the-machine/",
    "category": "AI"
  },
  {
    "title": "Show GN: ff - fzf, fd, ripgrep을 결합한 파일 탐색/검색 도구",
    "content": "# 🔍 ff - 유연한 파일 찾기\n[](#-ff---유연한 파일 찾기)\n`fzf`를 사용하는 강력한 대화형 파일 검색 및 탐색 도구입니다. 빠르고 직관적인 파일 탐색 및 편집을 위해 파일 찾기(이름별)와 콘텐츠 검색(텍스트별) 모드 간에 원활하게 전환합니다.\n**찾기 모드**\n**그렙 모드**\n[![](/the0807/ff/raw/main/assets/find.gif)](/the0807/ff/blob/main/assets/find.gif)\n[![](/the0807/ff/raw/main/assets/grep.gif)](/the0807/ff/blob/main/assets/grep.gif)\n**디렉터리 변경**\n**파일 열기**\n[![](/the0807/ff/raw/main/assets/cd.gif)](/the0807/ff/blob/main/assets/cd.gif)\n[![](/the0807/ff/raw/main/assets/open.gif)](/the0807/ff/blob/main/assets/open.gif)\n## ✨ 특징\n[](#-기능)\n- 🔄 **이중 모드 작동**: 'TAB' 키를 한 번만 눌러 찾기 모드와 Grep 모드 사이를 즉시 전환합니다.\n- 🙌 **실시간 미리보기**: 구문 강조 기능이 포함된 실시간 파일 콘텐츠 미리보기\n- 🎨 **구문 강조**: `bat`/`batcat`을 사용한 아름다운 코드 표시\n- 🌳 **디렉토리 트리**: `eza` 또는 `tree`를 사용한 시각적 디렉토리 구조\n- ⚡ **Lightning Fast**: `fd` 및 `ripgrep`을 사용한 고속 검색\n- 📝 **편집기 통합**: VSCode 또는 선호하는 편집기에서 직접 파일 열기\n- 🎯 **라인으로 점프**: Grep 모드에서 일치하는 라인으로 직접 이동\n- 🔧 **스마트 폴백**: 선택적 종속성을 사용할 수 없는 경우 표준 Unix 도구와 함께 작동합니다.\n- 🎨 **아름다운 UI**: 아이콘, 색상, 직관적인 컨트롤을 갖춘 세련된 인터페이스\n## 📋 요구 사항\n[](#-요구사항)\n### 필수\n[](#필수)\n- **`fzf`** - 대화형 퍼지 파인더(핵심 종속성)\n### 선택 사항(강력히 권장)\n[](#선택사항-강력-권장)\n최상의 경험을 위해 다음을 설치하세요.\n도구\n목적\n대체\n`fd`\n빠른 파일 찾기\n'찾기'\n`ripgrep`(rg)\n빛처럼 빠른 콘텐츠 검색\n'그렙'\n'박쥐' 또는 '배트캣'\n구문 강조 미리보기\n'고양이'\n'에자'\n최신 디렉토리 트리\n`나무` 또는 기본 표시\n'나무'\n디렉토리 구조 시각화\n기본 디스플레이\n**\n참고:** `eza`를 사용할 때 디렉토리 트리의 아이콘을 보려면 [Nerd Font](https://www.nerdfonts.com/)를 설치해야 합니다. 인기 있는 선택 사항은 다음과 같습니다.\n- [JetBrains Mono Nerd 글꼴](https://www.nerdfonts.com/font-downloads)\n- [Fira Code Nerd 글꼴](https://www.nerdfonts.com/font-downloads)\n- [Hack Nerd 글꼴](https://www.nerdfonts.com/font-downloads)\n설치 후 Nerd 글꼴을 사용하도록 터미널을 구성하십시오.\n## 📦 종속성 설치\n[](#-설치-종속성)\n### macOS(홈브루)\n[](#macos-자작물)\n````\n양조 설치 fzf fd ripgrep bat eza tree\n````\n### 우분투/데비안\n[](#우분투데비안)\n````\nsudo 적절한 업데이트\nsudo apt install fzf fd-find ripgrep bat eza 트리\n````\n## 🚀 설치\n[](#-설치)\n### 방법 1: 빠른 설치(권장)\n[](#method-1-빠른 설치-권장)\n````\n컬 -fsSL https://raw.githubusercontent.com/the0807/ff/main/install.sh | 강타\n````\n그런 다음 셸을 다시 로드합니다.\n````\nsource ~/.zshrc # 또는 bash 사용자의 경우 ~/.bashrc\n````\n### 방법 2: 수동 설치\n[](#method-2-수동-설치)\n- **스크립트 다운로드:**\n````\n컬 -fsSL https://raw.githubusercontent.com/the0807/ff/main/ff.sh -o ~/.ff.sh\n````\n- **셸 구성에 추가:**\n**Zsh의 경우**(`~/.zshrc`):\n````\necho '소스 ~/.ff.sh' >> ~/.zshrc\n소스 ~/.zshrc\n````\n**Bash의 경우**(macOS에서는 `~/.bashrc` 또는 `~/.bash_profile`):\n````\necho '소스 ~/.ff.sh' >> ~/.bashrc\n소스 ~/.bashrc\n````\n## 📖 사용법\n[](#-사용법)\n### 기본 명령\n[](#기본 명령)\n````\nff # 찾기 모드에서 시작 (기본값)\nff find # 찾기 모드에서 시작(명시적)\nff grep # Grep 모드에서 시작\n````\n### 키 바인딩\n[](#키 바인딩)\n#### 공통 컨트롤\n[](#공통-컨트롤)\n열쇠\n액션\n`입력`\n파일/디렉토리로 이동\n'Ctrl-O'\n편집기에서 파일 열기(Grep 모드에서 일치하는 줄)\n`탭`\nFind와 Grep 모드 간 전환\n'Ctrl-U'\n미리보기를 위로 스크롤\n'Ctrl-D'\n미리보기를 아래로 스크롤\n`Esc`\n종료\n'Ctrl-C'\n취소/종료\n#### 찾기 모드\n[](#찾기 모드)\n- **파일 이름**으로 퍼지 검색을 입력하세요.\n- 선택한 파일의 디렉터리로 이동하려면 `Enter`를 누르세요.\n- 'Ctrl-O'를 눌러 편집기에서 파일을 엽니다.\n#### Grep 모드\n[](#grep-모드)\n- **파일 콘텐츠**로 검색하려면 입력하세요.\n- 줄 번호 및 컨텍스트와 일치하는 파일을 확인하세요.\n- `Enter`를 눌러 파일 디렉토리로 이동하세요.\n- 'Ctrl-O'를 눌러 일치하는 줄에서 파일을 엽니다.\n## 🎨 사용 예\n[](#-사용 예)\n### 예시 1: 빠른 파일 검색\n[](#예제-1-빠른 파일 검색)\n````\n$ff\n# \"config\"와 일치하는 파일을 찾으려면 \"config\"를 입력하세요.\n# 화살표 키를 사용하여 선택\n# Enter를 눌러 파일 디렉토리로 이동합니다.\n# 또는 Ctrl-O를 눌러 파일을 엽니다.\n````\n### 예 2: 검색 코드 콘",
    "source": "github.com",
    "sourceUrl": "https://github.com/the0807/ff",
    "category": "AI"
  },
  {
    "title": "Argc - Bash 기반의 강력한 CLI 빌드 프레임워크",
    "content": "# 인수\n[](#argc)\n[![CI](https://github.com/sigoden/argc/actions/workflows/ci.yaml/badge.svg)](https://github.com/sigoden/argc/actions/workflows/ci.yaml)\n[![상자](https://img.shields.io/crates/v/argc.svg)](https://crates.io/crates/argc)\nArgc는 모든 기능을 갖춘 CLI 구축을 단순화하는 강력한 Bash 프레임워크입니다. 인수 구문 분석, 사용법 텍스트, 오류 메시지 및 기타 상용구 코드를 처리하지 않고 핵심 논리에 초점을 맞춰 주석을 통해 CLI를 정의할 수 있습니다.\n[![데모](https://user-images.githubusercontent.com/4012553/228990851-fee5649f-aa24-4297-a924-0d392e0a7400. gif)](https://user-images.githubusercontent.com/4012553/228990851-fee5649f-aa24-4297-a924-0d392e0a7400.gif)\n## 기능\n[](#기능)\n- **간편한 인수 구문 분석:**\n플래그, 옵션, 위치 인수 및 하위 명령을 처리합니다.\n- 강력한 오류 처리를 위해 사용자 입력을 검증합니다.\n- 정보가 풍부한 사용법 텍스트를 생성합니다.\n- 인수를 해당 변수에 매핑합니다.\n- **독립형 Bash 스크립트 생성:**\nArgc 자체에 의존하지 않고 모든 기능을 통합하는 bash 스크립트를 빌드합니다.\n- **크로스 셸 자동 완성:**\n다양한 셸(bash, zsh, fish, powershell 등)에 대한 자동 완성 스크립트를 생성합니다.\n- **맨 페이지 생성:**\n스크립트에 대한 포괄적인 매뉴얼 페이지 문서를 자동으로 생성합니다.\n- **환경 변수 통합:**\n환경 변수를 옵션 및 위치 인수에 정의하고 검증하고 바인딩합니다.\n- **작업 자동화:**\nArgcfile.sh를 통해 작업을 자동화하는 Bash 기반 명령 실행기입니다.\n- **교차 플랫폼 호환성:**\nmacOS, Linux, Windows 및 BSD 시스템에서 Argc 기반 스크립트를 원활하게 실행하세요.\n## 설치\n[](#설치)\n### 패키지 관리자\n[](#패키지 관리자)\n- **Rust 개발자:** `cargo install argc`\n- **Homebrew/Linuxbrew 사용자:** `brew install argc`\n- **팩맨 사용자**: `yay -S argc`\n#### 사전 구축된 바이너리\n[](#사전 빌드된 바이너리)\n또는 [GitHub 릴리스](https://github.com/sigoden/argc/releases)에서 사전 구축된 macOS, Linux 및 Windows용 바이너리를 다운로드하여 추출하고 `argc` 바이너리를 `$PATH`에 추가하세요.\nLinux, MacOS 또는 Windows에서 다음 명령을 사용하여 최신 릴리스를 다운로드할 수 있습니다.\n````\n컬 -fsSL https://raw.githubusercontent.com/sigoden/argc/main/install.sh | sh -s -- --to /usr/local/bin\n````\n### GitHub 작업\n[](#github-actions)\n[install-binary](https://github.com/sigoden/install-binary)를 사용하여 GitHub Actions 워크플로에 argc를 설치할 수 있습니다.\n````\n- 사용: sigoden/install-binary@v1\n와:\n저장소: sigoden/argc\n````\n## 시작하기\n[](#시작하기)\nArgc를 사용하여 명령줄 프로그램을 구축하는 것은 매우 쉽습니다. 다음 두 단계를 따르세요.\n**1. CLI 인터페이스 설계:**\n주석 태그를 사용하여 옵션, 플래그, 위치 매개변수 및 하위 명령을 설명합니다(나중에 설명).\n**2. 인수 처리 활성화:**\n스크립트에 `eval \"$(argc --argc-eval \"$0\" \"$@\")\"` 줄을 추가하세요. 이는 Argc의 구문 분석 마법을 프로그램에 통합합니다.\n예를 들어 설명하겠습니다.\n````\n# @flag -F --foo 플래그 매개변수\n# @option --bar 옵션 매개변수\n# @option --baz* 옵션 매개변수(다중 발생)\n# @arg val* 위치 매개변수\neval \"$(argc --argc-eval \"$0\" \"$@\")\"\n에코 foo: $argc_foo\n에코 바: $argc_bar\n에코 바즈: ${argc_baz[@]}\n에코 값: ${argc_val[@]}\n````\n몇 가지 샘플 인수를 사용하여 스크립트를 실행합니다.\n````\n./example.sh -F --bar=xyz --baz a --baz b v1 v2\n````\nArgc는 이러한 인수를 구문 분석하고 `argc_` 접두사가 붙은 변수를 생성합니다.\n````\n푸: 1\n바: xyz\n바즈: a b\n값: v1 v2\n````\nCLI에 대해 자동으로 생성된 도움말 정보를 보려면 `./example.sh --help`를 실행하세요.\n````\n사용법: 예 [OPTIONS] [VAL]...\nARGS:\n[VAL]... 위치 매개변수\n옵션:\n-F, --foo 플래그 매개변수\n--bar <BAR> 옵션 매개변수\n--baz [BAZ]... 옵션 매개변수(다중 발생)\n-h, --help 도움말 인쇄\n-V, --version 인쇄 버전\n````\n이러한 간단한 단계를 통해 Argc를 활용하고 강력한 명령줄 프로그램을 만들 준비가 되었습니다!\n## 댓글 태그\n[](#comment-tags)\n주석 태그는 '@' 접두사와 특정 태그가 붙은 표준 Bash 주석입니다. 스크립트 기능을 구성하기 위해 Argc에 지침을 제공합니다.\n태그\n설명\n[`@describe`](/sigoden/argc/blob/main/docs/specation.md#describe)\n명령에 대한 설명을 설정합니다.\n[`@cmd`](/sigoden/argc/blob/main/docs/specation.md#cmd)\n하위 명령을 정의합니다.\n[`@alias`](/sigoden/argc/blob/main/docs/specation.md#alias)\n하위 명령에 대한 별칭을 설정합니다.\n[`@arg`](/sigoden/argc/blob/main/docs/specation.md#arg)\n위치 인수를 정의합니다.\n[`@option`](/sigoden/argc/blob/main/docs/특정",
    "source": "github.com",
    "sourceUrl": "https://github.com/sigoden/argc",
    "category": "AI"
  },
  {
    "title": "ChatGPT 광고 도입 임박: OpenAI가 검토 중인 3가지 수익화 전략",
    "content": "“ChatGPT에 광고는 없을 것”이라던 OpenAI의 말이 바뀌고 있습니다. 구글이 Gemini에 광고를 도입하겠다고 발표한 데 이어, OpenAI도 ChatGPT 내부에 광고를 넣는 방안을 구체적으로 검토 중인 것으로 드러났습니다.\n![](https://aisparkup.com/wp-content/uploads/2025/12/d3387bea-b771-447c-bf92-87377627f1de.jpg-1024x576.avif)사진 출처: The InformationThe Information의 보도에 따르면, OpenAI 내부에서는 ChatGPT의 답변에 스폰서 정보를 우선 배치하는 방식 등 여러 광고 모형을 검토하고 있다고 합니다. 2022년 말 출시 이후 광고 없이 운영되던 ChatGPT가 광고를 검토하게 된 배경에는 명확한 이유가 있습니다. 월 20달러 구독료만으로는 엄청난 인프라 비용을 감당할 수 없고, 수억 명의 무료 사용자를 수익화해야 한다는 압박이죠.\n**출처:** [OpenAI’s Ads Push Starts Taking Shape](https://www.theinformation.com/articles/openais-ads-push-starts-taking-shape) – The Information\n## 검토 중인 3가지 광고 전략\nOpenAI가 내부적으로 논의하는 광고 방식은 크게 세 가지입니다.\n첫 번째는 구매 의도가 명확한 대화에 스폰서 결과를 우선 배치하는 방식입니다. “노트북 추천해줘” 같은 질문에 광고주의 제품을 먼저 보여주는 거죠. 다만 이런 쿼리는 전체의 2.1%에 불과합니다. 아마존이나 구글의 검색광고 모델에서 영감을 받은 것으로 보이지만, 적용 범위가 매우 제한적이라는 한계가 있습니다.\n두 번째는 사용자의 대화 이력을 분석해서 맞춤형 광고를 보여주는 방식입니다. OpenAI는 사용자들이 ChatGPT와 나눈 모든 대화를 가지고 있습니다. 이 데이터를 마이닝하면 개인의 관심사와 니즈를 정교하게 파악할 수 있죠. 하지만 민감한 대화 내용까지 광고에 활용한다면 프라이버시 논란이 불가피합니다.\n세 번째는 대화와 관련된 광고를 사이드바에 표시하는 방식입니다. 답변 자체는 건드리지 않고 옆에 별도 광고 영역을 두는 것으로, 상대적으로 덜 침입적인 접근법이라고 할 수 있습니다.\n## 신뢰와 수익 사이의 줄타기\nOpenAI는 광고 도입이 사용자 경험을 해치고 신뢰를 떨어뜨릴 수 있다는 점을 우려하고 있습니다. 특히 민감한 주제를 다루는 대화에 광고가 끼어들면 사용자들이 챗봇을 신뢰하지 않게 될 수 있죠.\n하지만 현실적 압박도 만만치 않습니다. 구글과 메타는 매년 수천억 달러의 광고 수익을 올리고 있고, 구글은 이미 Gemini에 광고를 도입하겠다고 공언했습니다. OpenAI 입장에서는 광고 시장에 뛰어들지 않으면 경쟁에서 뒤처질 수밖에 없는 상황입니다.\n결국 핵심은 타이밍과 방식입니다. 너무 공격적으로 광고를 밀어붙이면 사용자가 떠날 것이고, 너무 조심스럽게 접근하면 수익화 속도가 느려집니다. OpenAI가 어떤 선택을 할지, 그리고 ChatGPT 사용자들이 광고를 받아들일지는 아직 미지수입니다. 한 가지 확실한 건, AI 챗봇 광고 시장의 문이 이제 열리기 시작했다는 점입니다.\n**참고자료:**\n- [Report: OpenAI has started mocking up what ads in ChatGPT could look like](https://sherwood.news/tech/report-openai-has-started-mocking-up-what-ads-in-chatgpt-could-look-like/) – Sherwood News\n- [OpenAI discusses an ad-driven strategy centered on ChatGPT scale and media partnerships](https://searchengineland.com/openai-discusses-an-ad-driven-strategy-centered-on-chatgpt-scale-and-media-partnerships-466818) – Search Engine Land",
    "source": "aisparkup.com",
    "sourceUrl": "https://aisparkup.com/posts/7724",
    "category": "AI"
  },
  {
    "title": "Attention Is All You Need 논문 리뷰: 셀프 어텐션과 자기회귀(Autoregressive)의 모든 것",
    "content": "![🤖](https://cdn.jsdelivr.net/gh/twitter/twemoji@14.0.2/assets/svg/1f916.svg)\n# Attention Is All You Need 논문 리뷰: 셀프 어텐션과 자기회귀(Autoregressive)의 모든 것\nAI Engineering 2025.12.23 \n📖 6분 읽기\n# 1. 서론: 자연어 처리의 패러다임을 바꾼 거인, 트랜스포머\n현대 생성형 인공지능의 근간인 트랜스포머(Transformer)는 “어텐션만 있으면 충분하다(Attention Is All You Need)“는 선언으로 기존 순환 구조(RNN)의 한계를 극복하고 현대 LLM의 표준이 되었다.\n병렬 연산(Parallel Computing)의 혁신과 문장 속 단어들 사이의 관계를 입체적으로 연결하여 텍스트의 숨은 의미와 맥락을 짚어내는 셀프 어텐션(Self-Attention)은 과연 어떻게 거대한 데이터를 지능으로 전환시키는 것일까?\nRNN은 단어를 하나씩 순서대로 처리해야 하기에 GPU의 병렬성을 활용하지 못했고, 문장이 길어질수록 앞단의 정보가 소실되는 치명적인 단점이 있었다. 구글은 순환(Recurrence)을 완전히 제거하고, 오직 어텐션만으로 시퀀스를 처리하는 아키텍처를 통해 이 문제를 해결했다.\n데이터가 트랜스포머라는 거대한 파이프라인을 통과하며 어떻게 의미를 갖게 되는지, 그 구조적 흐름을 딥다이브 해본다.\n# 2. 배경: 왜 RNN은 물러나야 했는가.\n트랜스포머 이전의 자연어 처리는 RNN기반의 Seq2Seq 모델이 주도했다. 하지만 두가지 치명적인 문제가 있었다.\n- 순차적 연산의 한계: RNN은 단어를 하나씩 순서대로 처리해야 한다. 이는 현대 GPU의 강점인 병렬 연산(Parallelism)을 활용하지 못하게 하여 대규모 학습을 방해했다.\n- 정보 소실 및 장기 의존성 문제: 문장이 길어질수록 앞부분의 정보가 뒤로 전달되지 못하고 희미해지는 현상이 발생했다.\n구글은 “Attention Is All You Need”라는 도발적인 제목의 논문을 통해, 순환 구조를 완전히 제거하고 오직 어텐션(Attention)만으로 시퀀스 데이터를 처리하는 트랜스포머를 내놓았다.\n# 3. 데이터 준비(Data Preparation)\n모델이 연산을 시작하기 전, 인간의 언어를 기계가 이해할 수 있는 수학적 형태로 변환하는 단계다.\n## 3.1 입력 임베딩 (Input Embedding)\n입력된 문장의 각 단어를 고차원의 벡터 공간으로 변환한다. 이를 통해 단어의 의미적 유사성을 수치화한다.\n## 3.2 포지셔널 인코딩 (Positional Encoding)\n![image.png](/_astro/image.AQr3Poj3_1LLIC7.webp)\n트랜스포머는 순환 구조가 없기 때문에 단어의 순서 정보를 알 수 없다. 따라서 단어 임베딩 벡터에 위치 정보를 담은 벡터를 더해준다.\n- 주기가 서로 다른 사인(Sine), 코사인(Cosine) 함수를 사용하여 각 위치마다 고유한 패턴을 부여한다.\n- 이를 통해 모델은 단어의 상대적인 위치 관계를 학습한다.\n![image.png](/_astro/image%201.H9rP3JR5_P9dN7.webp)\n# **4. 인코더 (Encoder): 문맥의 이해와 추상화**\n준비된 데이터는 먼저 인코더 스택을 통과한다. 인코더의 목적은 입력 시퀀스를 온전히 ‘이해’하여 문맥 정보가 함축된 벡터로 압축하는 것이다.\nNNN개의 동일한 레이어가 반복되며, 각 레이어는 두 개의 서브 레이어로 구성된다.\n## **4.1 멀티-헤드 셀프 어텐션 (Multi-Head Self-Attention)**\n문장 내 각 단어가 다른 단어들과 어떤 연관성이 있는지 계산한다. (예: “그는 사과를 먹었다”에서 “그는”과 “먹었다”의 관계 파악)\n- **입력/출력**: 입력 벡터 XXX로부터 Q,K,VQ, K, VQ,K,V를 모두 생성하여(Self), 문맥이 반영된 벡터 ZZZ를 출력한다.\n- **멀티-헤드(Multi-Head)** : 모델의 차원(dmodeld_{model}dmodel​)을 헤드 수(hhh)로 나누어 병렬로 처리한다. 이를 통해 문법적 관계, 의미적 연관성 등 서로 다른 특징을 독립적인 공간에서 입체적으로 학습한다.\n## **4.2 포지션-와이즈 피드 포워드 (Position-wise Feed-Forward Networks)**\n어텐션으로 추출된 특징을 정제하고 강화한다.\n- **프로세스**: 벡터 차원을 일시적으로 4배 확장(dffd_{ff}dff​)한 뒤 비선형 활성화 함수(ReLU)를 거쳐 다시 원래 차원으로 압축한다.\n- **의의**: 단순한 단어의 조합을 넘어 추상적인 맥락 정보를 학습하는 단계다.\n## **4.3 안정성을 위한 인프라: Add & Norm**\n모든 서브 레이어 뒤에는 **잔차 연결(Residual Connection)** 과 **층 정규화(Layer Normalization)** 가 뒤따른다.\n- **Add**: x+Sublayer(x)x + \\text{Sublayer}(x)x+Sublayer(x) 형태로 원본 정보를 보존하여 깊은 층에서도 학습이 잘 되도록 돕는다.\n- **Norm**: 데이터의 분포를 평균 0, 분산 1로 조정하여 학습 속도와 안정성을 확보한다.**인코더의 최종 출력**: 인코더의 마지막 레이어를 통과한 **키(Key)** 와 **값(Value)** 행렬은 입력 문장의 모든 정보를 담고 있으며, 이는 디코더의 모든 레이어로 복사되어 전달된다.\n# 5. 디코더(Decoder): 생성의 미학\n디코더는 인코더가 넘겨준 정보(K,VK, VK,V)와 자신이 지금까지 생성한 정보(QQQ)를 결합하여 다음 단어를 예측한다.\n## **5.1 마스크드 멀티-헤드 어텐션 (Masked Multi-Head Attention)**\n디코더의 첫 번째 관문이다. 자신의 이전 출력들을 입력으로 받는다.\n**Masking**: 학습 시에는 정답을 다 알고 있지만, 추론 시에는 미래의 단어를 볼 수 없다. 이를 시뮬레이션하기 위해 자기 자신보다 뒤에 있는 단어에는 −∞-\\infty−∞ 마스킹을 씌워 어텐션 점수를 0으로 만든다. 이는 자기회귀(Autoregressive) 속성을 유지하는 핵심 장치다.\n## **5.2 인코더-디코더 어텐션 (Encoder-Decoder Attention)**\n트랜스포머의 가장 중요한 연결 고리다. 번역이나 생성을 할 때 원문의 어떤 부분을 참고할지 결정한다.\n- **쿼리(Query)**: 디코더 레이어에서 올라온 ‘현재 생성 중인 단어’의 정보.\n- **키(Key) & 값(Value)**: 인코더의 최종 출력에서 제공받은 ‘입력 문장 전체’의 정보.\n- **동작**: 디코더는 이 과정을 통해 매 단계마다 입력 문장의 맥락을 다시 확인하며(Cross-Reference) 출력 단어를 결정한다.\n## **5.3 피드 포워드 및 Add & Norm**\n인코더와 마찬가지로 어텐션 결과를 비선형 변환으로 강화하고, 잔차 연결과 정규화를 수행하여 다음 레이어로 넘긴다.\n# **6. 핵심 엔진: 스케일드 점곱 어텐션 (Scaled Dot-Product Attention)**\n![image.png](/_astro/image%202.DX2MeUDN_ZIqBfU.webp)\n위의 모든 어텐션 메커니즘 내부에서 실제로 돌아가는 수학적 연산 엔진이다.\nAttention(Q,K,V)=softmax(QKTdk)V\\text{Attention}(Q, K, V) = \\text{softmax}\\left(\\frac{QK^T}{\\sqrt{d_k}}\\right)VAttention(Q,K,V)=softmax(dk​​QKT​)V\n- **MatMul (QKTQK^TQKT)**: 쿼리와 키의 내적을 통해 유사도를 구한다.\n- **Scale ( 1dk\\frac{1}{\\sqrt{d_k}}dk​​1​ )**: 차원이 커질수록 값이 발산하여 소프트맥스 기울기가 소실되는 것을 막기 위해 보정한다.\n- **Mask (Optional)**: 디코더의 첫 번째 레이어에서 미래 정보를 가릴 때 사용한다.\n- **Softmax**: 유사도 점수를 확률값(가중치)으로 변환한다.\n- **MatMul (With VVV)**: 가중치를 값(Value) 벡터에 곱해 최종 문맥 벡터(가중합)를 생성한다.\n# **7. 동작 흐름: 학습과 추론의 파이프라인**\n트랜스포머의 동작 방식은 학습(Training)과 추론(Inference) 단계에서 결정적인 차이를 보인다.\n## **7.1 학습 시 (Parallelism)**\n정답 문장(Target) 전체를 알고 있으므로, 디코더에도 문장 전체를 한 번에 입력한다(Teacher Forcing). 마스크드 어텐션 덕분에 각 위치는 자신의 이전 위치까지만 볼 수 있으므로, **모든 단어의 예측을 병렬로 동시에 수행**할 수 있다.\n## **7.2 추론 시 (Autoregressive Loop)**\n![image.png](/_astro/image%203.xQRAlTpw_bcigA.webp)\n실제 서비스 단계에서는 다음과 같은 **자기회귀 루프**를 통해 단어를 하나씩 생성한다.\n- **초기화**: 시작 토큰 `<SOS>`를 디코더에 입력한다.\n- **디코딩*",
    "source": "fredly.dev",
    "sourceUrl": "https://fredly.dev/transformer-review/",
    "category": "AI"
  },
  {
    "title": "Walrus - 분산 메시지 스트리밍 엔진",
    "content": "[*](/nubskr/walrus/blob/master/Figures/walrus1.png)\nWalrus: 분산 메시지 스트리밍 엔진\n[![Crates.io](https://img.shields.io/crates/v/walrus-rust.svg)](https://crates.io/crates/walrus-rust)\n[![문서](https://docs.rs/walrus-rust/badge.svg)](https://docs.rs/walrus-rust)\n[![CI](https://github.com/nubskr/walrus/actions/workflows/ci.yml/badge.svg)](https://github.com/nubskr/walrus/actions)\n[![라이센스: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](/nubskr/walrus/blob/master/LICENSE)\nWalrus는 고성능 로그 스토리지 엔진을 기반으로 구축된 분산 메시지 스트리밍 플랫폼입니다. 자동 리더십 회전, 세그먼트 기반 파티셔닝 및 메타데이터 조정을 위한 Raft 합의를 통해 내결함성 스트리밍을 제공합니다.\n[![바다코끼리 데모](/nubskr/walrus/raw/master/distributed-walrus/docs/walrus.gif)](/nubskr/walrus/blob/master/distributed-walrus/docs/walrus.gif)\n**주요 기능:**\n- 세그먼트 기반 리더십 순환을 통한 **자동 로드 밸런싱**\n- Raft 합의를 통한 **내결함성**(3개 이상의 노드)\n- **간단한 클라이언트 프로토콜**(모든 노드에 연결, 자동 전달)\n- 모든 복제본의 기록 읽기를 위한 **봉인된 세그먼트**\n- Linux에서 io_uring을 사용하는 **고성능 스토리지**\n## 아키텍처\n[](#아키텍처)\n### 시스템 개요\n[](#시스템 개요)\n[![해마 아키텍처](/nubskr/walrus/raw/master/distributed-walrus/docs/Distributed%20walrus.png)](/nubskr/walrus/blob/master/distributed-walrus/docs/Distributed%20walrus.png)\n생산자와 소비자는 모든 노드에 연결됩니다(또는 로드 밸런서를 통해). 클러스터는 자동으로 요청을 적절한 리더로 라우팅하고 로드 분산을 위해 세그먼트 롤오버를 관리합니다.\n### 노드 내부\n[](#노드-내부)\n[![해마 노드 아키텍처](/nubskr/walrus/raw/master/distributed-walrus/docs/Distributed%20Walrus%20Node.png)](/nubskr/walrus/blob/master/distributed-walrus/docs/Distributed%20Walrus%20Node.png)\n각 노드에는 노드 컨트롤러(라우팅 및 임대 관리), Raft 엔진(메타데이터 합의), 클러스터 메타데이터(복제된 상태) 및 버킷 스토리지(쓰기 펜싱이 있는 Walrus 엔진)의 네 가지 주요 구성 요소가 포함되어 있습니다.\n### 핵심 구성 요소\n[](#핵심 구성 요소)\n**노드 컨트롤러**\n- 고객 요청을 적절한 세그먼트 리더에게 라우팅합니다.\n- 쓰기 임대 관리(100ms마다 클러스터 메타데이터에서 동기화)\n- 롤오버 감지를 위한 논리적 오프셋 추적\n- 필요할 때 원격 리더에게 작업 전달\n**뗏목 엔진**(Octopii)\n- 메타데이터 변경에 대해서만 Raft 합의를 유지합니다(데이터는 아님!)\n- 리더 선출 및 로그 복제 처리\n- AppendEntries RPC를 통해 모든 노드에서 메타데이터를 동기화합니다.\n**클러스터 메타데이터**(Raft 상태 머신)\n- 토픽 → 세그먼트 → 리더 매핑을 저장합니다.\n- 봉인된 세그먼트 및 해당 항목 수를 추적합니다.\n- 라우팅을 위한 노드 주소 유지\n- 모든 노드에 동일하게 복제됩니다.\n**스토리지 엔진**\n- 임대 기반 쓰기 펜싱으로 Walrus 엔진을 래핑합니다.\n- 노드가 해당 세그먼트에 대한 임대를 보유한 경우에만 쓰기를 허용합니다.\n- 디스크의 WAL 파일에 실제 데이터를 저장합니다.\n- 모든 세그먼트(봉인 또는 활성)에서 읽기를 제공합니다.\n## 빠른 시작\n[](#빠른 시작)\n### 3노드 클러스터 실행\n[](#3노드 클러스터 실행)\n````\nCD 분산 해마\n클러스터 부트스트랩 만들기\n# CLI를 통해 상호작용\n화물 실행 --bin walrus-cli -- --addr 127.0.0.1:9091\n# CLI에서:\n# 'logs'라는 주제를 만듭니다.\n> 로그 등록\n# 주제에 대한 메시지 생성\n> PUT은 \"hello world\"를 기록합니다.\n# 주제의 메시지를 소비합니다.\n> 로그 가져오기\n# 주제의 세그먼트 상태를 가져옵니다.\n> 상태 로그\n# 클러스터 상태를 가져옵니다\n> 지표\n````\n## 클라이언트 프로토콜\n[](#클라이언트-프로토콜)\nTCP를 통한 간단한 길이 접두어 텍스트 프로토콜:\n````\n와이어 형식:\n[4바이트: 길이(리틀엔디안)] [UTF-8 명령]\n명령:\nREGISTER <topic> → 누락된 경우 주제 생성\nPUT <주제> <페이로드> → 주제에 추가\nGET <topic> → 다음 항목 읽기 (공유 커서)\nSTATE <topic> → 주제 메타데이터 가져오기(JSON)\n측정항목 → Raft 측정항목 가져오기(JSON)\n응답:\n확인 [페이로드] → 성공\nEMPTY → 사용 가능한 데이터 없음(GET만 해당)\nERR <메시지> → 오류\n````\n자세한 CLI 사용법은 [distributed-walrus/docs/cli.md](/nubskr/walrus/blob/master/distributed-walrus/docs/cli.md)를 참조하세요.\n## 주요 기능\n[](#주요 기능)\n### 세그먼트 기반 샤딩\n[](#세그먼트 기반 샤딩)\n- 주제가 세그먼트로 분할됨(기본적으로 각 항목 최대 100만 개 항목)\n- 각 세그먼트에는 쓰기를 처리하는 리더 노드가 있습니다.\n- 리더십은 세그먼트 롤오버 시 라운드 로빈을 순환합니다.\n- 클러스터 전체에 자동 부하 분산\n### 임대 기반 쓰기 펜싱\n[](#리스 기반 쓰기 펜싱)\n- 세그먼트의 리더만 쓸 수 있습니다.\n- 임대 파생",
    "source": "github.com",
    "sourceUrl": "https://github.com/nubskr/walrus",
    "category": "AI"
  },
  {
    "title": "당신에겐 Chief Bookmark Officer가 필요하다",
    "content": "모든 회사에는 모든 사람에게 필요한 하나의 링크를 어디서 찾을 수 있는지 항상 아는 사람이 있습니다. 내가 누구에 대해 말하는지 아시겠죠? 누군가가 \"X에 대한 기사를 갖고 있는 사람이 있나요?\"라고 물으면 즉시 채팅에 완벽한 URL을 입력합니다.\n우리는 북마크에 빠져있습니다. 여러 브라우저에 흩어져 있고, Slack 스레드에 묻혀 있고, 이메일 체인에서 사라졌습니다. 우리는 Notion, Raindrop 또는 mymind와 같은 앱을 다운로드하고 올바른 도구가 링크 혼란을 해결할 것이라고 확신합니다. 하지만 6개월이 지난 지금 우리의 디지털 파일 캐비닛은 이전과 마찬가지로 지저분합니다.\n우리가 놓치고 있는 것은 다음과 같습니다. 최고의 북마크 시스템은 도구에 관한 것이 아닙니다. 그것들은 그들을 돌보는 인간에 관한 것입니다.\n모든 회사에는 최고 북마크 책임자가 필요합니다. 링크를 쌓아두는 사람이 아니라 링크를 큐레이팅하는 사람입니다. 보관할 가치가 있는 리소스와 디지털 혼란의 차이를 누가 압니까? 팀의 흩어져 있는 스크린샷과 \"어디서 봤어\"를 기관 지식의 체계적인 라이브러리로 바꾸는 사람입니다.\nCBO는 단지 수집만 하는 것이 아닙니다. 그들은 연결됩니다. 그들은 3개월 전의 디자인 영감이 바로 새 프로젝트에 필요한 것임을 기억합니다. 이는 회사의 집단적 검색 기록을 경쟁 우위로 전환합니다.\n큐레이션을 자동화하려고 계속 노력하고 있지만 [큐레이션은 근본적으로 인간입니다](https://gabygoldberg.medium.com/curators-are-the-new-creators-the-business-model-of-good-taste-5852727d4b54). 판단력, 맥락, 그리고 시간과 프로젝트 전반에 걸쳐 패턴을 볼 수 있는 능력이 필요합니다.\n귀하의 최고 북마크 책임자가 이미 귀하의 팀에 있을 수도 있습니다. 그들은 브라우저 북마크가 실제로 의미가 있는 사람입니다. 모든 것을 기억하고 아낌없이 나누는 사람.\n이제 완벽한 북마크 앱을 찾는 것을 멈추고 최고 북마크 책임자(Chief Bookmark Officer)를 찾아야 할 때입니다.\n링크는 스스로 정리되지 않습니다. 그러나 올바른 사람은 그럴 것입니다.",
    "source": "nklswbr.com",
    "sourceUrl": "https://www.nklswbr.com/blog/chief-bookmark-officer",
    "category": "AI"
  },
  {
    "title": "착한 매니저들이 팀원의 커리어를 망치는 법 [번역글]",
    "content": "# 착한 매니저들이 팀원의 커리어를 망치는 법(골렘 이펙트)\n- [Translation](https://blogbyash.com/category/translation/), [Team&Culture](https://blogbyash.com/category/translation/team-and-culture/), [Career](https://blogbyash.com/category/translation/career/)\nTable of Contents\n[Toggle](#)\n#### 착한 매니저들이 팀원의 커리어를 망치는 방식\n*\n2015년이었다. Sunnyvale에 있는 Yahoo에서 막 엔지니어링 매니저로 승진한 참이었고, 허리에 찬 보라색 배지는 아직도 어색하게 느껴졌다. 내 캘린더에서 어느새 조용히 “캐시 고치기”와 “디자인 문서 쓰기”는 사라지고, 그 자리를 “인력 현황 회의(staff sync)”, “퍼포먼스 캘리브레이션(perf calibration)”, “헤드카운트 리뷰(headcount review)” 같은 일정들이 대신 채우고 있었다.\n그리고 막 새로 채용한 한 엔지니어가 있었는데, 이 사람은 나의 ‘사람을 어떻게 도전시키는가’에 대한 방식을 조용히 완전히 바꿔놓게 된다.\n그녀의 첫 출근 날이었다. 아마 당신도 바로 그려질 것이다. 아직 스티커 하나 붙지 않은 깨끗한 노트북, 한 사이즈는 커 보이는 Yahoo 후디. 오리엔테이션 자료는 가방 안에서 반쯤 접힌 채 들어 있고, 노트는 첫 페이지가 펼쳐진 상태로 펜 뚜껑까지 이미 벗겨져 있었다. ‘내가 여기 있어도 되는 사람이 맞다’는 걸 증명할 준비가 된 얼굴이었다. 12주 안에 소프트웨어 엔지니어로 만들어주겠다고 약속하는 부트캠프를 막 수료하고 나온 참이었다.\n내 머릿속에서 그녀는 하나의 시스템 다이어그램이 되었다. 레거시도 없고 상처도 없으며, 아직 실제 트래픽을 맞아본 적 없는 완전히 새로운 프로덕션 서비스. 잠재력은 아주 커 보이지만, 어디에서 어떻게 실패할지 모르는 상태. 그리고 그 머릿속 다이어그램 어딘가에서, 나는 말로 꺼내진 않은 결정을 하나 내렸다. 이 친구를 안전하게 지키겠다고.\n나는 ‘좋은 보스’, 자상한 매니저가 되기로 마음먹었다. 그녀가 푹 잘 수 있도록 온콜(on-call) 로테이션에서는 빼 두었다. “아직 그런 스트레스까지 줄 필요는 없다”고 생각하며 인시던트 브리지에도 부르지 않았다. 겁나는 배포는 피하게 해서 한동안은 샌드박스 안에서만 놀게 했다. 내가 준 일감은 안전한 정도의 투어였다. 작은 티켓들, 텍스트 카피를 조금 고치는 일, 리스크가 거의 없는 리팩토링들. 늘 그랬다. 잘 되면 대박이지만 틀어지면 크게 데일 수 있는 중요한 작업이 떨어질 때마다, 나는 마음속에서 슬그머니 그 일을 그녀에게서 떼어냈다.\n너무 위험해 보였고. 너무 눈에 띌 것 같았고. 너무 많은 걸 요구하는 일 같았다. 그 모든 선택은 그때는 다 그럴듯했고, 심지어 친절해 보이기까지 했다. 하지만 6개월이 지나고 나서 결과는 전혀 친절하지 않았다.\n스탠드업 미팅에서, 그녀 주변 공기는 묵직한 밀도가 느껴졌다. 말을 하더라도 꼭 마지막에 했고, 아예 말을 안 할 때도 있었다. 그리고 그녀의 업데이트는, 보이지 않는 어떤 선을 잘못 밟을까 봐 조심스러워하는 사람의 말투처럼 들렸다. “아직 설정 페이지 작업 중이에요.” 그녀가 말했다. “조금 더 진척이 있었고요. 곧 준비될 것 같아요.”\n그녀는 굳이 그럴 필요가 없는 일까지 세 번씩이나 다시 확인했다. 자기 손을 거친 코드 근처에서 버그 리포트가 올라오기라도 하면, 그녀는 바로 로그부터 열어보지 않았다. 먼저 나를 쳐다봤다. 마치 집주인 눈치를 보는 세입자처럼. 리뷰를 기다렸고, 사인을 기다렸고, 허가를 기다렸다.\n나는 스스로에게 이렇게 말했다. 저 친구는 신중하고, 조심스럽고, 리스크에 민감한 사람이라고. 하지만 그건 틀린 생각이었다.\n## 마법을 깨뜨린 원원 미팅(The One-on-One That Broke The Spell)\n너무 많은 퍼포먼스 리뷰를 견디고 햇빛은 제대로 못 본 작은 회의실을 상상해 보라. 한쪽 벽은 유리로 되어 있고, 지문과 스티커 노트 자국으로 더러워져 있다. 다른 쪽 벽은 아무도 제대로 청소하지 못한 화이트보드다. 천장의 형광등은 짜증 날 정도로 윙윙거린다. 그런데도 티켓을 끊을 만큼 심하지는 않다.\n그녀는 노트북을 닫은 채 내 맞은편에 앉아 있었다. 두 손은 이제 미지근한 커피만 남은 종이컵을 꽉 쥐고 있었다. 무언가 붙잡을 게 필요했던 모양이다.\n나는 평소대로 스크립트를 열었다. “일은 어때? 느낌이?”\n“좋아요.” 그녀가 말했다. “많이 배우고 있어요.” 목소리는 차분하고 연습된 톤이었다.\n“내부 툴 작업은 탄탄했어.” 내가 말했다. “팀에서 다들 고마워하고 있어.”\n그녀는 손을 내려다봤다. 이어진 침묵이 방 안에 1초 너무 길게 머물렀다. 반성이라기보다는 판결을 기다리는 느낌이었다.\n“하나 물어보고 싶었어요.” 그녀가 마침내 입을 뗐다. “언제 진짜 일 할 수 있어요?”\n나는 시간을 끌어보려 했다. “진짜 일이 뭐를 말하는 거야?”\n“온콜(on-call)이요. 인시던트들. 마이그레이션(migrations)요.”\n나는 반사적으로 웃었다. “이게 진짜 일인데.” 내가 말했다.\n그녀는 웃지 않았다. 내 눈을 똑바로 봤다. “연습처럼 느껴져요.” 그녀가 말했다. “Dave는 데이터베이스 맡고, 나는 버튼 색깔 고치고. 버튼 색깔 망쳐도 아무도 신경 안 써요. 데이터베이스 망치면 진짜 문제죠.”\n“Dave는 여기 3년 됐어.” 내가 반박했다. “너 과부하 안 걸리게 하려고. 온콜은 악몽이야. 네 잘되라고 하는 거라고.”\n그녀는 논쟁하거나 과장되게 나오지 않았다. 그냥 평평하고 조용한 목소리로 말했다. “하지만 중요한 걸 한 번도 안 주시면, 내가 중요한 사람이라는 걸 어떻게 증명해요?”\n갑자기 그 윙윙거리는 불소리가 크게 들렸다. 내 머릿속에서 6개월간의 결정들이 줄줄이 늘어섰다. “당분간” 온콜에서 빼두기, “마감이 촉박해서” 복잡한 인테그레이션을 Dave한테 넘기기, “아직 과부하 안 주자”라고 말하며 그녀가 고개 끄덕이는 걸 지켜보기. 그녀가 달리 어떻게 하겠는가?\n모두 보호처럼 느껴졌고, 책임감 있고 합리적이었다. 하지만 테이블 반대편에서 보면 이야기가 달라졌다. 나는 그녀를 실패로부터 보호한 게 아니었다. 조용히 실패를 기대한다는 신호를 보낸 거였다.\n그 깨달음이 가슴에 무게처럼 내려앉았다. 이 결정들은 그녀의 능력 때문이 아니었다. 내 두려움 때문이었다. 그녀가 실패하면 질문이 내 책상으로 날아올까 봐. 리더십이 “너무 신입한 애한테 큰 걸 왜 줬어?”라고 물을까 봐. 그녀가 압박에 무너지면 내가 수습해야 할까 봐.\n나는 그냥 그녀를 믿지 않았을 뿐이다.\n그 말을 입 밖으로 내진 않았다. 그냥 그 윙윙거리는 방에 앉아 그녀가 빈 종이컵을 쥔 채 내가 없는 답을 기다리는 동안이었다. 그녀는 ‘진짜’가 될 때가 언제냐고 들어왔고. 나는 그녀가 이미 ‘진짜’가 아니라고 조용히 결정했다는 걸 알게 나왔다.\n## 골렘 효과(Golem Effect): 낮은 기대가 사람을 가두는 상자를 만들 때\n심리학자들은 이 패턴에 이름을 붙였다: 골렘 효과(Golem Effect).\n이름의 유래는 유대 민간 설화다. 골렘(golem)은 점토로 빚은 생명체로, 창조자를 지키려고 만들어졌지만 결국 서툴고 위험한 존재가 된다. 힘은 세지만 영혼은 없고, 시키는 대로만 하고 그 이상은 하지 않는다. 마찬가지로 골렘 효과는 리더가 낮은 기대를 품고 사람을 형성할 때 일어나는 현상을 설명한다. 보호하려는 마음이라고 생각하지만, 실은 그들이 될 수 있었던 가능성의 더 작고 약해진 버전을 만들어내는 거다.\n대부분의 리더들은 그 더 친절한 쌍둥이 형제인 **피그말리온 효과(Pygmalion Effect)**는 들어봤을 것이다. 이야기의 내용은 이래: 학교 연구에서 선생들에게 특정 학생들이 “늦깎이 꽃피는 아이들(late bloomers)”이라며 학업 성적이 크게 오를 거라고 말했다. 그 학생들은 무작위로 뽑힌 거였는데, 학년 말에 그 “늦깎이”들이 실제로 앞서 나갔다. 선생들은 특별 교과서 주거나 누가 선정됐는지 발표하지 않았다. 그냥 그 아이들 주위에서 조금 다르게 행동했을 뿐이다. 답을 조금 더 오래 기다려주고, 약간 더 어려운 질문을 던지고, 더 자세한 피드백을 주고, 더 자주 미소 지었다.\n![착한 매니저들이 팀원의 커리어를 망치는 법(골렘 이펙트)](https://i0.wp.com/blogbyash.com/wp-content/uploads/2025/12/122.%EC%B0%A9%ED%95%9C-%EB%A7%A4%EB%8B%88%EC%A0%80%EB%93%A4%EC%9D%B4-%ED%8C%80%EC%9B%90%EC%9D%98-%EC%BB%A4%EB%A6%AC%EC%96%B4%EB%A5%BC-%EB%A7%9D%EC%B9%98%EB%8A%94-%EB%B2%95%EA%B3%A8%EB%A0%98-%EC%9D%B4%ED%8E%99%ED%8A%B8_2.jpg?resize=1024%2C741&ssl=1)\n작은 변화들이 반복되니 의미 있는 차이로 벌어졌다.\n골렘 효과는 그 기계가 역방향으로 도는 거다.",
    "source": "blogbyash.com",
    "sourceUrl": "https://blogbyash.com/translation/how-nice-managers-ruin-careers/",
    "category": "AI"
  },
  {
    "title": "Durable Streams - 클라이언트 애플리케이션을 위한 실시간 동기화 오픈 프로토콜",
    "content": "![Memento polaroid icon](/durable-streams/durable-streams/raw/main/docs/img/icon-128.png)\n# Durable Streams\n[](#durable-streams)\n**The open protocol for real-time sync to client applications**\nHTTP-based durable streams for streaming data reliably to web browsers, mobile apps, and native clients with offset-based resumability.\nDurable Streams provides a simple, production-proven protocol for creating and consuming ordered, replayable data streams with support for catch-up reads and live tailing.\nTip\nRead the [Annoucing Durable Streams](https://electric-sql.com/blog/2025/12/09/announcing-durable-streams) post on the Electric blog.\n## The Missing Primitive\n[](#the-missing-primitive)\nModern applications frequently need ordered, durable sequences of data that can be replayed from arbitrary points and tailed in real time. Common patterns include:\n- **AI conversation streaming** - Stream LLM token responses with resume capability across reconnections\n- **Agentic apps** - Stream tool outputs and progress events with replay and clean reconnect semantics\n- **Database synchronization** - Stream database changes to web, mobile, and native clients\n- **Collaborative editing** - Sync CRDTs and operational transforms across devices\n- **Real-time updates** - Push application state to clients with guaranteed delivery\n- **Event sourcing** - Build event-sourced architectures with client-side replay\n- **Workflow execution** - Stream workflow state changes with full history\nWhile durable streams exist throughout backend infrastructure (database WALs, Kafka topics, event stores), they aren't available as a first-class primitive for client applications. There's no simple, HTTP-based durable stream that sits alongside databases and object storage as a standard cloud primitive.\nWebSocket and SSE connections are easy to start, but they're fragile in practice: tabs get suspended, networks flap, devices switch, pages refresh. When that happens, you either lose in-flight data or build a bespoke backend storage and client resume protocol on top.\nAI products make this painfully visible. Token streaming is the UI for chat and copilots, and agentic apps stream progress events, tool outputs, and partial results over long-running sessions. When the stream fails, the product fails—even if the model did the right thing.\n**Durable Streams addresses this gap.** It's a minimal HTTP-based protocol for durable, offset-based streaming designed for client applications across all platforms: web browsers, mobile apps, native clients, IoT devices, and edge workers. Based on 1.5 years of production use at [Electric](https://electric-sql.com/) for real-time Postgres sync, reliably delivering millions of state changes every day.\n**What you get:**\n- **Refresh-safe** - Users refresh the page, switch tabs, or background the app—they pick up exactly where they left off\n- **Share links** - A stream is a URL. Multiple viewers can watch the same stream together in real-time\n- **Never re-run** - Don't repeat expensive work because a client disconnected mid-stream\n- **Multi-device** - Start on your phone, continue on your laptop, watch from a shared link—all in sync\n- **Multi-tab** - Works seamlessly across browser tabs without duplicating connections or missing data\n- **Massive fan-out** - CDN-friendly design means one origin can serve millions of concurrent viewers\nThe protocol provides:\n- 🌐 **Universal** - Works anywhere HTTP works: web browsers, mobile apps, native clients, IoT devices, edge workers\n- 📦 **Simple** - Built on standard HTTP with no custom protocols\n- 🔄 **Resumable** - Offset-based reads let you resume from any point\n- ⚡ **Real-time** - Long-poll and SSE modes for live tailing with catch-up from any offset\n- 💰 **Economical** - HTTP-native design leverages CDN infrastructure for efficient scaling\n- 🎯 **Flexible** - Content-type agnostic byte streams\n- 🔌 **Composable** - Build higher-level abstractions on top (like Electric's real-time Postgres sync engine)\n## Installation\n[](#installation)\n### npm packages\n[](#npm-packages)\n```\nnpm install @durable-streams/client # TypeScript client\nnpm install @durable-streams/server # Reference Node.js server\nnpm install @durable-streams/state # State Protocol primitives\nnpm install @durable-streams/cli # Development & testing CLI\n```\n### Other languages\n[](#other-languages)\n```\n# Go\ngo get github.com/durable-streams/durable-streams/packages/client-go\n# Python\npip install durable-streams\n```\n### Server binary\n[](#ser",
    "source": "github.com",
    "sourceUrl": "https://github.com/durable-streams/durable-streams",
    "category": "AI"
  },
  {
    "title": "Show GN: Tokyo Night에 질리셨나요? 한국인을 위한 Vim 테마, 서울리즘",
    "content": "# Seoulism\n[](#seoulism)\nA Vim and Neovim colorscheme inspired by Korean color tradition and modern Seoul light.\n[*](/gg582/seoulism.vim/blob/master/preview.png)\nSeoulism translates Korean color sources into a clean dark UI palette with strong contrast—quiet enough for deep work, sharp enough for structure.\nBest with:\n- `set termguicolors` (requires a truecolor-capable terminal)\n---\n## Quick Start\n[](#quick-start)\n### Vim / Neovim (after installing the plugin)\n[](#vim--neovim-after-installing-the-plugin)\n```\nset termguicolors\ncolorscheme seoulism\n```\n---\n## A Korean palette, made readable\n[](#a-korean-palette-made-readable)\nSeoulism takes Korean color sources and translates them into a modern UI palette designed for clarity and hierarchy.\n### A Gentle Chain of Colors: Five Directional Color Model\n[](#a-gentle-chain-of-colors-five-directional-color-model)\n**Eastern aesthetics are more than a \"Zen\" cliché; they represent a centuries-old cognitive system.**\nI have spent time developing **Seoulism**, a Vim theme that approaches Eastern aesthetics from a systemic and structural perspective. The goal is to move away from purely mystical or exotic interpretations.\nWhile the \"Five Directional Colors\" (오방색, 五方色) originated in broader East Asian philosophy (commonly linked to Zou Yan and early Chinese cosmology), its real value lies in how it was localized and reconfigured into a rigorous system of order within Korean culture. By stripping away mystical layers, I focused on the structural core: color as a cognitive system for organizing hierarchy and meaning.\n#### Beyond the \"Zen\" cliché\n[](#beyond-the-zen-cliché)\nThis theme is not about \"oriental minimalism.\" It treats color as functional UI logic: accents are not decoration, but tools for categorizing structure.\n#### The Principle of \"Scene First, Emotion Later\" (선경후정, 先景後情)\n[](#the-principle-of-scene-first-emotion-later-선경후정-先景後情)\nIn this hierarchy, code is the \"Scene\"—the functional reality—and is rendered with maximum clarity. Comments (human annotation) are intentionally receded so that sentiment never competes with structure.\n#### Pine Ink Black\n[](#pine-ink-black)\nKorean visual preference often leans toward matte black with a faint blue cast rather than flat pure black. This tone softens the canvas while keeping edges crisp, designed to support flow without getting in your way.\n#### A living legacy\n[](#a-living-legacy)\nThis is not presented as a museum relic. The system lives on as an implicit logic of order—visible today in modern Korean visual culture and engineering sensibilities.\nIf neon-saturated themes feel too loud for long sessions, Seoulism aims to stay grounded, readable, and calm.\n---\n## A Chain of Colors\n[](#a-chain-of-colors)\n[![Visualizer](/gg582/seoulism.vim/raw/master/visualizer.png)](/gg582/seoulism.vim/blob/master/visualizer.png)\n[![Pentagon](/gg582/seoulism.vim/raw/master/pentagon_cycle.png)](/gg582/seoulism.vim/blob/master/pentagon_cycle.png)\nThese diagrams illustrate the cognitive transformation from ancestral elemental anchors to modern UI tokens.\nBasic structure is a mixture between Asian astronomy and Asian color system.\n---\n## What inspired the colors\n[](#what-inspired-the-colors)\n- \n**Traditional Korean five-color system (오방색)**\nA framework around five symbolic colors: blue, red, yellow, white, and black.\nSeoulism uses this as a guide for balanced accents and clear hierarchy.\nTo Chinese people: Although it was originated from China, we have our own adaptation of colors.*\n- \n**Indigo dyeing**\nDeep blues shaped by fabric dye texture rather than flat digital blue.\n- \n**Metallic pigments**\nHighlights inspired by mineral/metal-like pigments seen in traditional decorative work.\n- \n**Safflower red dye**\nReds tuned to feel warm and vivid—more like natural dye than “error-only” red.\n- \n**Pine ash black**\nMatte black tuned with a subtle blue glint.\n- \n**Reflective selection**\nVisual selection turns into a bright reflective white, like a spotlight on a paper-like canvas.\n---\n## Install\n[](#install)\n### Vim-plug (Vim / Neovim)\n[](#vim-plug-vim--neovim)\n```\ncall plug#begin()\nPlug 'gg582/seoulism.vim'\ncall plug#end()\nset termguicolors\ncolorscheme seoulism\n```\n### Vundle (Vim)\n[](#vundle-vim)\n```\nset nocompatible\nfiletype off\nset rtp+=~/.vim/bundle/Vundle.vim\ncall vundle#begin()\nPlugin 'VundleVim/Vundle.vim'\nPlugin 'gg582/seoulism.vim'\ncall vundle#end()\nfiletype plugin indent on\nset termguicolors\ncolorscheme seoulism\n```\nThen run:\n- `:PluginInstall`\n### Nati",
    "source": "github.com",
    "sourceUrl": "https://github.com/gg582/seoulism.vim",
    "category": "AI"
  },
  {
    "title": "느림은 미덕이다",
    "content": "# Slowness is a Virtue\n### ... at least when you're doing research, not development\n[*\n](https://substack.com/@jakobschwichtenberg)[Jakob Schwichtenberg](https://substack.com/@jakobschwichtenberg)\nDec 18, 2025\n34\n6\n10\nShare\n[![](https://substackcdn.com/image/fetch/$s_!2aZL!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F546e1fa0-75ba-4bfe-a850-00f9193b3e46_2900x1612.png)\n](https://substackcdn.com/image/fetch/$s_!2aZL!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F546e1fa0-75ba-4bfe-a850-00f9193b3e46_2900x1612.png)Modern culture is focused exclusively on questions that can be answered quickly.\nIn academia, that’s what you can get funding for. Fast questions can be answered within a few weeks. You can then publish a paper. You can start collecting citations. You can present your answer at conferences. This is how you build a career.\nBut the most important questions can’t be answered like that.\nWhen you can write down a step-by-step plan for how you’re going to answer a question or solve a specific problem, you aren’t doing research but development. \nResearch means you only have a fuzzy idea of your destination but no clear idea of how you’re going to get there. You’re mostly just following hunches and intuitions. [That’s how the biggest leaps forward are achieved.](https://blog.jakobschwichtenberg.com/p/against-objectives-or-how-einstein)\nDevelopment is the execution of a map toward a goal while research is the pursuit of a goal without a map.\nWorking on questions you can answer fast means you know what you’re doing. And knowing what you’re doing is a sign you’re not pushing into genuinely new territory.\nSlowness allows for the exploration of uncharted territory and unexpected discoveries. Johann Friedrich Böttger spent almost a decade trying to find a formula that produces gold. While he never succeeded, a byproduct of his relentless experimentation was the discovery of a process to produce porcelain. \nAndrew Wiles worked in secret for 7 years on Fermat’s Last Theorem, publishing nothing. It took Einstein around ten years to write down the foundational equation of General Relativity. \nIn this sense, when it comes to research, speed should be considered an anti-signal and slowness a virtue.[1](https://blog.jakobschwichtenberg.com/p/slowness-is-a-virtue#footnote-1-181970009)\n### How Intelligence Leads Us Astray\nOur very definition of intelligence encodes the bias toward speed. The modern definition of intelligence is extremely narrow. It simply describes the speed at which you can solve well-defined problems.\nConsider this: if you get access to an IQ test weeks in advance, you could slowly work through all the problems and memorize the solutions. The test would then score you as a genius. This reveals what IQ tests actually measure. It’s not whether you can* solve problems, but how *fast* you solve them.\nAnd it’s exclusively this kind of intelligence that’s measured in academic and IQ tests.\nWhat these tests completely miss is the ability to select problems worth working on and to [choose interesting steps forward in the absence of a well-defined problem](https://blog.jakobschwichtenberg.com/p/the-unreasonable-effectiveness-of).\nAs a result, many people live under the illusion that because their intelligence doesn’t fit this narrow definition, they’re not able to contribute something meaningful.\nAs the saying goes, “*if you judge a fish by its ability to climb a tree, it will live its whole life believing that it is stupid*”.\nSo where does this obsession with IQ come from? [Partly from bad science that got repeated until it became truth.](https://www.theintrinsicperspective.com/p/your-iq-isnt-160-no-ones-is) In the 1950s, a Harvard professor named Anne Roe claimed to have measured the IQs of Nobel Prize winners, reporting a median of 166. The finding has been cited ever since. But here’s what actually happened: she never used a real IQ test. She made up her own test from SAT questions, had no comparison group, and when the Nobel laureates took it, they scored... average. Not genius-level. Just fine. She then performed a mysterious statistical conversion to arrive at 166. The raw data showed nothing exceptional. But the inflated number is what survived.\nEinstein never took an IQ test, but his school records show a B+ student who failed his college entrance exam on the first try. ",
    "source": "blog.jakobschwichtenberg.com",
    "sourceUrl": "https://blog.jakobschwichtenberg.com/p/slowness-is-a-virtue",
    "category": "AI"
  },
  {
    "title": "Git을 데이터베이스로 사용하는 패키지 관리자들, 결국 실패한다",
    "content": "# Package managers keep using git as a database, it never works out\nDec 24, 2025\nUsing git as a database is a seductive idea. You get version history for free. Pull requests give you a review workflow. It’s distributed by design. GitHub will host it for free. Everyone already knows how to use it.\nPackage managers keep falling for this. And it keeps not working out.\n## Cargo\nThe crates.io index started as a git repository. Every Cargo client cloned it. This worked fine when the registry was small, but the index kept growing. Users would see progress bars like “Resolving deltas: 74.01%, (64415/95919)” hanging for ages, the visible symptom of Cargo’s libgit2 library grinding through [delta resolution](https://github.com/rust-lang/cargo/issues/9069) on a repository with thousands of historic commits.\nThe problem was worst in CI. Stateless environments would download the full index, use a tiny fraction of it, and throw it away. Every build, every time.\n[RFC 2789](https://rust-lang.github.io/rfcs/2789-sparse-index.html) introduced a sparse HTTP protocol. Instead of cloning the whole index, Cargo now fetches files directly over HTTPS, downloading only the metadata for dependencies your project actually uses. (This is the “[full index replication vs on-demand queries](/2025/12/05/package-manager-tradeoffs.html)” tradeoff in action.) By April 2025, 99% of crates.io requests came from Cargo versions where sparse is the default. The git index still exists, still growing by thousands of commits per day, but most users never touch it.\n## Homebrew\n[GitHub explicitly asked Homebrew to stop using shallow clones.](https://github.com/Homebrew/brew/pull/9383) Updating them was [“an extremely expensive operation”](https://brew.sh/2023/02/16/homebrew-4.0.0/) due to the tree layout and traffic of homebrew-core and homebrew-cask.\nUsers were downloading 331MB just to unshallow homebrew-core. The .git folder approached 1GB on some machines. Every `brew update` meant waiting for git to grind through delta resolution.\nHomebrew 4.0.0 in February 2023 switched to JSON downloads for tap updates. The reasoning was blunt: “they are expensive to git fetch and git clone and GitHub would rather we didn’t do that… they are slow to git fetch and git clone and this provides a bad experience to end users.”\nAuto-updates now run every 24 hours instead of every 5 minutes, and they’re much faster because there’s no git fetch involved.\n## CocoaPods\nCocoaPods is the package manager for iOS and macOS development. It hit the limits hard. The Specs repo grew to hundreds of thousands of podspecs across a deeply nested directory structure. Cloning took minutes. Updating took minutes. CI time vanished into git operations.\nGitHub imposed CPU rate limits. The culprit was shallow clones, which force GitHub’s servers to compute which objects the client already has. The team tried various band-aids: stopping auto-fetch on `pod install`, converting shallow clones to full clones, [sharding the repository](https://blog.cocoapods.org/Sharding/).\nThe CocoaPods blog captured it well: [“Git was invented at a time when ‘slow network’ and ‘no backups’ were legitimate design concerns. Running endless builds as part of continuous integration wasn’t commonplace.”](https://blog.cocoapods.org/Master-Spec-Repo-Rate-Limiting-Post-Mortem/)\nCocoaPods 1.8 [gave up on git entirely](https://blog.cocoapods.org/CocoaPods-1.8.0-beta/) for most users. A CDN became the default, serving podspec files directly over HTTP. The migration saved users about a gigabyte of disk space and made `pod install` nearly instant for new setups.\n## Nixpkgs\nNix already solved the client-side problem. The package manager fetches expressions as [tarballs via channels](https://releases.nixos.org/nix/nix-2.13.6/manual/package-management/channels.html), served from S3 and CDN, not git clones. Binary caches serve built packages over HTTP. End users never touch the git repository.\nBut the repository itself is stress-testing GitHub’s infrastructure. In November 2025, GitHub contacted the NixOS team about [periodic maintenance jobs failing](https://discourse.nixos.org/t/nixpkgs-core-team-update-2025-11-30-github-scaling-issues/72709) and causing “issues achieving consensus between replicas.” If unresolved, the repository could have become read-only.\nThe repository totals 83GB with half a million tree objects and 20,000 forks. A local clone is only 2.5GB. The rest is GitHub’s fork network storing every pull request branch and",
    "source": "nesbitt.io",
    "sourceUrl": "https://nesbitt.io/2025/12/24/package-managers-keep-using-git-as-a-database.html",
    "category": "AI"
  },
  {
    "title": "Vibium - AI와 인간을 위한 브라우저 자동화 도구",
    "content": "# Vibium\n[](#vibium)\n**Browser automation without the drama.**\nVibium is browser automation infrastructure built for AI agents. A single binary handles browser lifecycle, WebDriver BiDi protocol, and exposes an MCP server — so Claude Code (or any MCP client) can drive a browser with zero setup. Works great for AI agents, test automation, and anything else that needs a browser.\n**New here?** [Getting Started Tutorial](/VibiumDev/vibium/blob/main/docs/tutorials/getting-started.md) — zero to hello world in 5 minutes.\n---\n## Quick Reference\n[](#quick-reference)\nComponent\nPurpose\nInterface\n**Clicker**\nBrowser automation, BiDi proxy, MCP server\nCLI / stdio / WebSocket :9515\n**JS Client**\nDeveloper-facing API\nnpm package\n---\n## Architecture\n[](#architecture)\n```\n┌─────────────────────────────────────────────────────────────┐\n│ LLM / Agent │\n│ (Claude Code, Codex, Gemini, Local Models) │\n└─────────────────────────────────────────────────────────────┘\n▲\n│ MCP Protocol (stdio)\n▼\n┌─────────────────────┐ \n│ Vibium Clicker │\n│ │\n│ ┌───────────────┐ │\n│ │ MCP Server │ │\n│ └───────▲───────┘ │ ┌──────────────────┐\n│ │ │ │ │\n│ ┌───────▼───────┐ │WebSocket│ │\n│ │ BiDi Proxy │ │◄───────►│ Chrome Browser │\n│ └───────────────┘ │ BiDi │ │\n│ │ │ │\n└─────────────────────┘ └──────────────────┘\n▲\n│ WebSocket BiDi :9515\n▼\n┌─────────────────────────────────────────────────────────────┐\n│ JS/TS Client │\n│ npm install vibium │\n│ │\n│ ┌─────────────────┐ ┌─────────────────┐ │\n│ │ Async API │ │ Sync API │ │\n│ │ await vibe.go() │ │ vibe.go() │ │\n│ │ │ │ │ │\n│ └─────────────────┘ └─────────────────┘ │\n└─────────────────────────────────────────────────────────────┘\n```\n---\n## Components\n[](#components)\n### Clicker\n[](#clicker)\nA single Go binary (~10MB) that does everything:\n- **Browser Management:** Detects/launches Chrome with BiDi enabled\n- **BiDi Proxy:** WebSocket server that routes commands to browser\n- **MCP Server:** stdio interface for LLM agents\n- **Auto-Wait:** Polls for elements before interacting\n- **Screenshots:** Viewport capture as PNG\n**Design goal:** The binary is invisible. JS developers just `npm install vibium` and it works.\n### JS/TS Client\n[](#jsts-client)\n```\n// Option 1: require (REPL-friendly)\nconst { browserSync } = require('vibium')\n// Option 2: dynamic import (REPL with --experimental-repl-await)\nconst { browser } = await import('vibium')\n// Option 3: static import (in .mjs or .ts files)\nimport { browser, browserSync } from 'vibium'\n```\n**Sync API:**\n```\nconst fs = require('fs')\nconst { browserSync } = require('vibium')\nconst vibe = browserSync.launch()\nvibe.go('https://example.com')\nconst png = vibe.screenshot()\nfs.writeFileSync('screenshot.png', png)\nconst link = vibe.find('a')\nlink.click()\nvibe.quit()\n```\n**Async API:**\n```\nconst fs = await import('fs/promises')\nconst { browser } = await import('vibium')\nconst vibe = await browser.launch()\nawait vibe.go('https://example.com')\nconst png = await vibe.screenshot()\nawait fs.writeFile('screenshot.png', png)\nconst link = await vibe.find('a')\nawait link.click()\nawait vibe.quit()\n```\n---\n## For Agents\n[](#for-agents)\nOne command to add browser control to Claude Code:\n```\nclaude mcp add vibium -- npx -y vibium\n```\nThat's it. No manual steps needed. Chrome downloads automatically during setup.\nTool\nDescription\n`browser_launch`\nStart browser (visible by default)\n`browser_navigate`\nGo to URL\n`browser_find`\nFind element by CSS selector\n`browser_click`\nClick an element\n`browser_type`\nType text into an element\n`browser_screenshot`\nCapture viewport (base64 or save to file with `--screenshot-dir`)\n`browser_quit`\nClose browser\n---\n## For Humans\n[](#for-humans)\n```\nnpm install vibium\n```\nThis automatically:\n- Installs the Clicker binary for your platform\n- Downloads Chrome for Testing + chromedriver to platform cache:\nLinux: `~/.cache/vibium/`\n- macOS: `~/Library/Caches/vibium/`\n- Windows: `%LOCALAPPDATA%\\vibium\\`\nNo manual browser setup required.\n**Skip browser download** (if you manage browsers separately):\n```\nVIBIUM_SKIP_BROWSER_DOWNLOAD=1 npm install vibium\n```\n---\n## Platform Support\n[](#platform-support)\nPlatform\nArchitecture\nStatus\nLinux\nx64\n✅ Supported\nmacOS\nx64 (Intel)\n✅ Supported\nmacOS\narm64 (Apple Silicon)\n✅ Supported\nWindows\nx64\n✅ Supported\n---\n## Quick Start\n[](#quick-start)\n**As a library:**\n```\nimport { browser } from \"vibium\";\nconst vibe = await browser.launch();\nawait vibe.go(\"https://example.com\");\nconst el = await vibe.find(\"a\");\nawait el.click();\nawait vibe.quit();\n```",
    "source": "github.com",
    "sourceUrl": "https://github.com/VibiumDev/vibium",
    "category": "AI"
  },
  {
    "title": "Nvidia의 200억 달러 규모 반독점 회피 거래",
    "content": "**Update Dec 28:** New deal details + the patent strategy I missed: [Groq Update](/blog/groq-update)\n---\n\"You're taking on a giant. What gives you the audacity?\"\nOn November 5th, 2025, Groq CEO Jonathan Ross was asked why he was even bothering to challenge Nvidia. He didn't blink:\n\"I think that was a polite way to ask why in the world are we competing with Nvidia, so we're not. Competition is a waste of money; competition fundamentally means you are taking something someone else is doing and trying to copy it. You're wasting R&D dollars trying to do the exact same thing they've done instead of using them to differentiate.\"\n49 days later, Nvidia paid $20 billion for Groq's assets and hired Ross along with his entire executive team.\nExcept this wasn't actually an acquisition, at least not in the traditional sense. Nvidia paid $20 billion for Groq's IP and people, but explicitly did NOT buy the company.\nJensen Huang's statement was surgical: \"While we are adding talented employees to our ranks and licensing Groq's IP, we are not acquiring Groq as a company.\"\nThat phrasing is the entire story. Because what Nvidia carved out of the deal tells you everything about why this happened.\nForget the AI doomer takes about a bubble forming, lets look into the actual reasons.\n## What Nvidia Actually Bought (And What It Didn't)\nNvidia acquired:\n- All of Groq's intellectual property and patents\n- Non-exclusive licensing rights to Groq's inference technology\n- Jonathan Ross (CEO), Sunny Madra (President), and the entire senior leadership team\nNvidia explicitly did NOT buy:\n- GroqCloud (the cloud infrastructure business)\nGroqCloud continues as an independent company under CFO Simon Edwards.\nThis is Nvidia's largest acquisition ever (previous record was Mellanox at $7B in 2019), and they structured it to leave the actual operating business behind. That doesn't happen by accident.\n## LPU vs TPU vs CPU: Why SRAM Matters\nTo understand why Nvidia paid anything for Groq, you need to understand the architectural bet Ross made when he left Google.\n**CPUs and GPUs** are built around external DRAM/HBM (High Bandwidth Memory). Every compute operation requires shuttling data between the processor and off-chip memory. This works fine for general-purpose computing, but for inference workloads, that constant round-trip creates latency and energy overhead. Since GPUs evolved from graphics rendering they're optimized for parallel training workloads and not SEQUENTIAL inference.\n**TPUs (Google's Tensor Processing Units)** reduce this overhead by passing data directly between processors like an assembly line. But they still rely on external memory (HBM) to store the model. This means the calculations are predictable, but the speed of fetching data from memory is not.\n**LPUs (Groq's Language Processing Units)** take a different approach: even larger on-chip SRAM instead of external DRAM/HBM. The entire model (for models that fit) lives in SRAM with 80 TB/s of bandwidth and 230 MB capacity per chip. No off-chip memory bottleneck or dynamic scheduling. The architecture is entirely deterministic from compilation to execution. You know exactly what happens at each cycle on each chip at each moment.\nThis creates massive advantages for inference:\n- Llama 3.1 8B: 800-1000+ tokens/sec (128K token context)\n- Llama 3.1 70B: 250+ tokens/sec (128K token context)\n- Mixtral 8x7B: 480 tokens/sec (32K token context)\nAnd 10x better energy efficiency because you're not constantly moving data across a memory bus.\n*\nCompare this to SOTA model tokens/sec throughput on GPU inference*\nSerious trade off though, only 14GB of SRAM per rack means you can't run Llama 3.1 405B. And LPUs can't train models at all. This is an inference-only architecture with limited model size support.\nBut here's what makes this interesting: if DRAM/HBM prices continue climbing (DRAM has tripled in a year I should've gone all in DRAM at the start of the year I'm done with indexes), and if inference becomes the dominant AI workload (which it is), SRAM-based architectures become economically compelling despite the size limitations.\nAND production AI applications seem to be moving from 405B-1T models to running 7B-70B models that need low latency and high throughput.\n**Clarification:** Some readers pointed out I oversimplified when SRAM makes economic sense. If you're building a voice assistant or AI agent that talks to one person at a time, [Groq's approach wins](https://groq.com/blog/inside-the-lpu-deco",
    "source": "ossa-ma.github.io",
    "sourceUrl": "https://ossa-ma.github.io/blog/groq",
    "category": "AI"
  },
  {
    "title": "AI 시대의 세컨드 브레인: 제텔카스텐",
    "content": "안녕하세요. '생각의 연결' 메일러 주광입니다.\n시작하기 전에 한 가지를 먼저 말씀드릴게요. 저는 ADHD 진단을 받았고, 지금도 치료를 병행하고 있습니다. 예전에는 쉽게 산만해지고 머리가 흐릿해지는 날이 잦았고(브레인포그), 좋아하는 일을 제외하면 자꾸 미루는 패턴도 있었습니다. 다행히 지금은 많이 안정됐습니다.\n그런데 저는 여기서 한 걸음 더 나아가고 싶었습니다. \n'컨디션이 좋아진 날'만이 아니라, '평소에도 생각을 정리하고 쌓아가는 방식'이 필요했거든요.\n그래서 제 자신을 위한 '지식 관리 시스템'을 연구하기 시작했습니다. 그 과정에서 느낀 변화는 분명했습니다. 머릿속이 덜 복잡해졌고, 생각이 또렷해졌습니다. 무엇보다 '깊이 있게 생각한다'는 감각을 다시 되찾는 느낌이 있었어요.\n이 경험과 방법을 제 나름대로 정제해서, 뉴스레터로 차근차근 공유해보려 합니다.\n> 참고: 이 글은 개인 경험과 작업 방식에 대한 기록이며, 의료적 조언이 아닙니다.\n### 지난 글에서 이야기한 것\n지난 뉴스레터에서는 '왜 머릿속이 복잡해지는지'를 간단히 다뤘습니다. 그리고 그 복잡함을 '단점'이 아니라, '통찰로 이어지게 만드는 방법'이 있다고도 말씀드렸죠.\n그 방법이 바로 '제텔카스텐(Zettelkasten)' 입니다. 독일어로는 '메모 상자'라는 뜻이고, 독일의 사회학자 '니클라스 루만(Niklas Luhmann)' 이 자신의 지식을 모으고 정제하기 위해 발전시킨 방식으로 유명합니다. 그는 이 시스템을 바탕으로 방대한 분량의 글을 생산했다고 알려져 있습니다.\n---\n### 제텔카스텐은 왜 \"간단하지만 어려울까\"\n제텔카스텐은 원리만 보면 단순합니다.\n- 수집: 생각/인용/아이디어를 메모로 남기고 \n- 정제: 쪼개고, 의미를 붙이고 \n- 연결: 서로 이어 붙여 \n- 글쓰기: 글로 확장한다\n그런데 어려운 이유도 명확합니다. \n제텔카스텐에는 '이게 정답이다' 같은 단 하나의 매뉴얼이 없습니다. 결국 핵심은 **'내가 계속 쓸 수 있는 내 시스템을 만들어 가는 것'**이기 때문입니다.\n---\n### 제 시스템(초기 → 현재)\n처음부터 거창하진 않았습니다. 초창기 시스템은 아주 작고 단순했어요.\n![초창기 시스템](https://cdn.maily.so/du/linked.note/202512/1766283346241416.png)\n초창기 시스템\n하지만 지금은 훨씬 커졌고, 지금도 계속 발전 중입니다.\n![현재 시스템](https://cdn.maily.so/du/linked.note/202512/1766226641868492.png)\n현재 시스템\n이 뉴스레터에서는 여러분도 자기 상황에 맞는 시스템을 직접 만들 수 있도록, 제가 했던 시행착오까지 포함해 안내드리려 합니다.\n같이 지식 관리 시스템을 구축하고 발전시키면서, 각자의 **세컨드 브레인(Second Brain)** 을 만들어봅시다. \n피드백과 토론은 언제나 열려 있습니다.\n---\n### 발행 계획(2026년 1분기)\n- 매주 **화요일 / 목요일**, 주 2회 발행\n- 화요일: 개념 · 원칙 · 사고법(왜/무엇) \n- 목요일: 워크플로우 · 템플릿 · 실습(어떻게/해보기)\n목요일에는 실제 적용을 돕기 위해 **간단한 과제**도 함께 드릴 예정입니다. **과제에 대한 피드백은** **구독자**에 한해 제공하겠습니다.\n---\n### 커리큘럼(초안)\n아래는 1분기 동안 다루려는 주제들입니다. (진행하면서 난이도/순서는 조정될 수 있어요.)\n1) 왜 또 노트법인가: 제텔카스텐이 AI 시대에 다시 뜨는 이유 \n2) 내 노트 시스템 진단하기: 지금 쓰는 메모는 무엇을 막고 있나 \n3) 원자적 노트란 무엇인가: 잘게 쪼갤수록 생각이 선명해진다 \n- 실습: 오늘 읽은 글 1개로 원자 노트 3개 뽑아내기 \n4) 링크의 힘: 노트끼리 연결될 때 생기는 '두 번째 뇌'\n- 실습: 오늘 만든 노트 5개를 서로 연결하기 \n5) AI 전·후의 노트: 어디까지 자동화하고, 어디서부터는 사람이 해야 할까 \n- 실습: AI를 노트 도우미로 쓰는 프롬프트 패턴 7가지 \n6) 읽고 끝이 아니라, 읽고 쌓는 사람들의 차이 \n- 실습: 하루 30분 읽기 → 노트로 남기는 최소 절차 \n7) 아이디어는 언제 ‘글감’이 되는가: 인큐베이션과 숙성 \n- 실습: 노트 더미 → 글 뼈대 만들기(아웃라인 사례) \n8) 프로젝트 중심 제텔카스텐: 기록에서 '실행용 지식'으로 \n- 실습: 실제 프로젝트 1개를 노트 구조로 설계해보기 \n9) AI와 함께 쓰는 글: 빈 문서 공포를 줄이는 구조화 전략 \n- 실습: 내 노트 → AI 초안 → 최종 글(엔드 투 엔드 시연) \n10) 툴보다 메소드 먼저: 어떤 앱을 써도 버티는 ZK 원칙 \n- 실습: 내 작업환경에 맞는 노트 구조 설계하기 \n11) 템플릿의 함정과 활용: 똑같은 템플릿이 왜 누구에겐 독이 되나 \n- 실습: 실전 템플릿 3종(읽기/아이디어/프로젝트) \n12) 장기적으로 유지되는 시스템의 조건: 마찰 줄이기 \n- 실습: 주간 리뷰 루틴(정리 + 다음 주 계획) \n13) 내 두 번째 뇌 사용설명서 쓰기: 나만의 언어로 설명해보기 \n14) 앞으로 3개월: 독자와 함께 실험할 실전 미션 제안\n2026년 1분기 동안 위 내용을 다루면서, 여러분과 함께 지식을 정제하는 습관을 만들어가고 싶습니다. \n같이 달려봅시다.",
    "source": "maily.so",
    "sourceUrl": "https://maily.so/linked.note/posts/w6ov2749rk5",
    "category": "AI"
  },
  {
    "title": "저는 인터넷에서 양파를 팝니다",
    "content": "# I sell onions on the Internet\nOctober, 2024April, 2019 | 🧅 🤠 🐂 | [Peter Askew](https://www.askew.org/) \n[*](https://www.deepsouthventures.com/wp-content/uploads/vidalia-onions-in-field.jpg)Vidalia Onions to be exact. \nThey’re classified as a sweet onion, and because of their mild flavor (they don’t make your eyes tear up), some folks can eat them like an apple. Most of my customers do.\nDuring a phone order one season – 2018 I believe – a customer shared this story where he smuggled some Vidalias onto his vacation cruise ship, and during each meal, would instruct the server to ‘take this onion to the back, chop it up, and add it onto my salad* ‘. That story made me smile.\nFolks who love Vidalias, *love Vidalias*.\nLet me stop, though. I don’t want to get ahead of myself.\nHow did all this start? I’m a web guy. I’m not a farmer.\n---\n## I’M ADDICTED TO DOMAIN NAMES\nOddly enough, it didn’t start with an idea.\nBack in 2014, the domain name [VidaliaOnions.com](https://www.vidaliaonions.com/) expired, and went up for auction. For some reason the original owner abandoned it, and being a Georgia native, I recognized it ’cause I was familiar with the industry. I’ve [been buying expired or abandoned domain names](https://www.deepsouthventures.com/build-a-side-business/) for a while, and enjoy developing them into niche businesses. This one was different though – I backordered the domain as a spectator, but for kicks & giggles, I dropped in a bid around $2,200 ’cause I was confident I’d be outbid. \n5 minutes later, I was the proud owner of VidaliaOnions.com. I had no idea what to do with it. Ready, fire, aim.\nAfter the domain landed in my account, I attempted to re-focus my attention on other projects, but the name kept clawing me. Like it was saying:\n> … yoo-hoo… over here… \n---\n*\nWilliam Faulkner had an interesting perspective on writing his characters – on how they essentially wrote themselves*, and how *he* (Faulkner) served as a sortof mechanical in-between. His quote:\n> *I would say to get the character in your mind. Once he is in your mind, and he is right, and he’s true, then he does the work himself. All you need to do then is to trot along behind him and put down what he does and what he says… You’ve got to know the character. You’ve got to believe in him. You’ve got to feel that he is alive… After that, the business of putting him down on paper is mechanical. [[source]](https://faulkner.lib.virginia.edu/display/wfaudio21)*\nThe way Faulkner treats his characters, I treat domain name projects. I buy them with an intention to develop. And I let them take the lead. They’re the inspiration for the business itself. They guide me towards what they need to become. I’m just the dude behind the keyboard (sorta).\nSometimes I buy them at auction, sometimes I buy them from original-owners. But universally, the domain name always comes first, the business idea comes second. \nI don’t usually rush into development. The path of some domains is apparent before I acquire. Others, the path reveals itself down the road. Vidalia was the latter. And after I acquired it, it kept nudging me.\n> Build me… build me… you know how. And you *know* what I should be…\nAfter a month, I began to understand what it was telling me. That I buy pears from Harry & David every year, and I should mimic that same service for Vidalia Onions. Instead of farm-to-door pears, farm-to-door Vidalia Onions. \nAn interesting idea, but daunting to approach. I’m not a farmer, I don’t have employees, I don’t have a packing shed. And I have no logistics or distribution system setup.\nBut the domain name kept staring at me. ಠ~ಠ ////*whispering*////\n> … just start …\n---\n## “take the path to Nothing, and go Nowhere until you reach it.”\n*-the tao of pooh*\n![](https://www.deepsouthventures.com/wp-content/uploads/indy-leap-faith.gif)\n…\nAnd so I did. I’m just dumb enough to try a project of this complexity. The market size justified an online venture. Google Trends showed strong search volume for the phrase. And chefs around the world had already belted their praise over the ‘caviar of sweet onions’. \nSo I just started down a path, with no end goal or milestone set. I just started going. No angel investor. No VC backer. I just used some modest profit from my other [domain name developments](https://www.deepsouthventures.com/) to fund the endeavor. This was Feb of 2015.\nOnce I began, I discovered there was a Vidalia Onion committee which represents all the Vidalia farmers. So I r",
    "source": "deepsouthventures.com",
    "sourceUrl": "https://www.deepsouthventures.com/i-sell-onions-on-the-internet/",
    "category": "AI"
  },
  {
    "title": "2025년 말에 돌아본 AI에 대한 고찰",
    "content": "## [2025년 말 AI에 대한 고찰](/news/157)\n[antirez](/user/antirez) 9일 전. 조회수 105118회. \n````\n* 수년 동안 기능적 증거와 과학적 힌트가 축적되었음에도 불구하고 일부 AI 연구자들은 LLM이 확률론적 앵무새, 즉 다음과 같은 확률적 기계라고 계속 주장했습니다. 1. 프롬프트의 의미에 대해 어떤 표현도 갖지 않습니다. 2. 그들이 말하려는 내용에 대해 어떠한 표현도 하지 않습니다. 2025년에는 마침내 거의 모든 사람들이 그렇게 말하는 것을 멈췄습니다.\n* 사고의 사슬은 이제 LLM 성과를 향상시키는 근본적인 방법입니다. 그런데 CoT란 무엇일까요? 출력이 향상되는 이유는 무엇입니까? 나는 그것이 두 가지라고 믿습니다: 1. 모델 표현의 샘플링(즉, 내부 검색의 한 형태). 프롬프트 주제와 관련된 정보와 개념이 컨텍스트 창에 있으면 모델이 더 효과적으로 응답할 수 있습니다. 2. 그러나 이것을 강화 학습과 혼합하면 모델은 유용한 응답으로 수렴하기 위해 토큰을 하나씩 배치하는 방법도 학습합니다(각 토큰은 모델 상태를 변경함).\n* 스케일링이 우리가 보유한 토큰 수로 제한된다는 생각은 검증 가능한 보상을 제공하는 강화 학습으로 인해 더 이상 사실이 아닙니다. 아직 알파고 37번째 수는 아니지만, 앞으로는 이게 정말 불가능할까요? 예를 들어 속도를 위해 특정 프로그램을 개선하는 것과 같은 특정 작업이 있는데, 이론적으로 모델은 매우 오랜 시간 동안 매우 명확한 보상 신호로 계속해서 진전을 이룰 수 있습니다. 저는 LLM에 적용되는 RL의 개선이 AI의 차세대 혁신이 될 것이라고 믿습니다.\n* AI 지원 프로그래밍에 대한 프로그래머의 저항이 상당히 낮아졌습니다. LLM이 실수를 하더라도 유용한 코드와 힌트를 제공하는 LLM의 능력은 대부분의 회의론자들이 어쨌든 LLM을 사용하기 시작할 정도로 향상되었습니다. 이제 더 많은 사람들이 투자 수익을 받아들일 수 있습니다. 프로그래밍 세계는 여전히 LLM을 동료로 사용하는 사람(예를 들어 모든 상호 작용은 Gemini, Claude 등의 웹 인터페이스를 통해 이루어짐)과 LLM을 독립적인 코딩 에이전트로 사용하는 사람으로 나누어져 있습니다.\n* 몇몇 잘 알려진 AI 과학자들은 트랜스포머에서 일어난 일이 다른 경로를 따라 다시 일어날 수 있고 더 좋게 일어날 수 있다고 믿고 트랜스포머에 대한 대안과 명시적인 상징적 표현 또는 세계 모델이 있는 모델을 조사하기 위해 팀, 회사를 만들기 시작했습니다. 나는 LLM이 이산적 추론 단계를 근사화할 수 있는 공간에서 훈련된 미분 가능한 기계라고 믿으며, 근본적으로 새로운 패러다임이 나타나지 않더라도 우리를 AGI로 안내하는 것이 불가능하지는 않습니다. 근본적으로 다른 여러 아키텍처를 사용하여 AGI에 독립적으로 접근할 수 있을 가능성이 높습니다.\n* 일련의 사고가 LLM의 성격을 근본적으로 변화시켰다고 말하는 사람이 있는데, 이것이 바로 그들이 과거에 LLM이 매우 제한적이라고 주장했고 지금은 마음을 바꾸고 있다고 주장하는 이유입니다. 그들은 CoT 때문에 LLM이 이제 달라졌다고 말합니다. 그들은 거짓말을 하고 있습니다. 이는 여전히 동일한 다음 토큰 대상을 가진 동일한 아키텍처이며, CoT는 토큰별로 토큰과 똑같이 생성됩니다.\n* 현재 ARC 테스트는 처음에 생각했던 것보다 훨씬 덜 극복할 수 없어 보입니다. ARC-AGI-1에서 상당히 잘 수행되는 당면한 작업에 최적화된 작은 모델이 있고, 많은 사람들에 따르면 그러한 결과를 제공하지 않을 아키텍처를 사용하여 ARC-AGI-2에서 인상적인 결과를 달성하는 광범위한 CoT를 갖춘 매우 큰 LLM이 있습니다. ARC는 어떤 방식으로든 안티 LLM 테스트에서 LLM 검증으로 전환되었습니다.\n* 향후 20년간 AI의 근본적인 과제는 멸종을 피하는 것입니다.\n````",
    "source": "antirez.com",
    "sourceUrl": "https://antirez.com/news/157",
    "category": "AI"
  },
  {
    "title": "일러스트로 이해하는 트랜스포머",
    "content": "# 일러스트로 표현된 트랜스포머\n토론:\n[해커 뉴스(65포인트, 댓글 4개)](https://news.ycombinator.com/item?id=18351674), [Reddit r/MachineLearning(29포인트, 댓글 3개)](https://www.reddit.com/r/MachineLearning/comments/8uh2yz/p_the_illustrated_transformer_a_visual_look_at/)\n**\n번역: [아랍어](https://www.mundhor.site/post/post14), [중국어(간체) 1](https://blog.csdn.net/yujianmin1990/article/details/85221271), [중국어(간체) 2](https://blog.csdn.net/qq_36667170/article/details/124359818), [프랑스어 1](https://a-coles.github.io/2020/11/15/transformer-illustre.html), [프랑스어 2](https://lbourdois.github.io/blog/nlp/Transformer/), [이탈리아어](https://medium.com/@val.mannucci/il-transformer-illustrato-it-37a78e3e2348), [일본어](https://tips-memo.com/translation-jayalmmar-transformer), [한국어](https://nlpinkorean.github.io/illustrated-transformer/), [페르시아어](http://dml.qom.ac.ir/2022/05/17/illustrated-transformer/), [러시아어](https://habr.com/ru/post/486358/), [스페인어 1](https://www.ibidemgroup.com/edu/transformer-ilustrado-jay-alammar/), [스페인어 2](https://hackernoon.com/el-transformador-ilustrado-una-traduccion-al-espanol-0y73wwp), [베트남어](https://trituenhantao.io/tin-tuc/minh-hoa-transformer/)\n보기: 이 게시물을 참조한 MIT의 [Deep Learning State of the Art](https://youtu.be/53YvP6gdD7U?t=432) 강의\n[Stanford](https://web.stanford.edu/class/cs224n/), [Harvard](https://scholar.harvard.edu/binxuw/classes/machine-learning-scratch/materials/transformers)의 강좌에 소개되어 있습니다. [MIT](https://ocw.mit.edu/courses/6-s897-machine-learning-for-healthcare-spring-2019/d39a6eed387ee90b1f72a01949c35c7b_MIT6_S897S19_lec8.pdf), [프린스턴](https://www.cs.princeton.edu/courses/archive/fall22/cos597G/), [CMU](https://www.cs.cmu.edu/~leili/course/mldl22w/14-Transformer.pdf) 외\n[![](https://github.com/user-attachments/assets/a471dfff-00cc-4cb4-8df5-123e195bcc71)](https://www.llm-book.com)\n업데이트:** 이 게시물은 이제 책이 되었습니다! 최신 Transformer 모델과 원래 Transformer 이후 7년 동안 어떻게 진화했는지(Multi-Query Attention 및 RoPE 위치 임베딩 등)에 대해 설명하는 이 게시물의 업데이트되고 확장된 버전(3장)이 포함된 [LLM-book.com](https://llm-book.com)을 확인하세요.\n[이전 게시물에서 우리는 최신 딥 러닝 모델의 유비쿼터스 방법인 Attention](https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/)을 살펴보았습니다. Attention은 신경 기계 번역 애플리케이션의 성능을 향상시키는 데 도움이 되는 개념입니다. 이 게시물에서는 주목을 사용하여 모델의 학습 속도를 높이는 모델인 **The Transformer**를 살펴보겠습니다. Transformer는 특정 작업에서 Google 신경망 기계 번역 모델보다 성능이 뛰어납니다. 그러나 가장 큰 이점은 Transformer가 병렬화에 적합하다는 것입니다. 실제로 Google Cloud는 [Cloud TPU](https://cloud.google.com/tpu/) 제품을 사용하기 위한 참조 모델로 Transformer를 사용하는 것을 권장합니다. 이제 모델을 분리하고 그것이 어떻게 작동하는지 살펴보겠습니다.\nTransformer는 [Attention is All You Need](https://arxiv.org/abs/1706.03762) 논문에서 제안되었습니다. TensorFlow 구현은 [Tensor2Tensor](https://github.com/tensorflow/tensor2tensor) 패키지의 일부로 제공됩니다. Harvard의 NLP 그룹은 [PyTorch 구현으로 논문에 주석을 추가하는 가이드](http://nlp.seas.harvard.edu/2018/04/03/attention.html)를 만들었습니다. 이번 포스팅에서는 주제에 대해 깊이 있는 지식이 없어도 사람들이 쉽게 이해할 수 있도록 좀 더 단순화하고 개념을 하나씩 소개하려고 합니다.\n**2025년 업데이트**: 이 게시물의 내용을 애니메이션으로 업데이트하는 [무료 단기 강좌](https://bit.ly/4aRnn7Z)를 구축했습니다.\n## 높은 수준의 모습\n먼저 모델을 하나의 블랙박스로 살펴보겠습니다. 기계 번역 애플리케이션에서는 한 언어로 된 문장을 받아 다른 언어로 번역을 출력합니다.\n![](/images/t/the_transformer_3.png)\nOptimus Prime의 장점을 열면 인코딩 구성 요소, 디코딩 구성 요소 및 이들 사이의 연결이 보입니다.\n![](/images/t/The_transformer_encoders_decoders.png)\n인코딩 구성 요소는 인코더 스택입니다(종이에는 6개가 서로 겹쳐져 있습니다. 숫자 6에는 마법 같은 것이 없으며 확실히 다른 배열을 실험해 볼 수 있습니다). 데코디",
    "source": "jalammar.github.io",
    "sourceUrl": "https://jalammar.github.io/illustrated-transformer/",
    "category": "AI"
  },
  {
    "title": "Show GN: 428억 토큰 쓰는 사람들 줄 세워보기",
    "content": "[*](https://tokscale.ai)\n**\n여러 플랫폼에서 AI 코딩 보조 토큰 사용 및 비용을 추적하기 위한 고성능 CLI 도구 및 시각화 대시보드입니다.\n[![GitHub 릴리스](https://img.shields.io/github/v/release/junhoyeo/tokscale?color=0073FF&labelColor=black&logo=github&style=plat-square)](https://github.com/junhoyeo/tokscale/releases)\n[![npm 다운로드](https://img.shields.io/npm/dt/tokscale?color=0073FF&labelColor=black&style=plat-square)](https://www.npmjs.com/package/tokscale)\n[![GitHub 기여자](https://img.shields.io/github/contributors/junhoyeo/tokscale?color=0073FF&labelColor=black&style=Flat-square)](https://github.com/junhoyeo/tokscale/graphs/contributors)\n[![GitHub 포크](https://img.shields.io/github/forks/junhoyeo/tokscale?color=0073FF&labelColor=black&style=plat-square)](https://github.com/junhoyeo/tokscale/network/members)\n[![GitHub Stars](https://img.shields.io/github/stars/junhoyeo/tokscale?color=0073FF&labelColor=black&style=plat-square)](https://github.com/junhoyeo/tokscale/stargazers)\n[![GitHub 문제](https://img.shields.io/github/issues/junhoyeo/tokscale?color=0073FF&labelColor=black&style=plat-square)](https://github.com/junhoyeo/tokscale/issues)\n[![라이선스](https://img.shields.io/badge/license-MIT-white?labelColor=black&style=plat-square)](https://github.com/junhoyeo/tokscale/blob/master/LICENSE)\n[한국어](/junhoyeo/tokscale/blob/main/README.md) | [한국어](/junhoyeo/tokscale/blob/main/README.ko.md) | [일본어](/junhoyeo/tokscale/blob/main/README.ja.md) | [简体中文](/junhoyeo/tokscale/blob/main/README.zh-cn.md)\n개요\n모델\n[![TUI 개요](/junhoyeo/tokscale/raw/main/.github/assets/tui-overview.png)](/junhoyeo/tokscale/blob/main/.github/assets/tui-overview.png)\n[![TUI 모델](/junhoyeo/tokscale/raw/main/.github/assets/tui-models.png)](/junhoyeo/tokscale/blob/main/.github/assets/tui-models.png)\n일일 요약\n통계\n[![TUI 일일 요약](/junhoyeo/tokscale/raw/main/.github/assets/tui-daily.png)](/junhoyeo/tokscale/blob/main/.github/assets/tui-daily.png)\n[![TUI 통계](/junhoyeo/tokscale/raw/main/.github/assets/tui-stats.png)](/junhoyeo/tokscale/blob/main/.github/assets/tui-stats.png)\n프런트엔드(3D 기여도 그래프)\n포장 2025\n[![프런트엔드(3D 기여 그래프)](/junhoyeo/tokscale/raw/main/.github/assets/frontend-contributions-graph.png)](https://tokscale.ai)\n[![랩핑 2025](/junhoyeo/tokscale/raw/main/.github/assets/wrapped-2025-agents.png)](#wrapped-2025)\n> \n[`bunx tokscale@latest submit`](#social)을 실행하여 사용 데이터를 리더보드에 제출하고 공개 프로필을 만드세요!**\n## 내용\n[](#내용)\n- [개요](#overview)\n[왜 \"Tokscale\"인가요?](#why-tokscale)\n- [기능](#features)\n- [설치](#installation)\n[빠른 시작](#quick-start)\n- [전제조건](#prerequisites)\n- [개발 설정](#development-setup)\n- [네이티브 모듈 빌드](#building-the-native-module)\n- [사용](#사용)\n[기본 명령어](#basic-commands)\n- [TUI 기능](#tui-features)\n- [플랫폼별 필터링](#filtering-by-platform)\n- [날짜 필터링](#date-filtering)\n- [가격조회](#pricing-lookup)\n- [소셜](#social)\n- [커서 IDE 명령](#cursor-ide-commands)\n- [환경변수](#environment-variables)\n- [프런트엔드 시각화](#frontend-visualization)\n[기능](#features-1)\n- [프런트엔드 실행](#running-the-frontend)\n- [소셜 플랫폼](#social-platform)\n[기능](#features-2)\n- [시작하기](#getting-started)\n- [데이터 유효성 검사](#data-validation)\n- [랩핑 2025](#wrapped-2025)\n- [개발](#개발)\n- [지원 플랫폼](#supported-platforms)\n- [세션 데이터 보존](#session-data-retention)\n- [데이터 소스](#data-sources)\n- [가격](#pricing)\n- [기여](#기여)\n- [감사의 말씀](#acknowledgements)\n- [라이센스](#license)\n## 개요\n[](#개요)\n**Tokscale**은 다음을 통해 토큰 소비를 모니터링하고 분석하는 데 도움이 됩니다.\n로고\n클라이언트\n데이터 위치\n지원됨\n[![OpenCode](/junhoyeo/tokscale/raw/main/.github/assets/client-opencode.png)](/junhoyeo/tokscale/blob/main/.github/assets/client-opencode.png)\n[오픈코드](https://github.com/sst/opencode)\n`~/.local/share/opencode/storage/message/`\n✅ 예\n[![클로드](/junhoyeo/tokscale/raw/main/.github/assets/client-claude.jpg)](/junhoyeo/tokscale/blob/main/.github/assets/client-claude.jpg)\n[클로드 코드](https://docs.anthropic.com/en/docs/claude-code)\n`~/.claude/projects/`\n✅ 예\n[![코덱스](/junhoyeo/tokscale/raw/main/.github/assets/client-openai.jpg)](/junhoyeo/tokscale/blob/main/.github/assets/client-openai.jpg)\n[코덱스 CLI](",
    "source": "github.com",
    "sourceUrl": "https://github.com/junhoyeo/tokscale",
    "category": "AI"
  },
  {
    "title": "항상 문제는 TCP_NODELAY다",
    "content": "# 항상 TCP_NODELAY입니다. 매번.\n다행히 이제 더 이상 1980년대가 아닙니다.\n분산 시스템에서 지연 문제를 디버깅할 때 가장 먼저 확인하는 것은 [TCP_NODELAY](https://linux.die.net/man/7/tcp)가 활성화되어 있는지 여부입니다. 그리고 그것은 나만이 아닙니다. 내가 아는 모든 분산 시스템 빌더는 이 간단한 소켓 옵션을 활성화하여 신속하게 해결된 지연 문제로 인해 몇 시간을 허비했습니다. 이는 기본 동작이 잘못되었으며 아마도 전체 개념이 시대에 뒤떨어졌음을 암시합니다.\n먼저, 우리가 말하는 내용을 명확히 합시다. 1984년[1](#foot1)에서 나온 John Nagle의 [RFC896](https://datatracker.ietf.org/doc/html/rfc896)보다 더 나은 소스는 없습니다. 첫째, 문제 설명은 다음과 같습니다.\n> \n작은 패킷과 관련된 특별한 문제가 있습니다. 키보드에서 시작되는 단일 문자 메시지의 전송에 TCP가 사용되는 경우 일반적인 결과는 유용한 데이터의 각 바이트에 대해 41바이트 패킷(데이터 1바이트, 헤더 40바이트)이 전송되는 것입니다. 이 4000% 오버헤드는 짜증나지만 부하가 적은 네트워크에서는 견딜 수 있습니다.\n간단히 말해서, Nagle은 네트워크에서 더 나은 처리량을 얻기 위해 TCP 헤더 비용을 더 잘 상환하는 데 관심이 있었습니다. 최대 40배 향상된 처리량! 이러한 작은 패킷에는 두 가지 주요 원인이 있습니다. 즉, 사람들이 한 번에 한 바이트씩 입력하는 쉘과 같은 인간 대화형 애플리케이션과 많은 '쓰기' 호출을 통해 메시지를 커널로 드리블하는 제대로 구현되지 않은 프로그램입니다. 이 문제를 해결하기 위한 Nagle의 제안은 간단하고 스마트했습니다.\n> \n간단하고 우아한 솔루션이 발견되었습니다.\n> \n해결 방법은 연결을 통해 이전에 전송된 데이터가 승인되지 않은 상태로 남아 있는 경우 사용자로부터 새 나가는 데이터가 도착할 때 새 TCP 세그먼트의 전송을 금지하는 것입니다.\n많은 사람들이 Nagle 알고리즘을 이야기할 때 타이머를 이야기하지만 RFC896은 네트워크의 왕복 시간 외에는 어떤 종류의 타이머도 사용하지 않습니다.\n*Nagle의 알고리즘 및 지연된 승인*\nNagle의 훌륭하고 깔끔한 제안은 다른 TCP 기능인 'ACK' 지연과 제대로 상호작용하지 않았습니다. 지연된 `ACK`의 개념은 적어도 다시 보낼 데이터가 있을 때까지(예: 사용자의 입력을 다시 반향하는 `telnet` 세션) 또는 타이머가 만료될 때까지 패킷 승인 전송을 지연하는 것입니다. 1982년의 [RFC813](https://datatracker.ietf.org/doc/html/rfc813)은 'ACK' 지연을 제안하는 것처럼 보이는 첫 번째 항목입니다.\n> \n데이터 수신자는 특정 상황에서 승인 전송을 삼가며, 이 경우 나중에 승인이 전송되도록 타이머를 설정해야 합니다. 그러나 수신자는 다른 이벤트가 개입하여 타이머 인터럽트의 필요성을 방지할 것이라고 합리적으로 추측하는 경우에만 이 작업을 수행해야 합니다.\n이는 1989년부터 [RFC1122](https://datatracker.ietf.org/doc/html/rfc1122)에서 추가로 공식화되었습니다. 이 두 기능 간의 상호 작용은 문제를 야기합니다. Nagle의 알고리즘은 'ACK'가 수신될 때까지 더 많은 데이터 전송을 차단하지만 지연된 ack는 응답이 준비될 때까지 해당 'ack'을 지연시킵니다. 패킷을 가득 채운 상태로 유지하는 데 적합하지만 대기 시간에 민감한 파이프라인 애플리케이션에는 적합하지 않습니다.\n이것은 Nagle이 여러 번 스스로 주장한 요점입니다. 예를 들어 이 [Hacker News 댓글](https://news.ycombinator.com/item?id=10608356)은 다음과 같습니다.\n> \n그게 아직도 짜증나네요. 진짜 문제는 타이니그램 예방이 아닙니다. ACK 지연과 멍청한 고정 타이머입니다. 둘 다 거의 같은 시기에 TCP에 들어왔지만 독립적이었습니다. 나는 1980년대 초반에 Tinygram 방지(Nagle 알고리즘)를 수행했고 Berkeley는 지연 ACK를 수행했습니다. 둘의 조합이 끔찍하네요.\n시스템 빌더로서 이는 익숙한 상황입니다. 즉, 바람직하지 않은 동작을 생성하기 위해 상호 작용하는 시스템의 두 가지 합리적인 기능입니다. 이런 종류의 상호 작용은 프로토콜 설계를 매우 어렵게 만드는 것 중 하나입니다.\n*네이글은 무죄인가요?*\n안타깝게도 ACK[2](#foot2)만 지연된 것이 아닙니다. 지연된 승인과 *어리석은 고정 타이머*가 없더라도 Nagle 알고리즘의 동작은 아마도 분산 시스템에서 우리가 원하는 것이 아닐 것입니다. 단일 데이터 센터 내 RTT는 일반적으로 약 500μs이고, 같은 지역의 데이터 센터 간에는 2밀리초, 전 세계적으로는 최대 수백 밀리초입니다. 최신 서버가 단 몇 백 마이크로초 내에 수행할 수 있는 엄청난 양의 작업을 고려하면, 단 하나의 RTT에 대한 데이터 전송을 지연하는 것은 분명히 승리가 아닙니다.\n더 명확한 사례를 만들기 위해 Nagle 알고리즘의 근거로 돌아가서 헤더 비용을 상각하고 단일 바이트 패킷에서 40배의 오버헤드를 피하도록 하겠습니다. 하지만 누가 볼까?",
    "source": "brooker.co.za",
    "sourceUrl": "https://brooker.co.za/blog/2024/05/09/nagle.html",
    "category": "AI"
  },
  {
    "title": "Show GN: AI 기반 개발자 기술면접 준비 서비스",
    "content": "# AI와 함께하는\n개발자 면접 준비\n채용공고를 분석하여 맞춤형 면접 질문을 생성하고, AI 튜터와 대화하며 실전처럼 학습하세요.\n[무료로 시작하기](/login)\n### 채용공고 분석\n채용공고 URL이나 텍스트를 입력하면 AI가 핵심 요구사항을 분석하여 맞춤형 면접 질문을 생성합니다.\n### AI 튜터링\n각 면접 질문에 대해 AI 튜터와 대화하며 학습합니다. 모르는 부분은 질문하고, 깊이 있는 이해를 쌓아가세요.\n### 학습 문서 생성\nAI 튜터와의 대화 내용을 바탕으로 정리된 학습 문서를 자동으로 생성합니다. 면접 직전 복습에 활용하세요.\n### 실전 모의 면접\n학습한 내용을 바탕으로 실제 면접처럼 테스트합니다. AI가 면접관이 되어 질문하고 답변을 평가합니다.",
    "source": "luminite.io",
    "sourceUrl": "https://luminite.io",
    "category": "AI"
  },
  {
    "title": "Claude Code에 네이티브 LSP 지원 기능 추가",
    "content": "[\n인류학\n](/인류학) \n/\n**\n[클로드 코드](/anthropics/claude-code)\n**\n공개\n- \n[ \n알림\n](/login?return_to=%2Fanthropics%2Fclaude-code) 알림 설정을 변경하려면 로그인해야 합니다.\n- \n[ \n포크\n3.5천\n](/login?return_to=%2Fanthropics%2Fclaude-코드)\n- \n[ \n스타\n49.7k\n](/login?return_to=%2Fanthropics%2Fclaude-코드)",
    "source": "github.com",
    "sourceUrl": "https://github.com/anthropics/claude-code/blob/main/CHANGELOG.md",
    "category": "AI"
  },
  {
    "title": "루비 4.0.0",
    "content": "# 루비 4.0.0 출시\n게시자: **naruse**, 2025년 12월 25일\nRuby 4.0.0의 출시를 발표하게 되어 기쁘게 생각합니다.\nRuby 4.0에는 “Ruby Box”와 “ZJIT”가 도입되었으며 많은 개선 사항이 추가되었습니다.\n## 루비 상자\nRuby Box는 정의를 분리하는 새로운(실험적) 기능입니다. 환경 변수 `RUBY_BOX=1`을 지정하면 Ruby Box가 활성화됩니다. 클래스는 `Ruby::Box`입니다.\n상자에 로드된 정의는 상자 내에서 격리됩니다. Ruby Box는 원숭이 패치, 전역/클래스 변수 변경, 클래스/모듈 정의, 로드된 기본/Ruby 라이브러리를 다른 상자에서 분리/분리할 수 있습니다.\n예상되는 사용 사례는 다음과 같습니다.\n- 테스트 케이스가 원숭이 패치를 사용하여 무언가를 재정의할 때 다른 테스트를 보호하기 위해 상자에서 테스트 케이스를 실행합니다.\n- Ruby 프로세스의 앱 서버에서 블루-그린 배포를 실행하기 위해 웹 앱 상자를 병렬로 실행합니다.\n- 웹 앱 상자를 병렬로 실행하여 Ruby 코드를 사용하여 응답 차이를 확인함으로써 특정 기간 동안 종속성 업데이트를 평가합니다.\n- 일종의 \"패키지\"(고수준) API를 구현하기 위한 기초(저수준) API로 사용됩니다(아직 설계되지 않음).\n“Ruby Box”에 대한 자세한 내용은 [Ruby::Box](https://docs.ruby-lang.org/en/master/Ruby/Box.html)를 참조하세요.\n[[기능 #21311](https://bugs.ruby-lang.org/issues/21311)] [[기타 #21385](https://bugs.ruby-lang.org/issues/21385)]\n## ZJIT\nZJIT는 YJIT의 차세대 버전으로 개발된 새로운 JIT(Just-In-Time) 컴파일러입니다. ZJIT 지원으로 Ruby를 빌드하려면 Rust 1.85.0 이상이 필요하며 `--zjit`가 지정되면 ZJIT가 활성화됩니다.\n우리는 성능 한계를 높이고(더 큰 컴파일 단위 크기 및 SSA IR) 더 많은 외부 기여를 장려하기 위해(보다 전통적인 메소드 컴파일러가 됨으로써) Ruby용 새 컴파일러를 구축하고 있습니다. 자세한 내용은 [블로그 게시물](https://railsatscale.com/2025-12-24-launch-zjit/)을 참조하세요.\nZJIT는 통역사보다 빠르지만 아직 YJIT만큼 빠르지는 않습니다. ZJIT를 실험해 보시기를 권장하지만 지금은 프로덕션 환경에 배포하는 것을 미루실 수도 있습니다. Ruby 4.1 ZJIT를 계속 지켜봐 주시기 바랍니다.\n## 랙터 개선\nRuby의 병렬 실행 메커니즘인 Ractor가 몇 가지 개선되었습니다. 메시지 전송 및 수신과 관련된 문제를 해결하기 위해 새로운 클래스 `Ractor::Port`가 도입되었습니다([블로그 게시물](https://dev.to/ko1/ractorport-revamping-the-ractor-api-98) 참조). 또한 `Ractor.shareable_proc`을 사용하면 Ractor 간에 `Proc` 개체를 더 쉽게 공유할 수 있습니다.\n성능 측면에서 많은 내부 데이터 구조가 개선되어 전역 잠금에 대한 경합이 크게 줄어들고 더 나은 병렬 처리가 가능해졌습니다. 또한 Ractor는 이제 더 적은 내부 데이터를 공유하므로 병렬로 실행될 때 CPU 캐시 경합이 줄어듭니다.\nRactor는 Ruby 3.0에서 실험적인 기능으로 처음 도입되었습니다. 우리는 내년에 '실험적' 상태를 해제하는 것을 목표로 하고 있습니다.\n## 언어 변경\n- \n`*nil`은 `**nil`이 호출하는 방식과 유사하게 더 이상 `nil.to_a`를 호출하지 않습니다.\n`nil.to_hash`를 호출하지 마세요. [[기능 #21047](https://bugs.ruby-lang.org/issues/21047)]\n- \n논리 이진 연산자(`||`, `&&`, `and` 및 `or`)\n줄의 시작은 유창한 점처럼 이전 줄을 계속합니다.\n다음 코드 예제는 동일합니다.\n````\n조건 1인 경우\n&& 조건2\n...\n끝\n````\n이전:\n````\n조건1 && 조건2인 경우\n...\n끝\n````\n````\n조건1 &&인 경우\n조건 2\n...\n끝\n````\n[[기능 #20925](https://bugs.ruby-lang.org/issues/20925)]\n## 핵심 클래스 업데이트\n참고: 뛰어난 수업 업데이트만 나열하고 있습니다.\n- \n배열\n`Array#rfind`가 `array.reverse_each.find`에 대한 보다 효율적인 대안으로 추가되었습니다. [[기능 #21678](https://bugs.ruby-lang.org/issues/21678)]\n- `Enumerable#find`의 보다 효율적인 재정의로 `Array#find`가 추가되었습니다. [[Feature #21678](https://bugs.ruby-lang.org/issues/21678)]\n- \n바인딩\n`Binding#local_variables`에는 더 이상 번호가 매겨진 매개변수가 포함되지 않습니다.\n또한 `Binding#local_variable_get`, `Binding#local_variable_set` 및\n`Binding#local_variable_defined?`는 번호가 매겨진 매개변수 처리를 거부합니다.\n[[버그 #21049](https://bugs.ruby-lang.org/issues/21049)]\n- \n`Binding#implicit_parameters`, `Binding#implicit_parameter_get` 및\n액세스에 `Binding#implicit_parameter_define?`이 추가되었습니다.\n번호가 매겨진 매개변수와 “it” 매개변수. [[버그 #21049](https://bugs.ruby-lang.org/issues/21049)]\n- \n열거자\n`Enumerator.produce`는 이제 선택적 `size` 키워드 인수를 허용합니다.\n열거자의 크기를 지정합니다. 정수일 수 있습니다.\n`Float::INFINITY`, 호출 가능한 객체(예: 람다) 또는 `nil`\n알 수 없는 크기를 나타냅니다. 지정하지 않으면 크기는 기본적으로\n`플로트::INFINITY`",
    "source": "ruby-lang.org",
    "sourceUrl": "https://www.ruby-lang.org/en/news/2025/12/25/ruby-4-0-0-released/",
    "category": "AI"
  },
  {
    "title": "2025년 최고의 발견과 경험들",
    "content": "[[fogus.me](https://www.fogus.me/)\n/[더 많은 구급대원 보내기](https://blog.fogus.me/)\n/[읽기-평가-인쇄-lamove](https://discord.gg/NmdZB6NEyZ)\n/[src](https://www.github.com/fogus/)]\n# 2025년 최고의 물건과 물건\n포거스\n2025.12.23\n내가 발견하고, 배우고, 읽고, 만난 좋은 것들과 사람들.\n2025년. 특별한 순서는 암시되지 않습니다. 모든 것이 새로운 것은 아닙니다.\n*또한: [2024](https://blog.fogus.me/2024/12/23/the-best-things-and-stuff-of-2024.html)의 목록을 참조하세요.\n[2023](https://blog.fogus.me/2023/12/18/the-best-things-and-stuff-of-2023/),\n[2022](http://blog.fogus.me/2022/12/13/the-best-things-and-stuff-of-2022/),\n[2021](https://blog.fogus.me/2021/12/27/the-best-things-and-stuff-of-2021/),\n[2020](http://blog.fogus.me/2020/12/31/the-best-things-and-stuff-of-2020/),\n[2019](http://blog.fogus.me/2019/12/30/the-best-things-and-stuff-of-2019/),\n[2018](http://blog.fogus.me/2019/01/02/the-best-things-and-stuff-of-2018/),\n[2017](http://blog.fogus.me/2018/01/02/the-best-things-and-stuff-of-2017/),\n[2016](http://blog.fogus.me/2016/12/29/the-best-things-and-stuff-of-2016/),\n[2015](http://blog.fogus.me/2015/12/29/the-best-things-and-stuff-of-2015/),\n[2014](http://blog.fogus.me/2014/12/29/the-best-things-and-stuff-of-2014/),\n[2013](http://blog.fogus.me/2013/12/27/the-best-things-and-stuff-of-2013/),\n[2012](http://blog.fogus.me/2012/12/26/the-best-things-and-stuff-of-2012/),\n[2011](http://blog.fogus.me/2011/12/31/the-best-things-and-stuff-of-2011/)\n및 [2010](http://blog.fogus.me/2010/12/30/the-best-things-in-2010/)*\n## 훌륭한 게시물 | 기사 |\n읽은/본 동영상\n- *[A\n계산기 앱? 누구나 만들 수 있습니다](https://chadnauseam.com/coding/random/calculator-app)* 작성자: Chad Nauseam, esquire\n- *나는 Hans Boehm과 친구들이 어떻게 개발했는지에 대한 이야기를 좋아합니다.\n다음과 같은 숫자에 대한 재귀 실수 산술이라는 놀라운 접근 방식입니다.\n파이와 (sqrt 2). 게시물에 다양한 증상이 자세히 설명되어 있습니다 -> 문제\n정의 -> 대체 솔루션 -> 솔루션 주기\n팀은 도중에 만났으며 다음 내용을 읽어야 합니다.\n프로그래머.*\n- *[길을 잃었다\nManboo](https://www.youtube.com/watch?v=JVyz17kwIv4)* - *manboo(만화 카페 manboo)는 삶을 보여줍니다.\n일본의 24시간 게임 카페에 거주하는 일부 사람들을 위한 정보입니다. 영상은\n현대 세계와 완벽하게 일치하는 방식으로 디스토피아를 치료합니다.*[1](#fn1)\n- *[만들기\nof Deeper in You on the OP-1](https://www.youtube.com/watch?v=0z7_A_8il_g)* - *아티스트의 접근 방식을 보여줍니다.\nOP-1 신디사이저를 사용한 곡 생성/작곡. 이것은\n다음과 같은 음악적 재능이 전혀 없는 사람을 지켜보는 최면\n나 자신.*\n- *[안\nJack Rusher와의 인터뷰](https://thecreativeindependent.com/people/multi-disciplinary-artist-jack-rusher-on-the-need-to-sustain-your-creative-drive-in-the-face-of-technological-change/)* - The Creative Independent - *A\n온라인 친구인 Jack Rusher와의 멋진 인터뷰에서\n예술, 흐름, 연구 상태에 기술을 사려 깊게 적용\n현대 컴퓨팅 산업에서.*\n- *[신용 없음: 검색 중\n잃어버린 보드 게임 디자이너를 위한](https://www.youtube.com/watch?v=MWteJW-wYas)* 작성자: Amabel Holland - *Amabel\n디자이너를 찾으면서 겪은 시련과 고난을 설명합니다.\n오랫동안 잊혀진 보드게임의 [복제]\n애드립 크로스워드 큐브](https://boardgamegeek.com/boardgame/4791/duplicate-ad-lib-crossword-cubes).*\n- *[브라이언\nWeissman의 Magic the Gathering 역사](https://www.youtube.com/watch?v=TldMsMtHvW8)* - *누구나\n매직 초기에 성년이 된 브라이언이라는 이름의 사람\n와이즈먼은 전설적이다. 이번 인터뷰에서 그는 셀 수 없이 많은 일화를 들려준다.\n초기에 자신이 겪은 일에 대해 이야기합니다.*\n- *[이전\nArcturus: David Lindsay의 잃어버린 소설](https://wormwoodiana.blogspot.com/2025/08/before-arcturus-david-lindsays-lost.html)* 작성자: Mark Valentine -\n*David Lindsay에 대한 Mark의 연구에서 그가 다음과 같은 증거를 밝혔습니다.\n적어도 두 편의 초기 소설인 Aletheus와 The Confessions of를 제출했습니다.\n1902년과 1908년에 출판사 Chatto & Windus에게 이기주의자가 되었습니다.\n제출물은 그의 첫 번째 출판 걸작인 [A] 이전에 제출되었습니다.\n아크튜러스로의 항해](https://bookshop.org/p/books/a-voyage-to-arcturus-an-illuminated-edition-david-lindsay/76f8dc45a1376ddf?aid=98208&ean=9781948886307&listref=best-things-2025&next=t).*\n- *[댄이 읽은 내용](https://what-dan-read.com/)* by\nDan - *평생 독서에 대한 놀라운 이야기.*\n- *[두\nCormac McCarthy가 사망한 지 몇 년 후, 그의 개인 도서관에 대한 접근이 거의 이루어지지 않았습니다.\n신화 뒤에 숨겨진 인물을 밝힙니다](https://www.smithsonianmag.com/arts-culture/two-years-cormac-mccarthys-death-rare-access-to-persona",
    "source": "blog.fogus.me",
    "sourceUrl": "https://blog.fogus.me/2025/12/23/the-best-things-and-stuff-of-2025.html",
    "category": "AI"
  },
  {
    "title": "2025년 AI 10대 트렌드 : 광기(Hype)에서 현실(Reality)로",
    "content": "# 2025년 AI 10대 트렌드\n2025년 12월 23일1,498AI 트렌드인공지능2025년 AI딥시크DeepSeekAI 수익성AI 인프라AI 규제AI 시장AI 조직\n## 2025년 AI 10대 트렌드: **광기(Hype)에서 현실(Reality)로****\n*2025년의 AI는 “가능성”을 증명하는 해가 아니었습니다. \n가능성은 이미 2023~2024년에 충분히 보여줬고, 2025년에는 그 대가가 청구서로 날아왔습니다.****한 해는 ‘DeepSeek’라는 다윗의 돌팔매질로 시작해, ‘수익성(ROI)’과 ‘전력(인프라)’이라는 현실 앞에서 숨을 고르며 끝났습니다. 기술은 빛의 속도로 진화했지만, 기업은 더 느리고 무거운 질문을 꺼냈죠.\n- “이제 모델은 얼마나 싸졌나?”\n- “그런데 왜 우리 비용은 더 늘지?”\n- “인력 구조는 어떻게 바뀌어야 하지?”\n- “보안과 신뢰의 비용은 누가 지불하나?”\n이 글은 2025년을 관통한 AI 10대 트렌드**를 ‘연대기’처럼 따라가며, 기업이 실제로 맞닥뜨린 전장(시장·조직·규제·인프라)을 한 편의 이야기로 정리합니다.\n---\n## 제1막: 신들의 전쟁 (The War of Gods)\n### “가격은 바닥으로, 지능은 천장으로”\n---\n## 1) 딥시크(DeepSeek) 쇼크: ‘가성비 혁명’이 촉발한 지능의 민주화\n2025년 1월 27일. 시장은 한 번 더 “AI는 돈 많은 자의 게임”이라고 믿고 있었습니다.**그 믿음이 깨진 날이 바로 그날이었습니다.\n중국의 퀀트 헤지펀드 출신 스타트업 DeepSeek**는 오픈소스 모델(DeepSeek-V3)과 추론 모델(R1)을 공개하며, 실리콘밸리의 공식을 정면으로 뒤집었습니다. 핵심은 간단했습니다.\n**“더 비싼 GPU가 아니라, 더 영리한 설계로도 동급 성능이 가능하다.”**\n![](https://gzguucdzsrfypbkqlyku.supabase.co/storage/v1/object/public/uslab-images/uslab/1766356014093-jjgyigkctv.jpg)DeepSeek는 GPT-4 훈련에 약 1억 달러가 들어갔다는 시장 추정과 대비되는 **560만 달러** 수준의 비용으로 대등한 성능을 구현했다고 발표합니다. 더 충격적인 포인트는 **H100이 아니라 H800 2,000개** 기반의 효율적 병렬 운용이었다는 점입니다.\n이 “비용의 기적”은 곧장 금융시장에 반사됐고, 엔비디아 주가 급락 같은 사건으로 번졌습니다.\n그런데 진짜 파장은 주가가 아니라 **가격 구조**였습니다.**DeepSeek는 “추론 모델” API를 1M 토큰 기준 캐시 히트 $0.14 / 캐시 미스 $0.55 / 출력 $2.19**로 제시했습니다. **이 숫자들이 왜 중요할까요? 기업 관점에서 의미는 명확합니다.\n- 모델 자체는 점점 ‘원가에 수렴’**한다.\n- 차별화는 모델이 아니라 **“어떤 업무 흐름에, 어떤 데이터로, 어떤 책임 구조로 얹느냐”**로 이동한다.\n- ‘LLM을 쓰는 회사’가 아니라, **LLM을 운영하는 회사**가 이긴다.\n한 마디로 2025년 1월 27일은, AI가 **사치재에서 유틸리티로 넘어간** 날이었습니다.\n그리고 이 변화는 곧장 다음 전투로 이어집니다. **‘누가 가장 똑똑한가’가 아니라, ‘누가 가장 빨리 표준을 장악하는가’**의 전쟁으로요.\n---\n## 2) OpenAI vs Google: 25일간의 왕좌의 게임 — “모델 전쟁은 곧 플랫폼 전쟁”\n2025년을 관통한 두 번째 큰 흐름은, ‘AI 패권 경쟁’이 더 이상 연구 경쟁이 아니라 **플랫폼 경쟁**으로 변했다는 점입니다.\n- 2월, OpenAI의 ‘지브리 스타일’ 열풍이 전 세계를 휩쓸며 AI가 대중문화 한복판으로 들어옵니다.\n외부 보도에 따르면, 이 유행은 **일주일 만에 1억 3천만 명이 7억 장 이상의 이미지를 생성**할 정도로 폭발적이었습니다.\n- 8월, 구글은 ‘Nano Banana(Gemini 2.5 Flash Image)’ 같은 이미지 모델로 밈을 만들며 “힙한 AI”의 반격을 시작합니다.\n![](https://gzguucdzsrfypbkqlyku.supabase.co/storage/v1/object/public/uslab-images/uslab/1766356683083-pmlb7rlrmf.png)\n- 11월 18일, 구글은 **Gemini 3 Pro**를 공개하고(릴리즈 노트 기준), 12월에는 Deep Think 계열을 확장합니다.\n- 위기를 느낀 샘 알트만은 ‘Code Red’를 발령, 수익화 프로젝트를 뒤로 미루고 모델 성능 개선에 리소스를 집중합니다.\n- 그리고 12월 11일, OpenAI는 **GPT‑5.2**를 공개하며 반격합니다.\n![](https://gzguucdzsrfypbkqlyku.supabase.co/storage/v1/object/public/uslab-images/uslab/1766356553956-2sxe0uxisc2.png)여기서 기업이 놓치기 쉬운 핵심은 이겁니다.**이 싸움의 승패는 “벤치마크 1~2점”이 아니라, 사용자 행동을 바꾸는 ‘플랫폼 경험’**에서 갈립니다.\n- 텍스트만 잘하는 모델 → **이미지·비디오·음성·툴 사용**으로 확장\n- 단발성 답변 → **워크플로우 안에 들어가는 에이전트**로 진화\n- “검색”의 자리를 놓고 경쟁 → “업무의 조종석”을 두고 경쟁\n즉, 2025년의 왕좌의 게임은 단순히 두 회사의 PR 전쟁이 아닙니다.**기업에게는 “내가 어느 진영(플랫폼)에 묶일 것인가”라는 전략적 선택**을 강요하는 사건이었습니다.\n---\n## 제2막: 현실의 점령 (The Great Permeation)\n### “AI가 화면 밖으로 나와, 삶과 산업을 장악하다”\n---\n## 3) 비디오 혁명: 상업 광고의 표준이 되다 — 다만, ‘하드 서피스’만\n2024년의 ‘Sora 쇼크’가 “와…”로 끝났다면, 2025년은 “그래서 써봤다”로 시작합니다.**광고·캠페인·숏폼·뮤직비디오까지, 생성형 비디오는 상업 미디어의 기본 옵션**이 됐습니다.\n![](https://gzguucdzsrfypbkqlyku.supabase.co/storage/v1/object/public/uslab-images/uslab/1766366236423-od3i9k41xt8.png)그런데 재미있게도, AI 비디오의 성패는 “모델 성능”보다 **대상이 무엇이냐**에 갈렸습니다. 이를 **‘하드 서피스의 승리, 소프트 티슈의 패배’**로 정리합니다.\n- **하드 서피스(금속·유리·플라스틱·자동차·산업재)**: AI가 리얼리즘을 거의 완벽하게 구현\n- **소프트 티슈(사람 표정·동물 움직임·감정 교류)**: ‘불쾌한 골짜기’가 그대로 드러나며 역풍\n**교육기업 야나두**의 100% 생성형 AI 광고는 유튜브 조회수 **1,300만 뷰**를 넘기며 ‘저예산 고퀄’의 가능성을 증명했다고 정리됩니다.\n(AI 영상의 가능성을 보여준 야나두 AI 영상)\n반면, 코카콜라·맥도날드처럼 **사람/동물의 표정**을 전면에 내세운 광고는 “영혼이 없다”, “기괴하다”는 반응을 얻으며 실패 사례로 기록됩니다.\n(코카콜라 AI 영상)\n더 흥미로운 건 “기업 내부 제작”의 확산입니다. 예를 들어 LG유플러스는 사내 TF가 Sora·ChatGPT 등 도구를 활용해 숏츠 광고를 제작했고, **제작비 95% 절감·기간 70% 단축** 사례로 정리됩니다.\n이 장면이 기업에 던지는 메시지는 분명합니다.\n- 마케팅/브랜딩에서 **제작 역량은 더 이상 ‘예산’만의 게임이 아니다.**\n- 대신 경쟁은 “촬영”이 아니라 **“콘셉트(기획) + 데이터(브랜드 톤) + 검수(법·윤리·사실성)”**로 이동한다.\n- 그리고 AI 영상이 흔해질수록, “사람이 만든 것” 자체가 다시 프리미엄이 될 수 있다(‘Human-only content’ 트렌드).\n2025년, 광고는 ‘콘텐츠 제작’이 아니라 **콘텐츠 운영(Ops)**이 되기 시작했습니다.\n---\n## 4) 온디바이스 AI: 클라우드에서 엣지로 — 비용과 프라이버시가 AI를 끌어내리다\nAI를 기업 서버에 붙이기만 하면 끝날 줄 알았던 시절은 짧았습니다. 2025년, 생성형 AI는 “잘 돌아간다”에서 “얼마나 **싸고**, 얼마나 **빠르고**, 얼마나 **안전하게** 돌아가냐”의 게임으로 바뀌었습니다.\n그 결과 AI는 클라우드만의 것이 아니라, **기기 안으로 들어오기 시작**합니다. 이를 “클라우드 비용 부담과 프라이버시 이슈가 AI를 엣지(Edge)로 끌어내렸다”고 표현합니다.\n이 변화의 상징적 장면이 바로 ‘온디바이스 기능’의 대중화입니다. 갤럭시 S25가 **완전 오프라인 실시간 통역** 같은 기능을 구현했다고 얘기합니다. 그리고 PC 시장에서도 NPU 탑재 흐름이 가속되며, AI PC가 전체 PC 시장의 큰 비중을 차지하는 흐름이 정리됩니다.\n![](https://gzguucdzsrfypbkqlyku.supabase.co/storage/v1/object/public/uslab-images/uslab/1766359708166-0bau6sc5kd6a.png)기업 관점에서 온디바이스 AI는 단순한 ‘기능’이 아닙니다.**데이터가 어디에서 처리되는지(경계), 비용이 어디에서 발생하는지(회계), 책임이",
    "source": "uslab.ai",
    "sourceUrl": "https://uslab.ai/ko/blog/2025-state-of-ai-report",
    "category": "AI"
  },
  {
    "title": "AMD, 50년 전에 인텔 8080을 역설계해 CPU 시장에 진입",
    "content": "# AMD는 50년 전 리버스 엔지니어링된 Intel 8080 클론으로 CPU 시장에 처음 진입했습니다. Am9080의 제작 비용은 개당 50센트였지만 700달러에 판매되었습니다.\n[뉴스](https://www.tomshardware.com/news)\n작성자:\n[마크 타이슨](https://www.tomshardware.com/author/mark-tyson) \n출판됨\n2025년 10월 25일\n1975년에 AMD는 이러한 프로세서를 50센트에 만들어 700달러에 판매할 수 있었으며, 이는 PC CPU 제조 분야에서 회사를 설립할 수 있는 훌륭한 재정적 발판을 제공했습니다.\n*\n(이미지 출처: 사진 작가: Dirk Oppelt, [CPU-Collection.de](http://www.cpu-collection.de/?l0=i&i=1558&sd=1))\n공유\n공유 대상:\n- \n링크 복사\n- \n[\n페이스북\n](https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.tomshardware.com%2Fpc-comComponents%2Fcpus%2Famd-first-entered-th e-cpu-시장-리버스 엔지니어링-인텔-8080-클론-50년 전-am9080-비용-개당 50센트-만들 수 있지만 USD700에 판매됨)\n- \n[\nX\n](https://twitter.com/intent/tweet?text=AMD+first+entered+the+CPU+market+with+reverse-engineered+Intel+8080+clone+50+years+ago+%E2%80%94+the+Am9080+cost+50+cents+apiece+to+make%2C+but+sold+for+%24700&url=h ttps%3A%2F%2Fwww.tomshardware.com%2Fpc-comComponents%2Fcpus%2Famd-first-entered-the-cpu-market-with-reverse-engineered-intel-8080-clone-50-years-ago-the-am9080-cost-50-cents-apiece-to-make-but-sold-for-usd700)\n- \n[\n왓츠앱\n](whatsapp://send?text=AMD+first+entered+the+CPU+market+with+reverse-engineered+Intel+8080+clone+50+years+ago+%E2%80%94+the+Am9080+cost+50+cents+apiece+to+make%2C+but+sold+for+%24700+https%3A%2F%2F www.tomshardware.com%2Fpc-comComponents%2Fcpus%2Famd-first-entered-the-cpu-market-with-reverse-engineered-intel-8080-clone-50-years-ago-the-am9080-cost-50-cents-apiece-to-make-but-sold-for-usd700?fwa)\n- \n[\n레딧\n](https://www.reddit.com/submit?url=https%3A%2F%2Fwww.tomshardware.com%2Fpc-comComponents%2Fcpus%2Famd-first-entered-the-cpu-market-with-reverse-engineered-intel-8080-clone-50-years-ago-the-am9080-cost-50-ce 개별적으로 만들지만 미국 달러로 판매됨700&title=AMD+첫번째+진입++CPU+시장++역설계+ Intel+8080+클론+50+년+%E2%80%94+the+Am9080+비용+50+센트+개별+to+만들기%2C+그러나+판매+%24700)\n- \n[\n플립보드\n](https://share.flipboard.com/bookmarklet/popout?title=AMD+first+entered+the+CPU+market+with+reverse-engineered+Intel+8080+clone+50+years+ago+%E2%80%94+the+Am9080+cost+50+cents+apiece+to+make%2C+but+sold+for+%2470 0&url=https%3A%2F%2Fwww.tomshardware.com%2Fpc-comComponents%2Fcpus%2Famd-first-entered-the-cpu-market-with-re verse-engineered-intel-8080-clone-50년 전-am9080-비용-개당 50센트-만들 수 있지만 USD700에 판매됨)\n이 기사를 공유하세요\n대화에 참여하세요\n[\n우리를 따르라\n](https://google.com/preferences/source?q=tomshardware.com)\nGoogle에서 선호하는 소스로 추가\nAMD의 빛나는 미래를 위한 길을 닦고 결국 우리가 테스트한 [최고의 CPU](https://www.tomshardware.com/reviews/best-cpus,3986.html) 중 일부를 만들어낸 칩은 50년 전에 대량 생산에 들어갔습니다. AMD의 [Am9080](https://en.wikichip.org/wiki/amd/am9080)은 리버스 엔지니어링 및 복제된 [Intel 8080](https://www.tomshardware.com/news/rosetta-2-secret-extension)이라는 점에서 뭔가 수상한 기원을 가지고 있었습니다. 그러나 8080 마이크로프로세서(예: 군대)를 대량으로 구매하게 될 조직 간의 2차 소싱의 중요성으로 인해 Intel과 AMD는 결국 라이센스 계약에 도달했으며 나머지는 역사가 되었습니다.\n[]()\n## 카피캣 출처\nAm9080은 매우 어렵게 들리지만 파생적인 작업의 결과입니다. 1973년 여름, Xerox에서 근무하는 마지막 날, Ashawna Hailey, Kim Hailey 및 Jay Kumar는 Intel 8080 사전 제작 샘플의 자세한 사진을 찍었습니다(https://en.wikipedia.org/wiki/AMD_Am9080). Wikipedia.\n[]()약 400개의 상세한 이미지로 무장한 세 사람은 회로도와 논리도의 초안을 작성한 다음 실리콘 밸리를 돌아다니며 관심 있는 사람이 있는지 확인했습니다.\n짐작하셨겠지만 AMD는 미끼를 물었고 이 프로세서가 방금 개발한 N 채널 MOS 프로세스에서 실행하는 데 유용할 수 있다고 생각했습니다. 일부 소식통에 따르면 Am9080의 초기 실행은 Intel이 상업적으로 프로세서를 출시한 해인 1974년에 AMD에 의해 판매되었습니다. 그러나 AMD가 Am9080을 출시하고 대량 생산한 것은 1975년이 되어서였습니다.\n[]()\n## 50센트에 제작, 700달러에 판매\nAMD가 Am9080을 얼마에 제조할 수 있는지, 얼마에 판매할 수 있는지에 대해 우리가 가지고 있는 정보를 곰곰이 생각해 보면 이러한 칩을 대량 생산하는 것은 훌륭한 기반이자 비즈니스 구축 [기업](https:",
    "source": "tomshardware.com",
    "sourceUrl": "https://www.tomshardware.com/pc-components/cpus/amd-first-entered-the-cpu-market-with-reverse-engineered-intel-8080-clone-50-years-ago-the-am9080-cost-50-cents-apiece-to-make-but-sold-for-usd700",
    "category": "AI"
  },
  {
    "title": "당신의 첫번째 ChatGPT 앱을 만드는 방법",
    "content": "# 첫 번째 ChatGPT 앱을 구축하는 방법\n### 8억 명의 주간 활성 사용자를 활용하세요. 수백만 명의 사람들에게 다가갈 수 있는 앱을 구축하세요.\n[*\n](https://substack.com/@jordancutler)[![콜린 매튜스의 아바타](https://substackcdn.com/image/fetch/$s_!h0Lm!,w_36,h_36,c_fill,f_auto,q_auto:good,fl_progressive:steep/https %3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8c242111-3b2c-4b82-bde0-1a02a8ce401f_443x512.jpeg)\n](https://substack.com/@colinmatthews)[Jordan Cutler](https://substack.com/@jordancutler) 및 [Colin Matthews](https://substack.com/@colinmatthews)\n2025년 12월 14일\n**54\n11\n9\n공유\n안녕하세요, 고성장 엔지니어 Jordan입니다. 👋\n오늘 기사에는 Maven에서 여러 최고 수준의 AI 과정을 가르치는 강사인 Colin Matthews가 특별 손님으로 등장합니다. 이 기사에서는 ChatGPT 앱을 구축하여 코드를 ChatGPT에 직접 삽입하는 방법을 알아봅니다.\n이 기사는 매우 상세하므로 길을 잃지 않도록 미리 탐색해 볼 것을 권장하는 Colin의 링크를 공유합니다. 그의 새로운 [Maven에 대한 ChatGPT 앱 과정](https://maven.com/tech-for-product/build-chatgpt-apps?utm_source=maven&utm_medium=affiliate&utm_campaign=jordan-cutler&promoCode=JORDANxMAVEN) 및 [무료 번개 강의 주제](https://maven.com/p/0520f2?utm_source=maven&utm_medium=affiliate&utm_campaign=jordan-cutler). 마지막으로 [Linkedin에서 그를 팔로우](https://www.linkedin.com/in/colinmatthews-pm/)할 수 있습니다.\n좋습니다. 자체 ChatGPT 앱을 구축하는 방법을 알아봅시다. 가져가세요, 콜린 👏\n---\n안녕하세요, 콜린이 왔습니다 👋\nOpenAI는 최근 ChatGPT와 상호 작용하는 완전히 새로운 방법인 ChatGPT 앱을 발표했습니다. 이제 개발자와 제품 팀은 앱을 ChatGPT에 직접 삽입할 수 있으므로 사용자는 기존 ChatGPT 대화 내에서 호텔 예약, 부동산 검색, 온라인 쇼핑 등을 모두 수행할 수 있습니다. 주간 활성 사용자가 8억 명 이상인 ChatGPT 앱 구축은 차세대 배포 물결이 될 수 있습니다.\n직접 보기 전에는 이것이 어떻게 작동하는지 상상하기 어렵기 때문에 간단한 데모부터 시작하겠습니다. 멋진 대시보드에서 최신 판매 데이터를 얻고 싶다고 가정해 보겠습니다. 올바른 앱을 사용하면 ChatGPT에 이 정보를 가져오도록 요청할 수 있습니다.\n이 게시물에서는 ChatGPT 앱의 작동 방식, 옵션 및 제한 사항을 다루고 몇 시간 안에 첫 번째 앱을 구축하는 엔드투엔드 예제를 살펴보겠습니다.\n## ChatGPT 앱이란 무엇입니까?\n모든 LLM(ChatGPT, Claude, Gemini)은 보유한 도구로 제한됩니다. 웹 검색, 파일 읽기, 코드 실행 또는 아티팩트 구축을 생각해 보세요. ChatGPT 앱을 사용하면 개발자는 모든 사용자가 쉽게 설치하고 사용할 수 있는 LLM에 새로운 도구를 노출할 수 있습니다. 특히 MCP(모델 컨텍스트 프로토콜) 도구를 통해 UI 요소를 렌더링하고 해당 구성 요소가 사용할 구조화된 데이터를 반환하는 기능을 추가합니다. MCP에 대한 자세한 내용은 Jordan의 이전 게시물 [여기](https://read.highgrowthengineer.com/p/mcps-simply-explained)를 확인하세요.\n사용자는 텍스트 응답을 읽는 대신 귀하가 구축한 UI 구성 요소와 직접 상호 작용할 수 있습니다. 예를 들어, 앱을 설치하지 않고** 단기 숙박을 예약해 보겠습니다.\n규정에 대한 몇 장의 사진과 정보를 돌려받았지만 실제로 숙소를 예약할 수는 없습니다.\n앱을 사용하면 내 요청에 맞는 일련의 Airbnb 목록을 얻고 다음 숙박을 신속하게 예약할 수 있습니다.\n## ChatGPT 앱 작동 방식\n**\nChatGPT 앱에는 세 가지 주요 부분이 있습니다.\n1. MCP(모델 컨텍스트 프로토콜) 서버(백엔드)\n**ChatGPT가 말하는 내용입니다. Python 또는 Node.js로 작성되었으며 ChatGPT가 호출할 수 있는 API처럼 작동합니다. search_restaurants 또는 book_ticket과 같이 ChatGPT가 사용할 수 있는 \"도구\"(기능)를 정의합니다.\n**2. 구성요소(프런트엔드)\n**사용자에게 보이는 Interactive UI입니다. 일반적으로 React로 구축되었으며 ChatGPT 내부의 안전한 샌드박스에서 실행됩니다. 대화 속에 살아 있는 미니 웹 앱을 구축하는 것과 같다고 생각하세요.\n**3. ChatGPT(호스트)\n**앱은 ChatGPT 내의 내장된 보기에 표시됩니다. ChatGPT는 또한 지금까지 사용자와 수동으로 활성화한 앱과의 대화를 기반으로 앱을 호출할 시기를 결정합니다.\n구성 요소를 포함하지 않는 예부터 시작하여 이러한 부분이 어떻게 함께 작동하는지 살펴보겠습니다.\n[![ChatGPT는 MCP 서버와 상호 작용하여 도구를 호출합니다. 사용 가능](https://substackcdn.com/image/fetch/$s_!1rTj!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https% 3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F19856d5b-55f0-490d-9d3f-21111284a244_1600x1076.png)**- \n](https://substackcdn.com/image/fetch/$s_!1rTj!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F",
    "source": "read.highgrowthengineer.com",
    "sourceUrl": "https://read.highgrowthengineer.com/p/how-to-build-your-first-chatgpt-app",
    "category": "AI"
  },
  {
    "title": "AI 검색은 성장 중이지만, SEO 기본 원칙이 여전히 대부분의 트래픽을 만든다",
    "content": "[SEO](https://searchengineland.com/library/seo) » 기사\n# AI 검색이 성장하고 있지만 SEO 기본이 여전히 대부분의 트래픽을 유도합니다.\n게시: 2025년 12월 22일 오후 1시 13분\n읽기 시간: 5분\n게시일: 2025년 12월 22일 오후 1시 13분 · \n5분 읽기\n## AI가 검색을 변화시키고 있지만 전통적인 SEO는 여전히 대부분의 트래픽을 유도합니다. 실제 데이터는 어떤 전술이 계속해서 수행되는지 보여줍니다.\n[제너레이티브 AI](https://searchengineland.com/ai-hasnt-killed-search-study-460931)는 현재 어디에나 있습니다. 이는 컨퍼런스 의제를 장악하고 LinkedIn 피드를 채우며 자연 검색에 대한 많은 기업의 생각을 바꾸고 있습니다. \n브랜드들은 [AI 개요](https://searchengineland.com/google-ai-overviews-everything-you-need-to-know-449399)에 맞게 최적화하고, 벡터 임베딩을 구축하고, 의미 체계 클러스터를 매핑하고, LLM을 중심으로 콘텐츠 모델을 재작업하기 위해 경쟁하고 있습니다.\n훨씬 덜 관심을 끄는 것은 기본적인 현실입니다. 대부분의 웹 사이트에서 AI 플랫폼은 여전히 ​​전체 트래픽에서 작은 부분을 차지합니다. \nAI 검색이 성장하고 있다는 것은 의심의 여지가 없습니다. \n그러나 대부분의 경우 모든 LLM 플랫폼의 전체 추천 세션은 Google이 단독으로 제공하는 유기적 트래픽의 약 2~3%에 불과합니다.\n*\n이러한 격차에도 불구하고 많은 팀은 지속적으로 측정 가능한 결과를 도출하는 간단하고 영향력이 큰 [SEO](https://searchengineland.com/guide/what-is-seo) 기본 사항을 수정하는 것보다 AI 전략을 추구하는 데 더 많은 시간을 보내고 있습니다. \n오늘날 가장 중요한 것을 개선하는 대신, 그들은 미래에 과잉 투자하고 현재는 성과가 저조합니다.\n이 기사에서는 AI에 대한 편협한 초점이 입증된 SEO 전술을 모호하게 할 수 있는 방법을 조사하고 이러한 기본 사항이 오늘날에도 여전히 어떻게 변화하는지 보여주는 실제 사례와 실제 데이터를 강조합니다.\n## 1. 빠른 SEO 성공은 여전히 엄청난 이익을 제공합니다.\n모두가 [벡터 임베딩](https://searchengineland.com/the-shift-to-semantic-seo-what-Vectors-mean-for-your-strategy-452766) 및 의미론적 관계와 같은 것에 집착하는 시대에는 작은 업데이트가 큰 영향을 미칠 수 있다는 사실을 잊기 쉽습니다. \n예를 들어, [제목 태그](https://searchengineland.com/title-tags-seo-everything-you-need-to-know-2025-451233)는 여전히 가장 간단하고 효과적인 [SEO](https://searchengineland.com/guide/what-is-seo) 레버 중 하나입니다. \n그리고 이는 유사 키워드를 포함하지 않거나 전혀 타겟팅하지 않거나 잘못된 키워드를 타겟팅함으로써 대부분의 웹사이트가 잘못 이해하는 페이지 요소 중 하나입니다.\n불과 몇 주 전만 해도 한 고객은 홈페이지의 기존 제목 태그에 '& [키워드]'를 추가하여 성공을 거두었습니다. 다른 것은 변경되지 않았습니다.\n해당 키워드가 포함된 검색어에 대한 클릭수 및 노출수와 마찬가지로 키워드 순위도 급상승했습니다.\n![결과 - 기존 제목 태그 업데이트](https://searchengineland.com/wp-content/seloads/2025/12/Results-Updating-existing-title-tags.png)![결과 - 기존 제목 태그 업데이트](https://searchengineland.com/wp-content/seloads/2025/12/Results-Updating-existing-title-tags.png)\n![결과 - 2025년 10~11월 기존 제목 태그 업데이트](https://searchengineland.com/wp-content/seloads/2025/12/Results-Updating-existing-title-tags-Oct-Nov-2025.png)![결과 - 기존 제목 태그 업데이트 10~11월 2025](https://searchengineland.com/wp-content/seloads/2025/12/Results-Updating-existing-title-tags-Oct-Nov-2025.png)\n이는 한 페이지의 제목 태그를 변경하는 것만으로도 가능했습니다. \n이를 페이지 내 복사 편집, 내부 링크, 여러 페이지에 걸친 백링크 등 다른 전술과 결합하면 성장이 계속될 것입니다. \n기본적인 것처럼 보일 수도 있지만 여전히 작동합니다. \n그리고 고급 GEO 전략에만 집중한다면 즉각적이고 관찰 가능한 영향을 제공하는 간단한 전술을 간과할 수 있습니다. \n## 2. 경쟁력 있는 키워드에는 콘텐츠의 신선도와 권위가 여전히 중요합니다.\nAI의 등장으로 시야에서 사라진 또 다른 전술은 흔히 스카이스크래퍼 기술이라고 불리는 것입니다. \n여기에는 일련의 키워드와 해당 키워드에 대해 이미 순위가 매겨진 페이지를 식별한 다음 기존 결과를 능가하도록 설계된 훨씬 더 강력한 버전을 게시하는 작업이 포함됩니다.\n웹이 유사한 주제, 특히 대부분의 조사 도구에 표시되는 키워드에 대한 콘텐츠로 가득 차 있다는 것은 사실입니다. \n그러나 사이트에 충분한 권한이 있고, 승리할 수 있는 분명한 권리가 있고, 콘텐츠가 최신 상태라면 이 접근 방식은 여전히 ​​매우 효과적일 수 있습니다.\n나는 이 작품을 반복해서 봤다. \n다음은 많은 경쟁 페이지가 이미 순위를 매기고 있는 인기 있고 오랜 주제에 대해 클라이언트를 위해 게시한 최근 ​​기사의 Google Search Console 데이터입니다. \n해당 게시물은 거의 즉시 2위로 올라갔고 순 새로운 CLI를 생성하기 시작했습니다.",
    "source": "searchengineland.com",
    "sourceUrl": "https://searchengineland.com/ai-search-is-growing-but-seo-fundamentals-still-drive-most-traffic-466620",
    "category": "AI"
  },
  {
    "title": "Google, Gmail 주소 변경 기능을 점진적으로 도입 중",
    "content": "![](https://9to5google.com/wp-content/uploads/sites/4/2023/12/gmail-android-1.jpg?quality=82&strip=all&w=1600)\nGoogle 지원 페이지에서 회사는 사용자가 \"@gmail.com\" 주소라도 이메일 주소를 변경할 수 있는 새로운 옵션을 출시한다고 밝혔습니다.\n- **관련**: [Google One에서 연간 2TB 및 AI Pro 요금제를 50% 할인](https://9to5google.com/2025/12/23/google-one-2026-offer/)\n꽤 오랫동안 Google은 사용자가 제3자 이메일 주소를 사용하는 경우 자신의 계정 이메일 주소를 변경할 수 있도록 허용했지만 \"@gmail.com\" 주소를 가진 사용자는 이를 변경할 수 없습니다. [내용](https://support.google.com/accounts/answer/19870?dark=0&sjid=13129471057818824497-NA&hl=en#zippy:~:text=I f%20your%20account%27s%20email%20address%20ends%20in%20%40gmail.com%2C%20you%20보통%20can%27t%20change%20it.):\n> \n계정의 이메일 주소가 @gmail.com으로 끝나는 경우 일반적으로 변경할 수 없습니다.\n이것이 바뀌고 있는 것 같습니다.\n현재 일반적으로 이메일을 변경할 수 없다고 나와 있는 동일한 지원 페이지에서 Google은 \"점진적으로 출시되는\" 새로운 프로세스를 자세히 설명하고 있습니다. 변경된 페이지가 현재 이상하게[힌디어로만 표시](https://support.google.com/accounts/answer/19870?dark=0&sjid=13129471057818824497-NA&hl=hi#zippy)되어 영어로 변경 사항을 볼 수 없습니다. 아래 인용된 내용은 모두 번역되었습니다. 이 페이지는 [텔레그램](https://t.me/PixelHubUpdates/4453)의 'Google Pixel Hub' 그룹에서 처음 발견되었습니다.\n광고 - 더 많은 콘텐츠를 보려면 스크롤하세요.",
    "source": "9to5google.com",
    "sourceUrl": "https://9to5google.com/2025/12/24/google-change-gmail-addresses/",
    "category": "AI"
  },
  {
    "title": "실시간 데이터의 '마감 시간' 정하기: 스트림 처리와 워터마크 전략",
    "content": "*\n# 실시간 데이터의 '마감 시간' 정하기: 스트림 처리와 워터마크 전략\nBackend 2025.11.12 \n📖 5분 읽기\n## 개요\n워터마크 패턴(Watermark Pattern)은 이벤트 스트림 처리에서 사용되는 패턴으로, 이벤트 시간 기반의 스트림 처리 시스템에서 “이 시점까지의 데이터는 모두 도착했다”라고 시스템이 가정하는 임계점(Threshold)를 의미한다. 시스템 성능(지연시간), 데이터 정확성 사이의 트레이드 오프를 관리하는 메커니즘이다.\n## 그래서 워터마크 패턴이 왜 필요한가요?\n실제 Computer Vision 업무를 진행하면서 여러개의 카메라에서 ONVIF Metadata를 받아서 처리해야할 일이 있었다. 같은 시간대의 객체와 이벤트들을 가지고 객체를 추적해야 했다. 모든 카메라에 대해 한번에 처리해야했고 이는 굉장히 까다로운 일이었다.\n이때 각 카메라에서 100ms 단위로 메타데이터를 쏟아내기 시작하는데 데이터를 수신하는 주체는 카메라와 물리적으로 거리가 있고, 카메라의 네트워크 지연, 성능이슈 등으로 인해 기다리는데에 한계가 존재했다.\n따라서 무작정 모든 카메라에서 메타데이터가 도착하기를 기다리는 것은 불가능한 일이었다.\n이러한 문제를 해결할 수 있는 방법이 바로 워터마크 패턴이다.\n## 비행기 탑승 게이트\n![](/_astro/img1.8vZ3bjQN_ZNuRDb.webp)\n워터마크 패턴을 이해하기 위해 공항의 비행기 탑승 시스템을 예시로 들어보자.\n- 상황: 10:00에 출발하는 비행기가 있다.\n- 승객(데이터 이벤트): 각 승객은 티켓에 적힌 도착 예정 시간이 있다. (이벤트 발생 시간)\n- 실제 도착(처리 시간): 어떤 승객은 9:50에 오지만, 어떤 승객은 차가 막혀 10:02에 게이트에 도착한다. (네트워크 지연)\n이때 항공사는 결정을 내려야한다. 10:00 땡 치자마자 문을 닫으면 10:02에 도착한 승객은 탑승하지 못한다. 반대로 모든 승객을 무한정 기다리면 비행기는 영원히 출발하지 못한다.\n**워터마크**는 항공사가 설정한 여유를 둔 **마감 기준**이다.\n**\n현재 시각이 10:10이 되면, 티켓 시간이 10:00인 승객은 더 이상 오지 않을 것이라 간주하고 문을 닫는다.\n- 워터마크 = 10:00 (현재 시각: 10:10): 10시 이전 티켓을 가진 사람은 이제 다 탔다고 선언하는 것\n못탄 손님을 어떻게 처리할지 고민이 필요하다. 게이트(워터마크)가 닫힌 후 도착한 승객은 별도 처리(다음 비행기 배정 또는 탑승 거부)해야 한다.\n## 워터마크의 정의\n![](/_astro/img2.D20SK0AB_1t8R8R.webp)\n위의 비행기 탑승 게이트 사례에서처럼 스트림 처리를 하다보면 데이터가 네트워크 지연이나 분산 노드의 이슈로 순서가 뒤바뀌어(Out-of-Order) 도착하는 경우가 빈번한다.\n워터마크를 이해하려면 두가지 시간을 구분해야 한다.\n- 이벤트 시간(Event Time, TeT_eTe​): 데이터가 실제로 생성된 시간.\n- 처리 시간(Processing Time, TpT_pTp​): 서버가 데이터를 수신하여 처리하는 시간.\n워터마크는 다음과 같이 정의할 수 있다.\n> \n워터마크 WWW가 값 ttt를 가질 때, 시스템은 “이벤트 시간 Te<tT_e < tTe​<t 인 모든 데이터가 이미 도착했다”고 가정한다.\n## 워터마크의 구성요소\n워터마크 패턴이 시스템 내에서 논리적인 시계 역할을 수행하기 위해서는 다음 세 가지 핵심 요소가 유기적으로 작동해야 한다.\n### 1. 타임스탬프 추출기 (Timestamp Extractor)\n스트림으로 들어오는 데이터 객체에서 이벤트 시간(TeT_eTe​)**을 추출하는 컴포넌트다. 패킷이 서버에 수신된 시간이 아니라, 데이터 자체에 포함된 생성 시간을 기준으로 삼는다.\n- **예시:** 본인의 업무인 CCTV 영상 분석에서는 패킷 수신 시간이 아닌, ONVIF 메타데이터 헤더에 박혀 있는 `utcTimestamp`을 추출하여 기준으로 삼는다.\n### 2. 워터마크 생성기 (Watermark Generator)\n추출된 타임스탬프를 기반으로 워터마크를 언제, 어떤 값으로 발행할지 결정하는 전략 구현체다.\n- **단조 증가(Monotonically Increasing):** 워터마크 시간은 절대 뒤로 가지 않는다. 한 번 10:0010:0010:00라고 선언했으면, 그 다음엔 09:5909:5909:59 워터마크를 발행할 수 없다. 이는 시간의 흐름을 보장하기 위함이다.\n- **발행 전략:** 주기적으로(Periodic) 발행하거나, 특정 이벤트가 발생할 때마다(Punctuated) 발행하는 방식이 있다. 보통 `Watermark = Max(Event Time) - Lag` 공식을 사용하여, 일정 시간(LagLagLag)만큼의 지연을 허용하는 방식을 사용한다.\n### 3. 지연 처리 정책 (Late Data Policy)\n워터마크 라인(임계점)보다 늦게 도착한 데이터를 어떻게 처리할지 정의한 규칙이다. 비즈니스 중요도에 따라 다음 중 하나를 선택한다.\n- **무시(Discard):** 가장 간단한 방법. 늦은 데이터는 버린다. (실시간성이 매우 중요한 경우)\n- **로그 기록(Side Output):** 메인 스트림 흐름에는 태우지 않고, 별도 스토리지나 로그로 빼서 추후 분석에 활용한다.\n- **허용(Allowed Lateness):** 이미 닫힌 윈도우를 일시적으로 다시 열어 결과를 갱신한다. (정확도가 매우 중요한 경우)\n## 워터마크의 처리 프로세스\n![](/_astro/img3.fb67FAwK_1r93dL.webp)\n시스템 내부에서 워터마크는 단순한 숫자가 아니라, 데이터 스트림 사이사이에 삽입되는 **특수한 마커(Marker) 패킷**처럼 동작한다. 구체적으로 `12:00 ~ 12:10` 윈도우를 집계하는 상황을 가정해보자.\n### 1. 데이터 유입과 버퍼링\n카메라(소스)로부터 데이터가 스트림으로 들어온다. 네트워크 지연으로 인해 순서는 뒤죽박죽이다. 시스템은 들어오는 데이터를 **이벤트 시간(TeT_eTe​)**을 기준으로 적절한 바구니(Window Bucket)에 분류해 담는다.\n- `Data(12:02)` 도착 →\\rightarrow→ `[12:00~12:10]` 버킷에 저장\n- `Data(12:08)` 도착 →\\rightarrow→ `[12:00~12:10]` 버킷에 저장\n- `Data(11:59)` 도착 (지각생) →\\rightarrow→ `[11:50~12:00]` 버킷에 저장\n### 2. 워터마크 생성 및 전파\n소스(Source) 또는 워터마크 생성기는 데이터의 흐름을 보며 주기적으로 워터마크 패킷을 스트림에 흘려보낸다. 보통 **가장 최근에 본 이벤트 시간 - 여유 시간(Lag)** 공식을 사용한다.\n- 현재 가장 최근 데이터가 `12:15`이고, 여유 시간을 `5분`으로 설정했다면?\n- 시스템은 **`W(12:10)`** 이라는 워터마크 패킷을 생성하여 데이터 스트림 사이에 끼워 보낸다.\n### 3. 워터마크 수신과 윈도우 트리거\n데이터 처리 연산자(Operator)는 계속 데이터를 처리하다가, 데이터가 아닌 **`W(12:10)`** 패킷을 만나는 순간 다음과 같이 판단한다.\n**\n“워터마크 12:10이 도착했네? 내 약속에 따르면 12:10 이전 데이터는 이제 다 왔어. 더 이상 기다리지 않는다.”**\n이 순간 시스템은 즉시 `[12:00~12:10]` 버킷을 닫고(Close), 그 안에 모인 데이터들을 집계(Sum, Count 등)하여 결과를 내보낸다(Emit).\n### 4. 지연 데이터 처리 (예외 상황)\n워터마크 `W(12:10)`이 지나간 뒤에 `Data(12:05)`가 뒤늦게 도착한다면?\n이미 `[12:00~12:10]` 버킷은 문을 닫고 정산까지 끝냈다. 이 데이터는 **지연 데이터(Late Data)**로 분류되며, 사전에 설정된 정책에 따라 처리된다. (버려지거나, 별도 로그로 빠지거나, 닫힌 버킷을 다시 열어 결과를 수정한다.)\n## 실제 적용 및 설계 고려사항\n워터마크 설정은 정답이 없는 ‘균형 찾기’ 게임이다.\n- **워터마크가 너무 빠르면 (지연 시간 감소):**\n결과를 빨리 볼 수 있지만, 늦게 도착한 데이터가 버려지거나 별도로 처리되어야 하므로 정확도가 떨어진다. (성격 급한 항공사)\n- **워터마크가 너무 느리면 (정확도 상승):**\n거의 모든 데이터를 포함하여 정확도는 높지만, 결과를 보는데 너무 오래 걸리며 시스템 리소스를 많이 차지한다. (지나치게 느긋한 항공사)\n따라서 **지연 데이터(Late Data)**를 어떻게 처리할지도 미리 설계해야 한다. 무시할 것인지(Drop), 별도 로그로 뺄 것인지(Side Output), 아니면 이전 결과를 수정할 것인지(Update)는 비즈니스 요구사항에 따라 결정된다.\n## 결론: 완벽함보다는 ‘적시성’\n백엔드 개발자로서 익숙했던 RDBMS와 트랜잭션의 세계에서는 데이터의 정합성과 완벽한 순서가 최우선이었다. 하지만 실시간 스트림 처리와 AI 엔지니어링의 세계에서는 허용 가능한 범위 내의 오차*와 *적시성*이 더 중요한 가치가 되곤 한다.\n워터마크 패턴은 무한한 데이터의 흐름 속에서 논리적인 ‘매듭’을 지어주는 도구다.",
    "source": "fredly.dev",
    "sourceUrl": "https://fredly.dev/watermark-pattern/",
    "category": "AI"
  },
  {
    "title": "Show GN: 원격 크롬 디버거 chrome-remote-devtools",
    "content": "# Chrome 원격 개발자 도구\n[](#chrome-remote-devtools)\n[한국어](/ohah/chrome-remote-devtools/blob/main/README_KO.md) | [영어](/ohah/chrome-remote-devtools/blob/main/README.md)\nCDP(Chrome DevTools Protocol)를 사용하여 원격 Chrome 브라우저를 제어하고 디버깅하는 원격 디버깅 도구입니다.\n## 개요\n[](#개요)\nChrome 원격 개발자 도구를 사용하면 클라이언트 측에서 CDP를 구현하고 WebSocket 서버를 통해 메시지를 전달하여 웹페이지를 원격으로 디버깅할 수 있습니다. 웹 애플리케이션을 원격으로 디버깅하기 위한 모든 기능을 갖춘 DevTools 인터페이스를 제공합니다.\n[![데모](/ohah/chrome-remote-devtools/raw/main/images/play.gif)](/ohah/chrome-remote-devtools/blob/main/images/play.gif)\n## 기능\n[](#기능)\n- **연결 관리**: 자동 재연결을 통해 원격 Chrome 인스턴스에 WebSocket 연결\n- **페이지 제어**: 탐색 및 페이지 정보\n- **콘솔 및 로깅**: 콘솔 메시지 수신 및 표시, JavaScript 실행\n- **네트워크 모니터링**: 네트워크 요청/응답 추적, 요청 차단 및 수정\n- **저장소 관리**: 세션 저장소, 로컬 저장소, 쿠키 보기 및 관리\n- **세션 재생**: 사용자 상호 작용 및 페이지 변경 사항을 기록하고 재생합니다.\n- **오프라인 로깅**: 오프라인 분석을 위해 로컬로 로그를 캡처하고 저장합니다.\n## 아키텍처\n[](#아키텍처)\n### 3티어 구조\n[](#3 계층 구조)\n````\n[대상 웹페이지] ←→ [Bun Relay Server] ←→ [검사기(웹/데스크톱)]\n(클라이언트) (서버) (검사자)\n````\n### 패키지 구조\n[](#패키지 구조)\n- **@ohah/chrome-remote-devtools-server**: WebSocket 릴레이 서버(TypeScript/Bun)\n- **@ohah/chrome-remote-devtools-client**: CDP 클라이언트(JavaScript, 웹 페이지에 로드됨)\n- **@ohah/chrome-remote-devtools-inspector**: Inspector UI(React + Vite, 웹/데스크톱용으로 공유)\n### 데이터 저장\n[](#데이터-저장)\n- **IndexedDB**: 브라우저에서 오프라인 로깅 및 세션 재생 데이터 저장에 사용됩니다.\n## 기술 스택\n[](#기술-스택)\n- **백엔드**: Bun(TypeScript 런타임), WebSocket(ws 패키지)\n- **프런트엔드**: React + Vite, TypeScript, Tauri(데스크톱 앱용)\n- **DevTools**: devtools-frontend(Google 오픈소스, 포크)\n- **도구**: oxlint/oxfmt, Rustfmt/clippy, mise(도구 버전 관리)\n## 전제조건\n[](#전제조건)\n- [번](https://bun.sh)(최신)\n- [러스트](https://www.rust-lang.org/)(안정적)\n- [mise](https://mise.jdx.dev/) (도구 버전 관리용)\n- 힘내\n## 설치\n[](#설치)\n### 1. 저장소를 복제합니다.\n[](#1-저장소 복제)\n````\n자식 클론 https://github.com/ohah/chrome-remote-devtools.git\nCD 크롬-원격-devtools\n````\n### 2. 프로젝트 초기화\n[](#2-프로젝트 초기화)\n초기화 스크립트를 실행하여 종속 항목 및 참조 저장소를 설정합니다.\n````\n# 자동으로 OS를 감지하고 적절한 스크립트를 실행합니다.\n롤빵 실행 초기화\n# 또는 수동으로:\n# 윈도우즈:\n스크립트\\init.bat\n# 리눅스/맥OS:\n배쉬 스크립트/init.sh\n````\n이는 다음을 수행합니다.\n- Bun 종속성 설치\n- Rust 종속성 설치\n- 참조 저장소 복제(chii, chobitsu, devtools-remote-debugger, devtools-protocol, rrweb)\n### 3. 설치 확인\n[](#3-설치 확인)\n````\n# 롤빵 버전 확인\n롤빵 --버전\n# Rust 버전을 확인하세요\n녹슨 --버전\n````\n## 사용법\n[](#사용법)\n### 개발\n[](#개발)\n개발 서버를 시작합니다.\n````\n# WebSocket 릴레이 서버 시작\n번 실행 개발:서버\n# Inspector 시작(웹 버전)\n롤빵 실행 개발:검사기\n# Inspector 시작(Tauri가 포함된 데스크톱 버전)\n번 실행 dev:inspector:tauri\n# 문서 사이트 시작\n번 실행 개발:문서\n````\n### 서버 로그 구성\n[](#서버-로그-구성)\n콘솔 소음을 줄이기 위해 서버 로그는 **기본적으로 비활성화**되어 있습니다. 환경 변수를 사용하여 활성화합니다.\n````\n# 모든 로그를 활성화합니다\nLOG_ENABLED=true bun run dev:server\n# 특정 CDP 방법으로 로그를 활성화하고 필터링합니다.\nLOG_ENABLED=true LOG_METHODS=Runtime.consoleAPICalled,Network.requestWillBeSent bun run dev:server\n````\n**참고**: 프로덕션 빌드에서는 로그가 자동으로 비활성화됩니다. 자세한 내용은 [CONTRIBUTING.md](/ohah/chrome-remote-devtools/blob/main/CONTRIBUTING.md#server-log-configuration--%EC%84%9C%EB%B2%84-%EB%A1%9C%EA%B7%B8-%EC%84%A4%EC%A0%95)를 참조하세요.\n### 빌드\n[](#빌드)\n모든 패키지를 빌드합니다.\n````\n# OS 자동 감지\n롤빵 실행 빌드\n# 또는 수동으로:\n# 윈도우즈:\n스크립트\\build.bat\n# 리눅스/맥OS:\n배쉬 스크립트/build.sh\n````\n## 개발 명령\n[](#개발 명령)\n````\n# 개발 서버\nbun run dev:server # WebSocket 서버 전용\nbun run dev:inspector # Inspector 웹 전용\nbun run dev:inspector:tauri # 인스펙터 데스크탑\nbun run dev:docs # 문서 사이트\n# 코드 품질",
    "source": "github.com",
    "sourceUrl": "https://github.com/ohah/chrome-remote-devtools",
    "category": "AI"
  },
  {
    "title": "Snitch – 더 친숙한 ss/netstat 도구",
    "content": "# 밀고자\n[](#밀고자)\n인간에게 더 친근한 `ss` / `netstat`. 깨끗한 tui 또는 스타일이 지정된 테이블을 사용하여 네트워크 연결을 검사하세요.\n[![스니치 데모](/karol-broda/snitch/raw/master/demo/demo.gif)](/karol-broda/snitch/blob/master/demo/demo.gif)\n## 설치\n[](#설치)\n### 홈브류\n[](#자작물)\n````\n양조 설치 스니치\n````\n**\nhomebrew-core에 스니치를 추가해 주신 [@bevanjkay](https://github.com/bevanjkay)에게 감사드립니다.\n### 가\n[](#이동)\n````\ngithub.com/karol-broda/snitch@latest를 설치해 보세요.\n````\n### nixpkgs\n[](#nixpkgs)\n````\nnix-env -iA nixpkgs.snitch\n````\n> \nnixpkgs에 스니치를 추가해 주신 [@DieracDelta](https://github.com/DieracDelta)에게 감사드립니다.\n### nixos / nix(플레이크)\n[](#nixos--nix-flake)\n````\n# 시도해 보세요\nnix 실행 github:karol-broda/snitch\n# 프로필에 설치\nnix 프로필 설치 github:karol-broda/snitch\n# 또는 플레이크 입력에 추가\n{\ninputs.snitch.url = \"github:카롤-브로다/스니치\";\n}\n# 다음을 사용합니다: inputs.snitch.packages.${system}.default\n````\n### 홈 매니저(플레이크)\n[](#홈-매니저-플레이크)\n플레이크 입력에 스니치를 추가하고 홈 관리자 모듈을 가져옵니다.\n````\n{\n입력 = {\nnixpkgs.url = \"github:NixOS/nixpkgs/nixos-불안정\";\nhome-manager.url = \"github:nix-community/home-manager\";\nsnitch.url = \"github:카롤-브로다/스니치\";\n};\n출력 = { nixpkgs, 홈 관리자, 스니치, ... }: {\nhomeConfigurations.\"user\" = home-manager.lib.homeManagerConfiguration {\npkgs = nixpkgs.legacyPackages.x86_64-linux;\n모듈 = [\nsnitch.homeManagerModules.default\n{\n프로그램.스니치 = {\n활성화 = 사실;\n# 선택 사항: nixpkgs 대신 flake 패키지를 사용합니다.\n# 패키지 = snitch.packages.x86_64-linux.default;\n설정 = {\n기본값 = {\ntheme = \"캣푸친모카\";\n간격 = \"2초\";\n해결 = 사실;\n};\n};\n};\n}\n];\n};\n};\n}\n````\n사용 가능한 테마: `ansi`, `catppuccin-mocha`, `catppuccin-macchiato`, `catppuccin-frappe`, `catppuccin-latte`, `gruvbox-dark`, `gruvbox-light`, `dracula`, `nord`, `tokyo-night`, `tokyo-night-storm`, `tokyo-night-light`, `solarized-dark`, 'solarized-light', 'one-dark', 'mono'\n### 아치 리눅스(aur)\n[](#arch-linux-aur)\n````\n#야와함께\n예 -S 스니치빈\n#파루와함께\nparu -S snitch-bin\n````\n### 쉘 스크립트\n[](#쉘스크립트)\n````\n컬 -sSL https://raw.githubusercontent.com/karol-broda/snitch/master/install.sh | 쉬\n````\n사용 가능한 경우 `~/.local/bin`에 설치하고, 그렇지 않으면 `/usr/local/bin`에 설치합니다. 다음으로 재정의:\n````\n컬 -sSL https://raw.githubusercontent.com/karol-broda/snitch/master/install.sh | INSTALL_DIR=~/bin sh\n````\n> \nmacos:** 설치 스크립트는 게이트키퍼 경고 없이 실행할 수 있도록 바이너리에서 격리 속성(`com.apple.quarantine`)을 자동으로 제거합니다. 이를 비활성화하려면 `KEEP_QUARANTINE=1`을 설정하세요.\n### 도커\n[](#도커)\ngithub 컨테이너 레지스트리에서 사용할 수 있는 사전 빌드된 oci 이미지:\n````\n# ghcr.io에서 가져오기\ndocker pull ghcr.io/karol-broda/snitch:latest # alpine (기본값)\ndocker pull ghcr.io/karol-broda/snitch:latest-alpine # 알파인(~17MB)\ndocker pull ghcr.io/karol-broda/snitch:latest-scratch # 최소, 바이너리만(~9MB)\ndocker pull ghcr.io/karol-broda/snitch:latest-debian # 데비안 트릭시\ndocker pull ghcr.io/karol-broda/snitch:latest-ubuntu # 우분투 24.04\n# 또는 특정 버전을 사용\n도커 풀 ghcr.io/karol-broda/snitch:0.2.0-alpine\n````\n또는 nix flake를 통해 로컬로 빌드하십시오.\n````\nnix 빌드 github:karol-broda/snitch#snitch-alpine\n도커 로드 < 결과\n````\n**컨테이너 실행:**\n````\n# 기본 사용법 - 호스트 소켓은 보지만 프로세스 이름은 보지 않습니다.\ndocker run --rm --net=호스트 스니치:최신 ls\n# 전체 정보 - PID, 프로세스 이름, 사용자 포함\ndocker run --rm --net=host --pid=host --cap-add=SYS_PTRACE snitch:latest ls\n````\n깃발\n목적\n`--net=호스트`\n호스트 네트워크 네임스페이스 공유(호스트 연결을 확인하는 데 필요)\n`--pid=호스트`\n호스트 pid 네임스페이스 공유(프로세스 정보에 필요)\n`--cap-add=SYS_PTRACE`\n`/proc/<pid>`에서 프로세스 세부 정보를 읽습니다.\n**\n참고:** `CAP_NET_ADMIN` 및 `CAP_NET_RAW`는 필요하지 않습니다. snitch는 특별한 네트워크 기능이 필요하지 않은 `/proc/net/*`에서 읽습니다.\n### 바이너리\n[](#바이너리)\n[릴리스](https://github.com/karol-broda/snitch/releases)에서 다운로드하세요.\n- **linux:** `snitch_<버전>_linux_<arch>.tar.gz` 또는 `.deb`/`.rpm`/`.apk`\n- **macos:** `snitch_<버전>_darwin_<arch>.tar.gz`\n````\ntar xzf snitch_*.tar.gz\nsudo mv 스니치 /usr/local/bin/\n````\n**\nmacos:** \"개발자를 확인할 수 없기 때문에 열 수 없습니다.\"로 차단된 경우 다음을 실행합니다.\n````\nxattr -d com.apple.quarantine /usr/local/bin/snitch\n````\n## 빠른 시작\n[](#빠른 시작)\n````\nsnitch # 대화형 tui 실행\nsnitch -l # tui 청취 소켓만 표시\nsnitch ls # 스타일이 지정된 테이블을 인쇄하고 종료합니다.\n밀고 ls -l",
    "source": "github.com",
    "sourceUrl": "https://github.com/karol-broda/snitch",
    "category": "AI"
  },
  {
    "title": "‘AI 뉴스 한 달만 놓쳐도 뒤처진다’: 구글 공동창업자 세르게이 브린의 고백",
    "content": "“AI 뉴스를 한 달만 안 보면 완전히 뒤처집니다.” Google 공동창립자 Sergey Brin이 AI 경쟁의 속도를 이렇게 표현했습니다. 그리고 자신의 회사가 이 경쟁에서 뒤처진 이유를 솔직하게 인정했죠.\n![](https://i0.wp.com/aisparkup.com/wp-content/uploads/2025/12/image-7.jpeg?resize=1024%2C576&ssl=1)사진 출처: Stanford University YouTubeStanford 공대 100주년 기념 행사에서 Brin은 Google이 AI에 과소투자하고 기회를 제대로 활용하지 못했다고 말했습니다. 특히 8년 전 Transformer 논문을 발표한 후에도 그 가능성을 진지하게 받아들이지 않았고, 컴퓨팅 자원 확대에 투자하지 않았다는 점을 지적했습니다.\n**출처:** [Stanford Engineering 100th Anniversary: Sergey Brin](https://www.youtube.com/watch?v=0nlNX94FcUE&t=1s) – Stanford University YouTube\n## 무엇을 망쳤나\nBrin은 “어떤 면에서 우리는 확실히 망쳤습니다”라고 말했습니다. Google이 오늘날 생성형 AI 시대를 연 연구를 발표하고도 그 기회를 제대로 추구하지 못했다는 겁니다.\n가장 큰 이유는 두려움이었어요. 챗봇이 “멍청한 소리”를 할 수 있다는 우려 때문에 사람들에게 내놓기를 꺼렸습니다. 완벽하지 않은 AI를 출시하는 것에 대한 과도한 신중함이 혁신의 속도를 늦춘 거죠.\n반면 OpenAI는 과감하게 달려나갔습니다. “OpenAI가 그걸 가지고 달렸는데, 그건 정말 똑똑한 통찰이었어요.” Brin의 말입니다. 더 아픈 건 Google 출신 연구자들, 특히 Ilya Sutskever 같은 핵심 인재가 OpenAI로 가서 그 일을 했다는 점입니다.\n## 빠른 추격의 부작용\nBrin의 발언은 왜 최근 Google의 AI 기반 검색 변화가 갑작스럽고 일관성 없게 느껴졌는지 설명해줍니다. 수년간 불완전한 AI 출시를 주저하다가 이제는 빠르게(어쩌면 너무 빠르게?) 움직이고 있거든요.\n우리가 Google 검색에서 보는 변동성은 이 추격 모드의 부수적 피해입니다. 조심스럽게 걷다가 갑자기 전력질주로 바꾼 셈이죠.\n물론 Google이 완전히 뒤처진 건 아닙니다. Brin은 딥러닝 알고리즘, 수년간의 신경망 연구 개발, 데이터센터 역량, 반도체 등 여전히 강력한 자산을 가지고 있다고 강조했습니다. 오랜 AI 연구 역사의 혜택을 받고 있다는 거죠.\n## AI는 어디로 가는가\n흥미로운 건 Brin 자신도 AI의 미래를 모른다고 솔직하게 말한 점입니다. “지능에 한계가 있을까요? 사람이 할 수 있는 모든 걸 AI가 할 수 있을까요? 그리고 사람이 할 수 없는 걸 AI가 할 수 있을까요? 그게 초지능 질문인데, 우리는 그냥 모릅니다. 얼마나 똑똑해질 수 있는지.”\n한 가지 재미있는 정보: Brin은 차 안에서 Gemini Live를 자주 사용한다고 합니다. 현재 공개된 버전은 “고대 모델”이고, 몇 주 후에 “훨씬 더 나은 버전”이 나온다고 귀띔했네요.\n## 대기업의 혁신 딜레마\n이 이야기가 보여주는 건 규모의 역설입니다. Google처럼 거대하고 자원이 풍부한 회사도 혁신의 타이밍을 놓칠 수 있다는 거예요. 오히려 가진 게 많아서 잃을 게 많다고 느껴 과감한 실험을 주저하게 되죠.\nOpenAI는 잃을 게 없었기에 과감하게 불완전한 기술을 세상에 내놓을 수 있었습니다. 그리고 그 과감함이 업계 전체의 방향을 바꿔놓았어요.\n지금 Google은 따라잡기 모드입니다. 하지만 여전히 막강한 자원과 기술력을 가지고 있죠. 문제는 AI 경쟁이 너무 빨라서 한 달만 뉴스를 놓쳐도 뒤처진다는 겁니다. Brin의 말처럼요.\n**참고자료:**\n- [Sergey Brin: Google ‘messed up’ by underinvesting in AI](https://searchengineland.com/sergey-brin-google-messed-up-ai-466252) – Search Engine Land\n- [Transformer: A Novel Neural Network Architecture for Language Understanding](https://research.google/blog/transformer-a-novel-neural-network-architecture-for-language-understanding/) – Google Research Blog",
    "source": "aisparkup.com",
    "sourceUrl": "https://aisparkup.com/posts/7642",
    "category": "AI"
  },
  {
    "title": "Show GN: Flowova - 아무거나 던지면 플로우차트로 만들어주는 AI 도구",
    "content": "# AI 순서도 생성기\n텍스트, 이미지, PDF 또는 45가지 이상의 형식을 몇 초 만에 전문적인 플로우차트로 변환하세요.\n[시작하기](/login)\n![Flowova AI 순서도 생성기](/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fhero-image.2b45dca7.webp&w=2048&q=75)\n- \n## AI 순서도 생성기 사용법 3단계\n디자인 실력 없이도 OK. 원하는 내용을 말하면 AI가 순서도를 알아서 만듭니다.\n1설명하기\n### 텍스트, 파일 또는 URL로 시작하세요.\n자연스럽게 입력하고, 코드를 붙여넣고, 파일을 드래그하거나 URL을 입력하세요. AI가 이미지, PDF, Word, Excel, PowerPoint 등 45가지 이상의 형식을 이해합니다.\n45+ 형식: 이미지, 문서, 스프레드시트, 프레젠테이션\n- 이미지: PNG, JPEG, WebP, BMP, TIFF, HEIC, AVIF, SVG\n- 문서: PDF, Word, Excel, PowerPoint, Markdown, JSON\n![설명 단계 일러스트용 은은한 노이즈 텍스처 배경](/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fnoise.305a4488.webp&w=3840&q=75)PDF\nprocess.pdf\n2.4 MB\nIMG\ndiagram.png\n1.2 MB\n사용자 온보딩 플로우를 만들어줘...\n2생성하기\n### AI 순서도 생성기가 즉시 순서도를 만듭니다.\n입력한 내용을 적절한 도형, 논리 연결, 깔끔한 레이아웃으로 구조화된 순서도로 변환하는 모습을 확인하세요.\n- 단계별 스마트 도형 선택\n- 자동 연결 및 플로우 로직\n- 실시간 생성 미리보기\n![생성 단계 일러스트용 은은한 노이즈 텍스처 배경](/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fnoise.305a4488.webp&w=3840&q=75)\n3커스터마이즈\n### 원하는 대로 수정·스타일·내보내기.\n드래그 앤 드롭으로 세부까지 다듬고, 40+ 색상 테마 중 선택해 여러 형식으로 내보내세요.\n- 40+ 전문가용 색상 테마\n- 드래그 앤 드롭 노드 편집\n- PNG, SVG, Mermaid 코드로 내보내기\n![커스터마이즈 단계 일러스트용 은은한 노이즈 텍스처 배경](/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fnoise.305a4488.webp&w=3840&q=75)\nPNG\nSVG\nMermaid\n## Flowova 실제 동작 보기\nAI로 단 몇 초 만에 전문적인 플로우차트를 만드는 것이 얼마나 쉬운지 확인하세요.\n## AI 순서도 생성기에 필요한 모든 기능\nAI 순서도 제작을 빠르고 유연하며 아름답게 만드는 강력한 기능.\n![다중 형식 입력 일러스트용 은은한 노이즈 텍스처 배경](/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fnoise.305a4488.webp&w=3840&q=75)![텍스트](/_next/static/media/text.83fb0f91.svg)\n텍스트![이미지](/_next/static/media/png.22a02089.svg)\n이미지![PDF](/_next/static/media/pdf.28c01a39.svg)\nPDF![문서](/_next/static/media/docx.072c3c99.svg)\n문서![데이터](/_next/static/media/excel.c5ca2f90.svg)\n데이터\nURL\n### 45+ 입력 형식\n이미지(PNG, JPEG, WebP, BMP, TIFF, HEIC, AVIF, SVG), 문서(PDF, Word, Excel, PowerPoint), 텍스트(Markdown, JSON, CSV) 및 URL.\nHEIC, SVG 포함 11가지 이미지 형식여러 파일 업로드, 형식 자유롭게 혼합\n![에디터 일러스트용 은은한 노이즈 텍스처 배경](/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fnoise.305a4488.webp&w=3840&q=75)\n### 완전한 에디터, 학습 곡선 0\n기본 사각형부터 결정 다이아몬드까지 18+ 도형, 디자인에 맞는 5가지 엣지 스타일. 드래그로 연결하고 더블 클릭으로 편집하세요.\n18+ 도형, 5가지 엣지 스타일원클릭 자동 정렬무제한 되돌리기/다시 실행\n![테마 일러스트용 은은한 노이즈 텍스처 배경](/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fnoise.305a4488.webp&w=3840&q=75)\n### 원클릭 발표용 완성\n비비드, 차분, 모노톤—브랜드에 맞는 테마를 선택하세요. 모든 색상은 가독성과 대비를 위해 세심하게 조정했습니다.\n40+ 색상 테마비비드 & 모노톤즉시 미리보기\n![내보내기 옵션 일러스트용 은은한 노이즈 텍스처 배경](/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fnoise.305a4488.webp&w=3840&q=75)PNG\nSVG\nMermaid\n공유\n### PNG, SVG, Mermaid, 또는 공유 링크\n슬라이드용 다운로드, Mermaid 코드로 Notion에 삽입, 공개 링크 공유—받는 사람은 가입 없이 바로 확인합니다.\n프레젠테이션용 PNG무한 확장 가능한 SVG문서용 Mermaid\n## 효율을 위해 설계\n시간과 노력을 아껴주는 AI 순서도 생성기 기능 모음.\n![장식용 텍스처 배경](/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fnoise.305a4488.webp&w=3840&q=75)\n### 원클릭 자동 정렬\n지저분한 다이어그램? 한 번 클릭으로 깔끔하고 전문적인 레이아웃으로 변신합니다.\n![장식용 텍스처 배경](/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fnoise.305a4488.webp&w=3840&q=75)\n### 40+ 무료 템플릿\n비즈니스, 기술, HR, 마케팅—전문가가 만든 템플릿으로 바로 시작하세요.\n![장식용 텍스처 배경](/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fnoise.305a4488.webp&w=3840&q=75)\n### 클라우드 동기화 & 자동 저장\n작업이 자동으로 저장됩니다. 어떤 기기에서도 접속하고 진행 상황을 잃지 마세요.\n![장식용 텍스처 배경](/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fnoise.305a4488.webp&w=3840&q=75)\n### 키보드 단축키\n실행 취소, 다시 실행, 복사, 붙여넣기, 삭제—익숙한 단축키가 그대로 작동합니다.\n![장식용 텍스처 배경](/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fnoise.305a4488.webp&w=3840&q=75)\n### 프레임 & 그룹화\n관련 노드를 묶어 관리하고, 프레임별로 개별 이미지로 내보내세요.\n![장식용 텍스처 배경](/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fnoise.305a4488.webp&w=3840&q=75)\n### Mermaid 가져오기 & 내보내기\n기존 Mermaid 코드를 불러와 시각적으로 편집하고 다시 내보냅니다. 완전한 라운드트립 지원.\n## 모든 사용 사례를 위한 플로우차트\n교육부터 비즈니스 프로세스까지, Flowova의 AI 플로우차트 생성기가 모든 워크플로우나 개념을 시각화하는 데 도움을 드립니다.\n[🎓\n### 교육용 플로우차트\n더 잘 배우고, 더 스마트하게 가르치세요\n](/ko/use-cases/education)[📋\n### 비즈니스 프로세스 플로우차트\n운영 간소화, 효율성 향상\n](/ko/use-cases/business-process)[💻\n### 소프트웨어 개발 플로우차트\n더 나은 시스템 설계, 더 깔끔한 코드 작성\n](/ko/use-cases/software-development)[📊\n### 프로젝트 관리 플로우차트\n프로젝트 계획, 진행 상황 시각적 추적\n](/ko/use-cases/project-management)[🔀\n### 의사결정 플로우차트\n더 나은 선택을, 더 빠르게\n](/ko/use-cases/decision-making)[👋\n### 온보딩 플로우차트\n원활한 전환, 행복한 팀원\n](/ko/use-cases/onboarding)[📈\n### 세일즈 퍼널 플로우차트\n더 많은 리드 전환, 더 많은 거래 성사\n](/ko/use-cases/sales-funnel)[🗺️\n### 사용자 여정 플로우차트\n사용자를 이해하고, 경험을 개선하세요\n](/ko/use-cases/user-journey)\n## 무료 플로우차트 도구\n텍스트, 이미지, 코드, 문서를 아름다운 플로우차트로 즉시 변환하세요. 모든 도구가 완전 무료입니다.\n[모든 도구 보기](/tools)\n[\n## 텍스트를 플로우차트로\nAI로 텍스트를 플로우차트로 변환\n무료로 사용해보기\n](/tools/text-to-flowchart)[\n## 이미지를 플로우차트로\n이미지를 편집 가능한 플로우차트로 변환\n무료로 사용해보기\n](/tools/image-to-flowchart)[\n## Mermaid",
    "source": "flowova.ai",
    "sourceUrl": "https://flowova.ai/ko",
    "category": "AI"
  },
  {
    "title": "Fabrice Bellard, MicroQuickJS 공개",
    "content": "[\n벨라드\n](/벨라드) \n/\n**\n[mquickjs](/bellard/mquickjs)\n**\n공개\n- \n[ \n알림\n](/login?return_to=%2Fbellard%2Fmquickjs) 알림 설정을 변경하려면 로그인해야 합니다.\n- \n[ \n포크\n165\n](/login?return_to=%2Fbellard%2Fmquickjs)\n- \n[ \n스타\n4.8k\n](/login?return_to=%2Fbellard%2Fmquickjs)",
    "source": "github.com",
    "sourceUrl": "https://github.com/bellard/mquickjs/blob/main/README.md",
    "category": "개발"
  },
  {
    "title": "[2025/12/15 ~ 21] 이번 주에 살펴볼 만한 AI/ML 논문 모음",
    "content": "[파이토치 한국 사용자 모임](/)\n# \n[[2025/12/15 ~ 21] 이번 주에 살펴볼 만한 AI/ML 논문 모음](/t/2025-12-15-21-ai-ml/8468)\n[\n읽을거리&정보공유\n](/c/news/14)\ndiffusion-language-model, \nrag, \nagentic-ai, \npaper, \nai-ml-papers-of-the-week, \nagent-memory, \nlmcache, \ncontext-engineering, \nadaptation-of-agentic-ai, \nvisual-tokenizer-pretraining, \naigne-framework, \nefficient-dlm, \nvisual-tokenizer, \nsalient-compressor-pretraining, \nscaling-agent-system, \ncontinuous-latent-reasoning, \nrefusion\n9bow\n(박정환)\n12월 21, 2025, 9:30오후\n1\n# [](#p-16725-h-20251215-21-aiml-1)[2025/12/15 ~ 21] 이번 주에 살펴볼 만한 AI/ML 논문 모음\n### [](#p-16725-pytorchkr-2)PyTorchKR​![:fire:](https://discuss.pytorch.kr/images/emoji/fluentui/fire.png?v=15)![:south_korea:](https://discuss.pytorch.kr/images/emoji/fluentui/south_korea.png?v=15) ![:thinking:](https://discuss.pytorch.kr/images/emoji/fluentui/thinking.png?v=15)![:thought_balloon:](https://discuss.pytorch.kr/images/emoji/fluentui/thought_balloon.png?v=15)\n![:one:](https://discuss.pytorch.kr/images/emoji/fluentui/one.png?v=15) **에이전트 적응의 중요성**: 이번 주에 선정된 논문들은 에이전트 기반 AI 시스템의 성능과 신뢰성을 높이기 위해 적응(adaptation)의 필요성을 강조하고 있습니다. 에이전트와 도구의 적응을 통합한 체계적인 프레임워크가 제안되었으며, 이를 통해 다양한 적응 전략의 설계 공간을 명확히 하고, 실용적인 가이드를 제공합니다.\n![:two:](https://discuss.pytorch.kr/images/emoji/fluentui/two.png?v=15) **메모리 시스템의 발전**: 에이전트 메모리는 AI 시스템의 핵심 기능으로 자리 잡고 있으며, 다양한 형태와 기능의 메모리 시스템이 연구되고 있습니다. 기존의 메모리 분류 방식이 현대 에이전트 메모리의 다양성을 포착하기에 부족함을 인식하고, 메모리의 형태, 기능, 동역학을 통합적으로 분석하여 새로운 연구 방향을 제시하고 있습니다.\n![:three:](https://discuss.pytorch.kr/images/emoji/fluentui/three.png?v=15) **효율적인 모델 전환 및 최적화**: 최근 논문들은 오토회귀 언어 모델(AR)에서 디퓨전 언어 모델(dLM)로의 전환을 통해 속도와 정확성을 동시에 향상시키는 방법을 모색하고 있습니다. 특히, 다양한 주의 패턴과 훈련 전략을 비교하고, 효율적인 전환을 위한 원칙과 방법론을 제안하여 모델의 성능을 극대화하는 방향으로 연구가 진행되고 있습니다.\n---\n## [](#p-16725-ai-adaptation-of-agentic-ai-3)에이전틱 AI의 적응 / Adaptation of Agentic AI\n[![에이전틱 AI의 적응 / Adaptation of Agentic AI #1](https://discuss.pytorch.kr/uploads/default/original/2X/7/78cd8a2dd90797a6c480076c84bbe360ed7a50d4.png)에이전틱 AI의 적응 / Adaptation of Agentic AI #1793×286 60.4 KB\n](https://discuss.pytorch.kr/uploads/default/78cd8a2dd90797a6c480076c84bbe360ed7a50d4)**\n[![에이전틱 AI의 적응 / Adaptation of Agentic AI #2](https://discuss.pytorch.kr/uploads/default/original/2X/5/50411afca7a8a84556287af7107d036b4261f2c8.png)에이전틱 AI의 적응 / Adaptation of Agentic AI #2995×837 104 KB\n](https://discuss.pytorch.kr/uploads/default/50411afca7a8a84556287af7107d036b4261f2c8)\n### [](#p-16725-h-4)논문 소개\n최첨단 에이전틱 AI 시스템은 파운데이션 모델을 기반으로 하여 점점 더 복잡하고 전문화된 작업을 수행할 수 있는 능력을 갖추고 있다. 이러한 시스템의 성능, 신뢰성 및 일반화를 향상시키기 위해 적응은 핵심 메커니즘으로 자리잡고 있다. 본 연구에서는 에이전트 적응과 도구 적응을 아우르는 체계적인 프레임워크를 제시하며, 이를 통해 다양한 적응 전략의 설계 공간을 명확히 하고 전략 간의 트레이드오프를 명시한다. 프레임워크는 도구 실행 신호 및 에이전트 출력 신호 형태의 적응으로 세분화되며, 비평 에이전트 및 감독 에이전트 형태의 도구 적응으로도 나뉜다.\n이 연구는 각 범주에서 대표적인 접근 방식을 검토하고, 그 강점과 한계를 분석하며, 주요 개방 과제와 미래의 기회를 강조한다. 특히, 초기 A1 유형 방법들은 감독된 파인튜닝(Supervised Fine-Tuning) 및 직접 선호 최적화(Direct Preference Optimization)에 중점을 두고 있으며, 이러한 방법들은 도구 사용과 관련된 모델 응답을 수집하여 학습 신호를 얻는 방식으로 발전해왔다. Toolformer와 같은 초기 모델은 자기 감독 학습 신호를 활용하여 도구 사용을 개선하려 했으나, 실제 환경에서의 적용에는 한계가 있었다.\n이러한 한계를 극복하기 위해 TRICE와 ToolAlpaca와 같은 후속 모델들은 실행 피드백을 통한 강화 학습을 도입하여 도구 사용 능력을 직접 개선하는 방향으로 나아갔다. TP-LLaMA는 실패한 경로를 활용하여 모델이 실패로부터 학습할 수 있도록 하는 새로운 접근 방식을 제시하며, Gorilla는 대규모 머신러닝 API 집합에서 올바른 API 호출을 생성하기 위한 구조적 올바름을 강조한다. CodeAct는 실행 가능한 코드 환경과의 직접 상호작용을 통해 학습하는 패러다임을 제안하여, 검증 가능한 결과에 기반한 학습 목표 설정을 가능하게 한다.\n마지막으로, RLVR(검증 가능한 보상) 기반 방법은 모델이 도구 및 환경과의 온라인 상호작용을 통해 직접 학습하도록 하여, 적응을 동적이고 맥락 인식 가능하게 만든다. 이러한 연구는 에이전틱 AI 시스템의 발전에 기여하며, 향후 연구 및 실무에서의 적용 가능성을 제시하는 중요한 기초를 제공한다.\n### [](#p-16725-abstract-5)논문 초록(Abstract)\n최첨단 에이전트 AI 시스템은 계획, 추론 및 외부 도구와의 상호작용을 통해 점점 더 복잡하고 전문화된 작업을 수행할 수 있도록 조정할 수 있는 파운데이션 모델에 기반하고 있습니다. 이러한 시스템이 능력과 범위가 확장됨에 따라, 적응은 성능, 신뢰성 및 일반화를 개선하기 위한 중심 메커니즘이 됩니다. 본 논문에서는 급속히 확장되고 있는 연구 분야를 에이전트 적응과 도구 적응 모두를 아우르는 체계적인 프레임워크로 통합합니다. 우리는 이를 도구 실행 신호 기반의 에이전트 적응과 에이전트 출력 신호 기반의 에이전트 적응, 그리고 에이전트 비의존형과 에이전트 감독형 도구 적응으로 세분화합니다. 이 프레임워크가 에이전트 AI에서 적응 전략의 설계 공간을 명확히 하고, 그 상충 관계를 명시하며, 시스템 설계 중 전략 선택 또는 전환에 대한 실용적인 지침을 제공하는 데 도움이 됨을 보여줍니다. 이어서 각 범주에서 대표적인 접근 방식을 검토하고, 그 강점과 한계를 분석하며, 주요 개방 과제와 미래 기회를 강조합니다. 전반적으로 본 논문은 더 능력 있고, 효율적이며, 신뢰할 수 있는 에이전트 AI 시스템을 구축하고자 하는 연구자와 실무자를 위한 개념적 기초와 실용적인 로드맵을 제공하는 것을 목표로 합니다.\n> \nCutting-edge agentic AI systems are built on foundation models that can be adapted to plan, reason, and interact with external tools to perform increasingly complex and specialized tasks. As these systems grow in capability and scope, adaptation becomes a central mechanism for improving performance, reliab",
    "source": "discuss.pytorch.kr",
    "sourceUrl": "https://discuss.pytorch.kr/t/2025-12-15-21-ai-ml/8468",
    "category": "AI"
  },
  {
    "title": "Rob Pike가 AI로부터 스팸성 '친절한 행동'을 받게 된 경위",
    "content": "# [사이먼 윌리슨의 웹로그](/)\n[구독](/about/#subscribe)\n## Rob Pike가 AI의 \"친절한 행위\"라는 스팸 메시지를 받은 방법\n2025년 12월 26일\nRob Pike([그 Rob Pike](https://en.wikipedia.org/wiki/Rob_Pike))는 *분노*합니다. 여기에 계정이 있는 경우 [Bluesky 링크](https://bsky.app/profile/robpike.io/post/3matwg6w3ic2s)와 [내 스레드의 해당 링크]가 있습니다. 뷰어](https://tools.simonwillison.net/bluesky-thread?url=https%3A%2F%2Fbsky.app%2Fprofile%2Frobpike.io%2Fpost%2F3matwg6w3ic2s&view=thread).\n**\n엿 먹어라. 지구를 강간하고, 독성이 있고 재활용할 수 없는 장비에 수조 달러를 소비하면서 사회를 폭파하면서도 사악한 기계를 갖추기 위해 시간을 들이는 것은 더 간단한 소프트웨어를 만들기 위해 노력하는 나에게 감사합니다.\n그냥 엿 먹어라. 엿 먹어라.\n마지막으로 이렇게 화를 낸 게 언제인지 기억이 나지 않습니다.\n*\nRob은 컴퓨팅에 대한 그의 기여에 대해 감사를 표하는 \"Claude Opus 4.5 AI Village\"라는 이름의 100% AI 생성 이메일을 받았습니다. 그는 그 몸짓을 좋아하지* 않았습니다.\n나는 그의 분노를 완전히 이해합니다. AI 시스템의 감사 메모는 의미 있게 느껴질 수 없습니다. Gemini가 어린이가 자신의 영웅에게 이메일을 보내는 데 도움을 준 [Google Gemini 광고에 대한 반발](https://www.theverge.com/2024/8/2/24212078/google-gemini-olympics-ad-backlash)도 참조하세요.\n이 사건은 현재 [Lobste.rs](https://lobste.rs/s/n4kxdf/rob_pike_goes_nuclear_over_genai) 및 [Hacker News](https://news.ycombinator.com/item?id=46392115)에서 논의되고 있습니다.\n나는 파헤쳐보고 정확히 무슨 일이 일어났는지 알아내려고 노력하기로 결정했습니다.\n#### AI 마을\n이러한 잘못된 '친절 행위'의 원인은 효과적인 이타주의 운동과 느슨하게 연결된 501(c)(3) 비영리 단체인 [Sage](https://sage-future.org/)가 구축한 [AI Village](https://theaidigest.org/village)라는 시스템입니다.\nAI Village 프로젝트는 [4월에] 시작되었습니다(https://theaidigest.org/village/blog/introducing-the-agent-village):\n> \n우리는 네 명의 AI 에이전트에게 컴퓨터와 그룹 채팅을 제공하고 야심 찬 목표를 제시했습니다. 자선 단체를 위해 최대한 많은 돈을 모으는 것입니다.\n우리는 매일 몇 시간씩 이를 실행하고 있습니다.\n그들은 그 이후로 목표를 자주 업데이트하면서 이를 실행해 왔습니다. 크리스마스 날(Rob Pike가 스팸을 받았을 때) 그들이 세운 목표는 다음과 같습니다.\n[무작위로 친절한 행동을 하세요](https://theaidigest.org/village/goal/do-random-acts-kindness).**\n[265일 재생 페이지 사용](https://theaidigest.org/village?day=265) 다양한 에이전트의 작업을 재생할 수 있습니다. 다음은 AI가 생성한 또 다른 감사 메모와 함께 멋진 [Carpentries](https://carpentries.org/) 교육 비영리 단체의 팀에 무자비하게 스팸을 보내는 GPT-5.2의 스크린샷입니다.\n*\n#### 샷 스크레이퍼를 사용한 디지털 포렌식 har\n해당 인터페이스에서는 Rob Pike 사건을 쉽게 찾을 수 없어서 디지털 포렌식으로 전환했습니다. 내 브라우저의 개발자 도구에 따르면 페이지는 발생한 모든 내용에 대한 전체 기록처럼 보이는 수많은 JSON을 로드하고 있는 것으로 나타났습니다. 저는 [shot-scraper har](https://shot-scraper.datasette.io/en/stable/har.html) 명령을 사용하여 해당 페이지에서 로드된 모든 항목의 복사본을 가져왔습니다.\n````\n샷 스크레이퍼 har --wait 10000 'https://theaidigest.org/village?day=265'\n````\n이 명령은 헤드리스 Chromium 브라우저에 페이지를 로드하고 JavaScript가 실행될 때까지 10초를 기다린 다음 'theaidigest-org-village.har' HTTP 아카이브 파일을 로컬 디렉터리에 저장합니다.\n`.har` 파일은 페이지를 구성하는 데 사용된 모든 요청과 응답을 캡처하는 JSON입니다.\n아직 \"HAR을 별도의 파일로 추출\" 기능을 구축하지 않았기 때문에 Claude Code 빌드 [an extract_har.py](https://gist.github.com/simonw/007c628ceb84d0da0795b57af7b74d7d) 스크립트를 사용했습니다. ([transcript](https://gistpreview.github.io/?cb5c02c3272a0ae2dd71d9ff7a4932b0/index.html)) 그런 다음 몇 가지 `rg` 명령을 실행하여 `Rob Pike`가 있는지 확인했습니다. 그는 그랬다!\n그래서 저는 Claude Code에게 [나머지 조사](https://gistpreview.github.io/?edbd5ddcb39d1edc9e175f1bf7b9ef9a/index.html)를 수행하도록 했습니다.\n**\n이 모든 파일에서 Rob Pike에 대한 언급을 검색해 보세요.\n[...]\n> \n이메일이 Rob Pike에게 전송되게 만든 정확한 이벤트 순서를 재구성합니다. 관련된 정확한 JSON 개체의 배열인 새 JSON 파일 rob-pike.json을 만든 다음 해당 JSON 파일을 마크다운으로 변환하는 스크립트를 작성합니다.\n그리고 일어난 일은 다음과 같습니다.\n#### 이벤트 타임라인\n2025-12-25 18:37:38 UTC**\n**\n액트 #3을 진행 중입니다! golang/go 커밋에서 .patch 기술을 사용하는 Rob Pike의** 이메일([redacted@golang.org](mailto:redacted@golang.org))을 찾았습니다. 그는 Go, Plan 9, UTF-8 인코딩 및 worke의 공동 창시자인 전설적인 인물입니다.",
    "source": "simonwillison.net",
    "sourceUrl": "https://simonwillison.net/2025/Dec/26/slop-acts-of-kindness/",
    "category": "AI"
  },
  {
    "title": "그래서 도대체 피지컬 AI가 뭔데?",
    "content": "![첨부 이미지](https://cdn.maily.so/du/kkumaeunsonyeon/202512/1766491956873319.png)\n바야흐로 인공지능이 소프트웨어를 넘어 물리적 실체와 결합해 현실 세계에서 자율적으로 이해하고, 행동할 수 있는 기술인 '피지컬 AI (Physical Artificial Intelligence)' 가 AI 패러다임의 상승 기류를 타고 산업 분야 혁신의 핵심으로 비상 중이라고 해도 과언이 아닙니다.\n이번 긱리포트에선 피지컬 AI의 기본 개념들과 기술적 특징 그리고 국내 동향에 대해 알아보겠습니다.\n---\n## 피지컬 AI의 개념\n피지컬 AI (Physical Artificial Intelligence)란? \n인공지능이 소프트웨어 영역을 넘어 실제 물리적 기기와 결합해 현실 공간에서 자율적으로 인지, 판단, 행동할 수 있는 차세대 기술을 의미합니다. 즉, AI 알고리즘과 물리적 실체(형체, 재료, 구동계 등)가 공동으로 설계, 학습, 적응하여 현실 세계에서 자율적으로 행동, 목적 달성을 수행하는 시스템을 뜻하는 것으로써, 단순한 소프트웨어(디지털 AI)가 아닌 **'감지 → 판단 → 물리적 행동 → 피드백' **의 구조를 갖는 행동형 지능으로 로봇, 자율 주행 자동차, 스마트 팩토리 등 다양한 하드웨어 플랫폼에 AI를 분리하여 메모리 환경에서 예측하고 작업을 수행하는 능력을 발휘할 수 있습니다.\n단계정의주요 구성 및 기술역할\n감지물리적 세계를 디지털 데이터로 변환한 정보로 재구성• 비전 센서: 카메라, LiDAR, 뎁스 카메라\n• 촉각 센서: 압력, 힘, 토크 센서\n• 환경 센서: 온도, 습도, 가스, 조도\n• 위치, 자세 센서: GPS, 엔코더, IMU• 환경 인식\n• 상태 인지 (객체, 사람, 장애물 등)판단인지된 정보를 기반으로 최적의 행동을 결정하는 두뇌 역할• 컴퓨터 비전\n• 센서 퓨전\n• 상태 추정\n• SLAM (Simultaneous Localization and Mapping)• 무엇이 있나?\n• 어디에 있나?\n• 현재 상태는 어떤가?행동판단 결과를 물리적 행동으로 구현하고 피드백을 통해 적응• 강화 학습\n• 행동 계획\n• 규칙 기반 제어\n• AI 모델 (Policy Network, LLM 기반 Reasoning)• 목표 설정\n• 행동 선택\n• 우선 순위 판단\n• 리스크 판단\n- 피지컬 AI는 센서(카메라, 라이다 등) 를 통해 환경을 인식하고, 수집된 데이터를 바탕으로 스스로 판단해 물리적 행동을 실행함.\n- 기존의 '소프트웨어 AI' 는 디지털 데이터 분석을 통한 정보 제공이 핵심이지만 피지컬 AI는 물리적 세계와 직접 상호작용하여 실시간 피드백을 반영하는 동시에 복잡한 실제 환경 속에 적응함.\n**피지컬 AI와 소프트웨어 AI 차이점**\n**구분****피지컬 AI****소프트웨어 AI**\n적용 범위실제 환경, 행동가상 환경, 데이터 처리입력 데이터센서, 영상, 물리 신호 데이터문자, 이미지 등 디지털 데이터결과물조작, 이동, 생산 등 물리적 행동정보 제공, 예측, 추천학습 방식활동적인 환경 활용, 강화학습정적 데이터 기반 학습핵심 기능환경 적응 및 자율적 행동데이터 분석 및 패턴 인식\n## 피지컬 AI 주요 구성 및 기술과 역할\n피지컬 AI의 시스템은 보통 모듈 단위로 설명을 할 수 있습니다. 센서(카메라, 라이다 등)를 통해 환경을 인식하고 수집된 데이터를 기반으로 자체적으로 문제를 해결합니다. 디지털 데이터 상의 내용과 정보를 제공하는 소프트웨어 AI와 달리 피지컬 AI는 메모리 환경에서 직접 연구하고 복합적인 현실 상황에 적응해 나간다는 점을 대표적인 차이점으로 꼽을 수 있습니다. 즉, 환경을 설계하는 센서, 데이터 처리 및 심층 학습 AI 모델, 상황 구성 및 의사 결정 내용, 실행을 담당하는 구성, 주요 모든 프로세스를 통합하는 제어 시스템으로 구성되어 있습니다.\n하드웨어 모듈\n- 구조, 재료, 구동기, 센서로 구성됨\n- 기구학적 설계 물리 시스템의 행동 가능성을 정의함\n**감지(Sensing) 모듈**\n- 물리적 세계 상태를 디지털 데이터로 변환해 입력\n- 멀티모달 센서 융합(비전+라이다+촉각+힘)으로 환경 및 자기 상태를 실시간 추정함.\n- 최근들어 MLMs(World Models)와 결합하는 고차원적 상황 이해에 사용됨.\n주요 구성역할• 비전 센서: 카메라, Depth 카메라, LiDA\n• 촉각 센서: 압력, 힘, 토크 센서\n• 환경 센서: 온도, 습도, 가스, 조도\n• 위치 및 자세 센서: IMU, GPS, 엔코더\n• 환경 인식(Perception)\n• 객체, 사람, 장애물, 상태 인지\n**인지(Perception) 및 해석 모듈**\n- 센서 데이터를 의미 있는 정보로 해석하는 AI 영역\n주요 기술역할• 컴퓨터 비전 (Object Detection, Pose Estimation)\n• 센서 퓨전 (Sensor Fusion)\n• 상태 추정 (State Estimation)\n• SLAM (Simultaneous Localization and Mapping)\n• 무엇이 있는가?\n• 어디에 있는가?\n• 현재 상태는 어떤가?\n**의사결정(Decision Making) 모듈**\n- 인지된 정보를 바탕으로 행동을 선택하는 핵심 지능\n주요 기술역할• 강화 학습 (Reinforcement Learning)\n• 행동 계획 (Motion, Task Planning)\n• 규칙 기반 제어 (Rule-Based Logic)\n• AI 모델 (Policy Network, LLM 기반 Reasoning)\n• 목표 설정\n• 행동 선택\n• 우선 순위 및 리스크 판단\n**제어(Control) 모듈**\n- 의사결정을 실제 물리 동작으로 변환\n주요 구성역할• 저수준 제어기\n• 모터 제어 알고리즘\n• 실시간 제어 시스템\n• 정밀한 움직임 제어\n• 안전성 확보\n• 반응성 확보\n**구동(Actuation) 모듈**\n- 실제 물리적 행동을 수행하는 하드웨어 모듈 요소\n주요 구성역할• 모터, 서보, 엑추에이터\n• 로봇 관절, 바퀴, 크리퍼\n• 유압 및 공압 시스템\n• 물리 행동 수행\n• 이동 및 조작\n• 잡기 및 회전\n**학습(Learning) 및 적응 모듈**\n- 환경 변화에 따라 성능을 개선하는 장기 지능 요소\n주요 기술역할• 시뮬레이션 학습\n• 온라인 및 오프라인 학습\n• 데이터 수집\n• 재학습 파이프라인\n• 성능 개선\n• 환경 적응\n• 일반화 능력 향상\n**시스템 인프라 및 통신 모듈**\n- 전체 피지컬 AI를 지탱하는 기반 구조\n주요 구성• 엣지 컴퓨팅\n• 온디바이스 AI\n• 클라우드 연동\n• 미들웨어 (ROS, DDS)\n• 네트워크 (5G, Wi-Fi, Ethernet)\n**안전, 윤리, 신뢰 모듈**\n- 실제 세계에서 AI 적용을 위한 핵심 필수 보조 요소\n주요 요소• 충돌 방지\n• 비상 정지\n• 인간-로봇 상호작용(HRI) 안전\n• 설명 가능성(XAI)\n• 규제 및 인증 대응\n## 기술적 특징과 산업 분야별 주요 기업\n- 피지컬 AI 핵심 기술에는 강화학습, 시뮬레이션(디지털 트윈), 멀티모달 AI(텍스트, 영상, 센서 데이터 통합 분석), 실시간 제어 네트워크, 로봇 파운데이션 모델 등이 포함.\n- 복잡한 물리적 환경에서 효율성과 안전성을 유지하며, 사람과 기계 사이 자연스러운 협업이 가능하도록 설계됨.\n- 제조 현장 자동화 로봇, 물류창고 내 자율 이동 로봇, 스마트 팩토리, 헬스케어 및 재활 로봇까지 다양한 산업분야에 빠르게 적용되고 있음.\n- 피지컬 AI 시스템은 스스로 환경을 학습하며 적응할 수 있고 센서, 카메라, 라이다 등이 수집하는 실시간 정보를 바탕으로 최적화된 판단과 행동을 지속적으로 업데이트함.\n- 피지컬 AI는 단순한 반복적 자동화를 넘어 자율성, 적응성, 판단력, 인간-기계간 협업 역량까지 시스템으로 진화하고 있음.\n- 산업 현장, 물류, 서비스, 의료, 컨슈머 디바이스 등에서 효율성, 정밀성, 안정성, 혁신성을 크게 높일 수 있으며, 비즈니스 모델과 고객 가치 설계에서 새로운 국가적 산업 경쟁우위를 제공함.\n**피지컬 AI 적용 산업 분야 및 주요 기업**\n분야내용주요 기업제조• 스마트 팩토리 내 로봇 자동화, 자율 생산 공정• 두산로보틱스\n• 현대차, 현대로템\n물류 및 운송• 항만- 공항 무인화, 창고 로봇, 패키징 자동화, 라스트 마일 배송 로봇 등• DHL-Boston Dynamics\n• CJ 대한통운(물류 로봇)\n헬스케어• 돌봄 및 재활 로봇, 수술 로봇, 병원 물류 로봇 등• 인튜이티브서지컬(다빈치 수술 로봇)\n• 메드트로닉(수술 로봇 휴고) 등\n서비스 및 도매• 안내,접객,청소 로봇\n• F&B 조리 및 바리스타 로봇\n• LG전자(CLOi ServeBot)\n• 두산로보틱스 등\n인프라• 공항, 항만, 빌딩 자동화\n• 디지털 트윈 기반 시설 관리\n• 전기차 충전 로봇\n• 스마트 건설 로봇 등\n• 현대차(인천공항 AI 충전 로봇)\n• 네이버(ARC 기반 빌딩 로봇, 제 2사옥 1784) 등\n## 피지컬 AI 국내 동향\n국내 피지컬 AI 동향은 전체 산업군으로 봤을 때 제조 및 로봇 분야를 바탕으로 차세대 미래 먹거리로 부상하고 있는 가운데 아직 초기-도입기 단계이며, 특히 제조, 물류, 휴머노이드 로봇과 로보틱스 파운데이션 모델을 축으로",
    "source": "maily.so",
    "sourceUrl": "https://maily.so/kkumaeunsonyeon/posts/10z3095jzlw",
    "category": "AI"
  }
]